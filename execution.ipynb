{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.dataname == HAGUE\n",
      "\n",
      "trainXS.shape (146295, 1, 89, 12)\n",
      "trainYS.shape (146295, 12, 89, 1)\n",
      "testXS.shape (62698, 1, 89, 12)\n",
      "testYS.shape (62698, 12, 89, 1)\n",
      "\n",
      "spatialSplit_unseen all: trn/val/tst : 89 : 62 / 9 / 18\n",
      "spatialSplit_allNod all: trn/val/tst : 89 : 62 / 71 / 89\n",
      "spatialSplit_unseen.i_tst [51 49 72 33 62 54 11 16 36 40  0 73  8 29 28 64 15  9]\n",
      "\n",
      "train.shape torch.Size([83597, 1, 62, 12]) torch.Size([83597, 12, 62, 1])\n",
      "train_model.shape torch.Size([62698, 1, 62, 12]) torch.Size([62698, 12, 62, 1])\n",
      "val_u.shape torch.Size([62698, 1, 9, 12]) torch.Size([62698, 12, 9, 1])\n",
      "val_a.shape torch.Size([62698, 1, 71, 12]) torch.Size([62698, 12, 71, 1])\n",
      "tst_u.shape torch.Size([62698, 1, 18, 12]) torch.Size([62698, 12, 18, 1])\n",
      "tst_a.shape torch.Size([62698, 1, 89, 12]) torch.Size([62698, 12, 89, 1])\n",
      "\n",
      "adj_train length of 2 torch.Size([62, 62])\n",
      "adj_val_u length of 2 torch.Size([9, 9])\n",
      "adj_val_a length of 2 torch.Size([71, 71])\n",
      "adj_tst_u length of 2 torch.Size([18, 18])\n",
      "adj_tst_a length of 2 torch.Size([89, 89])\n",
      "\n",
      "pretrn_iter.dataset.tensors[0].shape torch.Size([62, 83597])\n",
      "preval_iter.dataset.tensors[0].shape torch.Size([71, 83597])\n",
      "\n",
      "pretrainModel Started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuyou/Desktop/master_graduation_project/utils.py:50: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 time used: 3.459359  seconds  train loss: tensor(4.4001, device='mps:0', grad_fn=<NegBackward0>) validation loss: tensor(2.8243, device='mps:0')\n",
      "PRETIME DURATION: 3.554564\n",
      "pretrainModel Ended ...\n",
      "\n",
      "\n",
      "trainModel Started ...\n",
      "\n",
      "ENCODER INFER DURATION IN MODEL TRAINING: 0:00:01.738657\n",
      "train_embed torch.Size([32, 62]) tensor(-0.0052, device='mps:0') tensor(0.0749, device='mps:0')\n",
      "val_u_embed torch.Size([32, 9]) tensor(-0.0041, device='mps:0') tensor(0.0680, device='mps:0')\n",
      "val_a_embed torch.Size([32, 71]) tensor(-0.0057, device='mps:0') tensor(0.0760, device='mps:0')\n",
      "TRAINING DURATION FOR EPOCH: 0:02:49.961603\n",
      "epoch 0 time used: 248.931497  seconds  train loss: 3.1675363191900736 validation all nodes loss: 2.9123868233750905\n",
      "MODEL TRAINING DURATION: 249.291324\n",
      "trainModel Ended ...\n",
      "\n",
      "Model Testing test_a Started ...\n",
      "Model Infer Start ...\n",
      "ENCODER INFER DURATION: 0:00:00.637365\n",
      "\n",
      "MODEL INFER START ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m P\u001b[38;5;241m.\u001b[39mis_tune \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Execute the experiment script\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39mmain(P)\n",
      "File \u001b[0;32m~/Desktop/master_graduation_project/experiment.py:980\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(P)\u001b[0m\n\u001b[1;32m    977\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(min_val_loss)\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m P\u001b[38;5;241m.\u001b[39mis_tune \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 980\u001b[0m     testModel(P, P\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_a\u001b[39m\u001b[38;5;124m'\u001b[39m, tst_a_iter, adj_tst_a, spatialSplit_allNod, device_cpu, device_gpu, mongodb)\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m P\u001b[38;5;241m.\u001b[39mis_mongo:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m P\u001b[38;5;241m.\u001b[39mis_pretrain:\n",
      "File \u001b[0;32m~/Desktop/master_graduation_project/experiment.py:722\u001b[0m, in \u001b[0;36mtestModel\u001b[0;34m(P, name, mode, test_iter, adj_tst, spatialsplit, device_cpu, device_gpu, mongodb)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMODEL INFER START ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03mPrediction is on all sensors\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;124;03mBut the loss is calculated only for the sensors after sensor_idx_start\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m YS_pred, YS \u001b[38;5;241m=\u001b[39m evaluateModel(P, model, criterion, test_iter, adj_tst, tst_embed, device_gpu, sensor_idx_start, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    723\u001b[0m e_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Infer End ...\u001b[39m\u001b[38;5;124m'\u001b[39m, e_time)\n",
      "File \u001b[0;32m~/Desktop/master_graduation_project/experiment.py:639\u001b[0m, in \u001b[0;36mevaluateModel\u001b[0;34m(P, model, criterion, data_iter, adj, embed, device, sensor_idx_start, test)\u001b[0m\n\u001b[1;32m    637\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:,:,sensor_idx_start:,]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    638\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(x, embed_after_index, P\u001b[38;5;241m.\u001b[39mencoder_to_model_ratio, P\u001b[38;5;241m.\u001b[39mis_concat_encoder_model, support \u001b[38;5;241m=\u001b[39m adj, is_example \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mexample_verbose, is_layer_after_concat \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mis_layer_after_concat)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 639\u001b[0m y \u001b[38;5;241m=\u001b[39m y[:,:,sensor_idx_start:,]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m P\u001b[38;5;241m.\u001b[39mexample_verbose:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIn model evaluation process:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import experiment\n",
    "\n",
    "track_id = 9999\n",
    "for i in range(1):\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "    P = type('Parameters', (object,), {})()\n",
    "    P.dataname = 'HAGUE'\n",
    "    P.model = 'gwnet'\n",
    "    P.pre_model = 'TCN'\n",
    "    P.track_id = track_id\n",
    "    P.replication = i + 1\n",
    "    P.seed = 10\n",
    "\n",
    "    P.t_train = 0.4\n",
    "    P.t_val = 0.3\n",
    "    P.s_train = 0.7\n",
    "    P.s_val = 0.1\n",
    "    P.fold = 4\n",
    "\n",
    "    P.timestep_in = 12\n",
    "    P.timestep_out = 12\n",
    "    P.n_channel = 1\n",
    "    P.batch_size = 64\n",
    "\n",
    "    P.lstm_hidden_dim = 128\n",
    "    P.lstm_layers = 2\n",
    "    P.lstm_dropout = 0.2\n",
    "    P.gwnet_is_adp_adj = True\n",
    "    P.gwnet_is_SGA = False\n",
    "\n",
    "    P.adj_type = 'doubletransition'\n",
    "    P.adj_method = 1\n",
    "    P.adj_diag = 1\n",
    "    P.cost_kernals = [1, 2, 4, 8, 16]\n",
    "    P.cost_alpha = 0.5\n",
    "    P.cl_temperature = 2\n",
    "    P.is_pretrain = True\n",
    "    P.is_GCN_encoder = True\n",
    "    P.is_GCN_after_CL = False\n",
    "    P.gcn_order = 1\n",
    "    P.gcn_dropout = 0\n",
    "    P.augmentation = 'input_smoothing'\n",
    "    P.temporal_shifting_r = 0.9\n",
    "    P.input_smoothing_r = 0.95\n",
    "    P.input_smoothing_e = 20\n",
    "    P.encoder_to_model_ratio = 0.8\n",
    "    P.is_concat_encoder_model = True\n",
    "    P.is_layer_after_concat = True\n",
    "    P.is_always_augmentation = True\n",
    "\n",
    "    P.tolerance = 20\n",
    "    P.learn_rate = 0.001\n",
    "    P.pretrain_epoch = 1\n",
    "    P.train_epoch = 1\n",
    "    P.weight_decay = 0\n",
    "    P.is_testunseen = True\n",
    "    P.train_model_datasplit = 'B'\n",
    "    P.train_encoder_on = 'gpu'\n",
    "\n",
    "    P.is_mongo = False\n",
    "    P.example_verbose = False\n",
    "    P.is_tune = False\n",
    "    # Execute the experiment script\n",
    "    val_loss = experiment.main(P)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
