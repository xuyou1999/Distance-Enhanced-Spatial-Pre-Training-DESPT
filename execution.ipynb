{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.dataname == METRLA\n",
      "data.shape: (34272, 207)\n",
      "METRLA_240417-1726 data splits\n",
      "trainXS.shape (23967, 1, 207, 12)\n",
      "trainYS.shape (23967, 12, 207, 1)\n",
      "testXS.shape (10271, 1, 207, 12)\n",
      "testYS.shape (10271, 12, 207, 1)\n",
      "spatialSplit_unseen all: trn/val/tst : 207 : 144 / 21 / 42\n",
      "spatialSplit_allNod all: trn/val/tst : 207 : 144 / 165 / 207\n",
      "train.shape torch.Size([13695, 1, 144, 12]) torch.Size([13695, 12, 144, 1])\n",
      "train_model.shape torch.Size([10272, 1, 144, 12]) torch.Size([10272, 12, 144, 1])\n",
      "val_u.shape torch.Size([10272, 1, 21, 12]) torch.Size([10272, 12, 21, 1])\n",
      "val_a.shape torch.Size([10272, 1, 165, 12]) torch.Size([10272, 12, 165, 1])\n",
      "tst_u.shape torch.Size([10271, 1, 42, 12]) torch.Size([10271, 12, 42, 1])\n",
      "tst_a.shape torch.Size([10271, 1, 207, 12]) torch.Size([10271, 12, 207, 1])\n",
      "adj_train length of 2 torch.Size([144, 144])\n",
      "adj_val_u length of 2 torch.Size([21, 21])\n",
      "adj_val_a length of 2 torch.Size([165, 165])\n",
      "adj_tst_u length of 2 torch.Size([42, 42])\n",
      "adj_tst_a length of 2 torch.Size([207, 207])\n",
      "pretrn_iter.dataset.tensors[0].shape torch.Size([144, 13695])\n",
      "preval_iter.dataset.tensors[0].shape torch.Size([165, 23967])\n",
      "pretrainModel Started ...\n",
      "epoch 0 time used: 1  seconds  train loss: tensor(0.0359, device='mps:0', grad_fn=<DivBackward0>) validation loss: tensor(0.0224, device='mps:0')\n",
      "PRETIME DURATION: 0:00:01.703542\n",
      "pretrainModel Ended ...\n",
      "\n",
      "trainModel Started ...\n",
      "TIMESTEP_IN, TIMESTEP_OUT 12 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuyou/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER INFER DURATION IN MODEL TRAINING: 0:00:00.326766\n",
      "train_embed torch.Size([32, 144]) tensor(0.0054, device='mps:0') tensor(0.0723, device='mps:0')\n",
      "val_u_embed torch.Size([32, 21]) tensor(0.0086, device='mps:0') tensor(0.0767, device='mps:0')\n",
      "val_a_embed torch.Size([32, 165]) tensor(0.0083, device='mps:0') tensor(0.0754, device='mps:0')\n",
      "epoch 0 time used: 35  seconds  train loss: 0.2650402361915862 validation unseen nodes loss: 0.2287759127391276 validation all nodes loss: 0.22906962400331304\n",
      "MODEL TRAINING DURATION: 0:00:35.533706\n",
      "trainModel Ended ...\n",
      "\n",
      "Model Testing test_a Started ...\n",
      "Model Infer Start ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuyou/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER INFER DURATION: 0:00:00.626176\n",
      "Model Infer End ... 2024-04-17 17:27:31.370559\n",
      "MODEL INFER DURATION: 0:00:09.095303\n",
      "YS.shape, YS_pred.shape, (10271, 12, 42, 1) (10271, 12, 42, 1)\n",
      "****************************************\n",
      "LSTM, test_a, Torch MSE, 2.6044480512e-01, 0.2604448051\n",
      "all pred steps, LSTM, test_a, MSE, RMSE, MAE, MAPE, 109.2557373047, 10.4525470734, 4.7664890289, 12.3355686665\n",
      "1 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 30.8567066193, 5.5548810959, 2.8175861835, 6.7690446973\n",
      "2 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 49.3645553589, 7.0259914398, 3.3183679581, 8.0820016563\n",
      "3 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 65.1561279297, 8.0719347000, 3.7100832462, 9.1788753867\n",
      "4 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 81.5403137207, 9.0299673080, 4.0893769264, 10.1912289858\n",
      "5 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 94.1640014648, 9.7038135529, 4.4128808975, 11.2231880426\n",
      "6 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 106.8482894897, 10.3367443085, 4.7302489281, 12.1705435216\n",
      "7 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 120.5541687012, 10.9797163010, 5.0327610970, 12.9961729050\n",
      "8 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 131.5017547607, 11.4674215317, 5.3047943115, 13.8893008232\n",
      "9 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 143.5732574463, 11.9822053909, 5.5812425613, 14.6663546562\n",
      "10 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 153.0924835205, 12.3730545044, 5.8303093910, 15.5072718859\n",
      "11 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 163.3299713135, 12.7800617218, 6.0789809227, 16.2916496396\n",
      "12 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 171.0915527344, 13.0801973343, 6.2913322449, 17.0614898205\n",
      "Model Testing Ended ... Wed Apr 17 17:27:40 2024\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for i in range(1):\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "    P = type('Parameters', (object,), {})()\n",
    "    P.dataname = 'METRLA'\n",
    "    P.model = 'LSTM'\n",
    "    P.seed = 0\n",
    "\n",
    "    P.t_train = 0.4\n",
    "    P.t_val = 0.3\n",
    "    P.s_train = 0.7\n",
    "    P.s_val = 0.1\n",
    "\n",
    "    P.timestep_in = 12\n",
    "    P.timestep_out = 12\n",
    "    P.n_channel = 1\n",
    "    P.batch_size = 64\n",
    "\n",
    "    P.lstm_hidden_dim = 128\n",
    "    P.gwnet_is_adp_adj = True\n",
    "    P.gwnet_is_SGA = False\n",
    "\n",
    "    P.adj_type = 'doubletransition'\n",
    "    P.is_cost = False\n",
    "    P.cost_kernals = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    P.cost_alpha = 0.5\n",
    "    P.cl_temperature = 1\n",
    "    P.is_pretrain = True\n",
    "    P.is_GCN_encoder = False\n",
    "    P.is_GCN_after_CL = True\n",
    "    # P.augmentation = 'sampler'\n",
    "    P.augmentation = 'temporal_shifting'\n",
    "    P.temporal_shifting_r = 0.8\n",
    "    P.encoder_to_model_ratio = 1\n",
    "    P.is_concat_encoder_model = True\n",
    "\n",
    "    P.learn_rate = 0.001\n",
    "    P.pretrain_epoch = 1\n",
    "    P.train_epoch = 1\n",
    "    P.weight_decay = 0\n",
    "    P.is_testunseen = True\n",
    "    P.train_model_datasplit = 'B'\n",
    "    P.train_encoder_on = 'gpu'\n",
    "    %run -i 'experiment.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
