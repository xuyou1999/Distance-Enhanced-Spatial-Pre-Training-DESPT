{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from experiment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an example for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the first 10 sensors, and only day 2012-03-01 7:00 to 22:55 from the network. Verify if the sensor's distances matches the adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>773869</th>\n",
       "      <th>767541</th>\n",
       "      <th>767542</th>\n",
       "      <th>717447</th>\n",
       "      <th>717446</th>\n",
       "      <th>717445</th>\n",
       "      <th>773062</th>\n",
       "      <th>767620</th>\n",
       "      <th>737529</th>\n",
       "      <th>717816</th>\n",
       "      <th>...</th>\n",
       "      <th>772167</th>\n",
       "      <th>769372</th>\n",
       "      <th>774204</th>\n",
       "      <th>769806</th>\n",
       "      <th>717590</th>\n",
       "      <th>717592</th>\n",
       "      <th>717595</th>\n",
       "      <th>772168</th>\n",
       "      <th>718141</th>\n",
       "      <th>769373</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:00:00</th>\n",
       "      <td>64.375000</td>\n",
       "      <td>67.625000</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>66.875000</td>\n",
       "      <td>68.750000</td>\n",
       "      <td>65.125</td>\n",
       "      <td>67.125</td>\n",
       "      <td>59.625000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.625000</td>\n",
       "      <td>65.500</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>66.428571</td>\n",
       "      <td>66.875</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>61.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:05:00</th>\n",
       "      <td>62.666667</td>\n",
       "      <td>68.555556</td>\n",
       "      <td>65.444444</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>64.444444</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>65.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>57.444444</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>69.875</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>58.555556</td>\n",
       "      <td>62.000</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>64.444444</td>\n",
       "      <td>55.888889</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>62.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:10:00</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>64.500</td>\n",
       "      <td>64.250</td>\n",
       "      <td>63.875000</td>\n",
       "      <td>65.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>68.125</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>61.375000</td>\n",
       "      <td>69.857143</td>\n",
       "      <td>62.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:15:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:20:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        773869     767541     767542     717447     717446  \\\n",
       "2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n",
       "2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  64.444444   \n",
       "2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
       "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "                        717445  773062  767620     737529     717816  ...  \\\n",
       "2012-03-01 00:00:00  68.750000  65.125  67.125  59.625000  62.750000  ...   \n",
       "2012-03-01 00:05:00  68.111111  65.000  65.000  57.444444  63.333333  ...   \n",
       "2012-03-01 00:10:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n",
       "2012-03-01 00:15:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
       "2012-03-01 00:20:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
       "\n",
       "                        772167  769372     774204     769806  717590  \\\n",
       "2012-03-01 00:00:00  45.625000  65.500  64.500000  66.428571  66.875   \n",
       "2012-03-01 00:05:00  50.666667  69.875  66.666667  58.555556  62.000   \n",
       "2012-03-01 00:10:00  44.125000  69.000  56.500000  59.250000  68.125   \n",
       "2012-03-01 00:15:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
       "2012-03-01 00:20:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
       "\n",
       "                        717592     717595     772168     718141  769373  \n",
       "2012-03-01 00:00:00  59.375000  69.000000  59.250000  69.000000  61.875  \n",
       "2012-03-01 00:05:00  61.111111  64.444444  55.888889  68.444444  62.875  \n",
       "2012-03-01 00:10:00  62.500000  65.625000  61.375000  69.857143  62.000  \n",
       "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
       "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf('data/METRLA/metr-la.h5').iloc[:, :1000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df.index.freq = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Slice the DataFrame to only include rows between 7:00 and 22:55 on 2012-03-01\n",
    "    # And to only include the first 20 columns\n",
    "    filtered_df = df.loc['2012-03-01 7:00':'2012-03-01 22:55', df.columns[:20]]\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>773869</th>\n",
       "      <th>767541</th>\n",
       "      <th>767542</th>\n",
       "      <th>717447</th>\n",
       "      <th>717446</th>\n",
       "      <th>717445</th>\n",
       "      <th>773062</th>\n",
       "      <th>767620</th>\n",
       "      <th>737529</th>\n",
       "      <th>717816</th>\n",
       "      <th>765604</th>\n",
       "      <th>767471</th>\n",
       "      <th>716339</th>\n",
       "      <th>773906</th>\n",
       "      <th>765273</th>\n",
       "      <th>716331</th>\n",
       "      <th>771667</th>\n",
       "      <th>716337</th>\n",
       "      <th>769953</th>\n",
       "      <th>769402</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-03-01 07:00:00</th>\n",
       "      <td>68.250</td>\n",
       "      <td>65.125000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>49.750000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>55.000</td>\n",
       "      <td>13.285714</td>\n",
       "      <td>58.125000</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>66.50</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>52.875000</td>\n",
       "      <td>59.875000</td>\n",
       "      <td>63.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 07:05:00</th>\n",
       "      <td>68.125</td>\n",
       "      <td>65.125000</td>\n",
       "      <td>26.875000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>59.125000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.375</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>20.750</td>\n",
       "      <td>67.25</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>52.875000</td>\n",
       "      <td>63.875000</td>\n",
       "      <td>63.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 07:10:00</th>\n",
       "      <td>69.000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>50.625000</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>57.625000</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.875</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>63.125000</td>\n",
       "      <td>19.375</td>\n",
       "      <td>68.25</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>32.375000</td>\n",
       "      <td>52.875000</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>64.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 07:15:00</th>\n",
       "      <td>69.000</td>\n",
       "      <td>63.555556</td>\n",
       "      <td>28.222222</td>\n",
       "      <td>48.111111</td>\n",
       "      <td>44.888889</td>\n",
       "      <td>57.111111</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>62.111111</td>\n",
       "      <td>58.125</td>\n",
       "      <td>7.111111</td>\n",
       "      <td>62.222222</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>18.125</td>\n",
       "      <td>66.00</td>\n",
       "      <td>6.777778</td>\n",
       "      <td>36.888889</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>51.888889</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>60.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 07:20:00</th>\n",
       "      <td>68.125</td>\n",
       "      <td>64.625000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>45.125000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>55.375000</td>\n",
       "      <td>64.375000</td>\n",
       "      <td>63.375000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.714286</td>\n",
       "      <td>60.375000</td>\n",
       "      <td>61.142857</td>\n",
       "      <td>16.875</td>\n",
       "      <td>64.75</td>\n",
       "      <td>9.875000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>32.875000</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>63.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     773869     767541     767542     717447     717446  \\\n",
       "2012-03-01 07:00:00  68.250  65.125000  31.750000  49.750000  48.500000   \n",
       "2012-03-01 07:05:00  68.125  65.125000  26.875000  51.000000  45.000000   \n",
       "2012-03-01 07:10:00  69.000  64.500000  31.625000  50.625000  39.750000   \n",
       "2012-03-01 07:15:00  69.000  63.555556  28.222222  48.111111  44.888889   \n",
       "2012-03-01 07:20:00  68.125  64.625000  29.250000  45.125000  48.500000   \n",
       "\n",
       "                        717445     773062     767620  737529     717816  \\\n",
       "2012-03-01 07:00:00  58.750000  67.000000  62.500000  55.000  13.285714   \n",
       "2012-03-01 07:05:00  59.125000  64.500000  65.000000  60.375  11.000000   \n",
       "2012-03-01 07:10:00  57.625000  67.750000  62.000000  62.875  11.250000   \n",
       "2012-03-01 07:15:00  57.111111  66.333333  62.111111  58.125   7.111111   \n",
       "2012-03-01 07:20:00  55.375000  64.375000  63.375000   0.000  11.714286   \n",
       "\n",
       "                        765604     767471  716339  773906     765273  \\\n",
       "2012-03-01 07:00:00  58.125000  64.750000  17.000   66.50  10.250000   \n",
       "2012-03-01 07:05:00  62.500000  63.750000  20.750   67.25   7.500000   \n",
       "2012-03-01 07:10:00  62.250000  63.125000  19.375   68.25   8.750000   \n",
       "2012-03-01 07:15:00  62.222222  63.333333  18.125   66.00   6.777778   \n",
       "2012-03-01 07:20:00  60.375000  61.142857  16.875   64.75   9.875000   \n",
       "\n",
       "                        716331     771667     716337     769953     769402  \n",
       "2012-03-01 07:00:00  43.750000  33.000000  52.875000  59.875000  63.875000  \n",
       "2012-03-01 07:05:00  44.500000  33.000000  52.875000  63.875000  63.750000  \n",
       "2012-03-01 07:10:00  40.500000  32.375000  52.875000  59.375000  64.750000  \n",
       "2012-03-01 07:15:00  36.888889  33.666667  51.888889  60.666667  60.666667  \n",
       "2012-03-01 07:20:00  38.000000  32.875000  55.750000  59.750000  63.750000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/METRLA/adj_mx_new.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.14388524, 0.1433578 , ..., 0.        , 0.34449434,\n",
       "        0.27822873],\n",
       "       [0.        , 1.        , 0.92753   , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.97311145, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.12031321,\n",
       "        0.        ],\n",
       "       [0.32921156, 0.        , 0.        , ..., 0.28058538, 1.        ,\n",
       "        0.1591485 ],\n",
       "       [0.        , 0.17780617, 0.        , ..., 0.        , 0.365523  ,\n",
       "        1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx[0] = adj_mx[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sensors = {}\n",
    "\n",
    "# Iterate over the items of the dictionary\n",
    "for sensor_id, index in adj_mx[1].items():\n",
    "    # Check if the index is between 1 and 10 (inclusive)\n",
    "    if 1 <= index <= 20:\n",
    "        # Add the sensor ID and index to the new dictionary\n",
    "        selected_sensors[sensor_id] = index\n",
    "        \n",
    "    # Stop if you already have 10 items\n",
    "    if len(selected_sensors) == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx[1] = selected_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx[2] = adj_mx[2][:20, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.14388524, 0.1433578 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.1516956 , 0.        , 0.        ,\n",
       "       0.2323694 , 0.18220767, 0.        , 0.34543255, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.41736084],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mx[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data'\n",
    "file_name = 'adj_mx_ex.pkl'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the adj_mx to a .pkl file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(adj_mx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_hdf('data/example.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by Step example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Preparation\n",
    "1. If the pretraining stage is not enabled, the output of the encoder is by default a matrix \\[latent_dimension, number_of_sensors\\] with all entries equal to 0. Therefore, to make sure that the input to the downstream model keeps as the original, the encoder output matrix cannot be concatenated with the actual data input, but adding them will have no impact. Therefore, in sucha a case, the parameter is_concat_encoder_model will be set to False anyway.\n",
    "2. set `data` and `scaler` as the global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. set backend devices. Check if the type of GPU, either mps or cuda, is available. Also, another options is to use the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Set the parameters to save the results. The results will be saved in the `save` folder. Each training execution will be in a different directory, named by dataname_datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Read the data file. In this example, the data is the example test data. There are only ten sensors in the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply the scaler to the sensor readings. The data is scaled based on the mean and standard deviation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "P = type('Parameters', (object,), {})()\n",
    "P.dataname = 'EXAMPLE'\n",
    "P.model = 'LSTM'\n",
    "P.seed = 0\n",
    "\n",
    "# Data Split\n",
    "P.t_train = 0.8\n",
    "P.t_val = 0.1\n",
    "P.s_train = 0.6\n",
    "P.s_val = 0.2\n",
    "\n",
    "P.timestep_in = 12\n",
    "P.timestep_out = 12\n",
    "P.n_channel = 1\n",
    "P.batch_size = 64\n",
    "\n",
    "P.lstm_hidden_dim = 128\n",
    "P.lstm_layers = 2\n",
    "P.lstm_dropout = 0.2\n",
    "P.gwnet_is_adp_adj = True\n",
    "P.gwnet_is_SGA = False\n",
    "\n",
    "P.adj_type = 'doubletransition'\n",
    "P.is_cost = False\n",
    "P.cost_kernals = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "P.cost_alpha = 0.5\n",
    "P.cl_temperature = 1\n",
    "P.is_pretrain = True\n",
    "P.is_GCN_encoder = True\n",
    "P.is_GCN_after_CL = False\n",
    "P.augmentation = 'temporal_shifting'\n",
    "P.temporal_shifting_r = 0.8\n",
    "P.encoder_to_model_ratio = 1\n",
    "P.is_concat_encoder_model = True\n",
    "\n",
    "P.learn_rate = 0.001\n",
    "P.pretrain_epoch = 1\n",
    "P.train_epoch = 1\n",
    "P.weight_decay = 0\n",
    "P.is_testunseen = True\n",
    "P.train_model_datasplit = 'A'\n",
    "P.train_encoder_on = 'cpu'\n",
    "\n",
    "P.example_verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the entire training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.dataname == EXAMPLE\n",
      "\n",
      "First row at 10 am: [68.25       65.125      31.75       49.75       48.5        58.75\n",
      " 67.         62.5        55.         13.28571429 58.125      64.75\n",
      " 17.         66.5        10.25       43.75       33.         52.875\n",
      " 59.875      63.875     ]\n",
      "\n",
      "Second row at 10:05: [68.125 65.125 26.875 51.    45.    59.125 64.5   65.    60.375 11.\n",
      " 62.5   63.75  20.75  67.25   7.5   44.5   33.    52.875 63.875 63.75 ]\n",
      "data.shape: (192, 20)\n",
      "\n",
      "First row at 10 am after scaling: [ 0.94965521  0.75991885 -1.26646543 -0.17358402 -0.24947856  0.37285669\n",
      "  0.87376067  0.60054031  0.14517306 -2.38753624  0.33490941  0.73715049\n",
      " -2.16202103  0.84340285 -2.57185156 -0.53787782 -1.19057089  0.01615234\n",
      "  0.44116177  0.68402431]\n",
      "\n",
      "Second row at 10:05 after scaling: [ 0.94206575  0.75991885 -1.56245415 -0.09768948 -0.46198328  0.39562505\n",
      "  0.72197158  0.7523294   0.47151959 -2.52631483  0.60054031  0.67643486\n",
      " -1.9343374   0.88893957 -2.73881955 -0.4923411  -1.19057089  0.01615234\n",
      "  0.68402431  0.67643486]\n",
      "\n",
      "First sensor data: [ 0.94965521  0.94206575  0.99519193  0.99519193  0.94206575  0.99519193\n",
      "  0.99519193  0.90411848  0.95471484  0.94965521  0.8602683   0.97242357\n",
      "  0.83328358  0.87376067  0.77931412  0.88135012  0.87376067  0.81979121\n",
      "  0.83581339  0.83581339  0.94206575  0.77931412  0.86617121  0.90411848\n",
      "  0.8509923   0.86701448  0.81304503  0.75907558  0.82822394  0.83328358\n",
      "  0.79027667  0.80629885  0.71438213  0.75907558  0.64607704  0.73209085\n",
      "  0.7523294   0.69920322  0.54994395  0.67643486  0.52295923  0.5701825\n",
      "  0.69161376  0.72197158  0.69835995  0.69835995  0.64607704  0.6688454\n",
      "  0.78268721  0.65788286  0.63848758  0.79280649  0.82822394  0.69835995\n",
      "  0.6688454   0.54319777  0.73883703  0.7523294   0.69161376  0.64439049\n",
      "  0.60812977  0.69920322  0.78268721  0.84340285  0.70510613  0.74473994\n",
      "  0.80545558  0.80629885  0.63089813  0.83581339  0.84340285  0.72534467\n",
      "  0.84340285  0.74473994  0.75991885  0.72534467  0.84677594  0.73715049\n",
      "  0.69835995  0.63848758  0.72956104  0.70679267  0.79786612  0.82063449\n",
      "  0.81304503  0.8602683   0.73715049  0.81304503  0.86701448  0.79027667\n",
      "  0.82063449  0.76750831  0.84002976  0.82063449  0.8509923   0.75907558\n",
      "  0.79027667  0.7523294   0.81304503  0.78268721  0.84002976  0.86617121\n",
      "  0.88135012  0.80545558  0.87376067  0.86617121  0.89652903  0.82822394\n",
      "  0.79569771  0.84002976  0.91170794  0.89399921  0.84340285  0.84340285\n",
      "  0.79955267  0.65788286  0.87376067  0.84773968  0.78268721  0.72534467\n",
      "  0.69161376  0.83328358  0.71185231  0.66125595  0.4866985   0.32057378\n",
      "  0.55500359  0.71438213  0.6688454  -0.46198328  0.15191924  0.69161376\n",
      "  0.31214105 -0.33380583 -2.40488357 -2.35175739 -2.41162975 -2.60979883\n",
      " -2.40488357 -2.33657848 -2.40488357 -2.22273666 -2.37452575 -2.38464502\n",
      " -2.37789884 -2.2834523  -2.47318865 -2.32139957 -2.12154394 -2.24550503\n",
      " -1.94951631 -1.31959161  0.81304503  0.97495339  0.82822394  0.90074539\n",
      "  0.88135012  0.94796866  1.00278139  0.89652903  0.81979121  0.90411848\n",
      "  0.75991885  1.0179603   0.88725303  0.75991885  0.87376067  0.96820721\n",
      "  0.91929739  0.8602683   0.82822394  0.70028743  0.85858176  0.92773012\n",
      "  0.96483412  0.96483412  0.88725303  0.84340285  0.99519193  0.68402431\n",
      "  0.9344763   0.91170794  0.95471484  0.94206575  0.88050685  0.9344763\n",
      "  0.70173304  0.66462904  0.74473994  0.91929739  0.67137522  0.76750831]\n",
      "\n",
      "Second sensor data: [ 0.75991885  0.75991885  0.72197158  0.66462904  0.72956104  0.74473994\n",
      "  0.70510613  0.84340285  0.77931412  0.79027667  0.82653739  0.77509776\n",
      "  0.73209085  0.8509923   0.77931412  0.79027667  0.82063449  0.84677594\n",
      "  0.76750831  0.80545558  0.72956104  0.76582176  0.79027667  0.79786612\n",
      "  0.82822394  0.77931412  0.75991885  0.73883703  0.65366649  0.74558322\n",
      "  0.67643486  0.81979121  0.83581339  0.84677594  0.8509923   0.75907558\n",
      "  0.76750831  0.77509776  0.71185231  0.67643486  0.70510613  0.85858176\n",
      "  0.76582176  0.84340285  0.7523294   0.81304503  0.75991885  0.76750831\n",
      "  0.61571922  0.83328358  0.85858176  0.38803559  0.80545558  0.81304503\n",
      "  0.63848758  0.78606031  0.81979121  0.80437137  0.79027667  0.78606031\n",
      "  0.81304503  0.79786612  0.76750831  0.72956104  0.86701448  0.82822394\n",
      "  0.69920322  0.81304503  0.75991885  0.75991885  0.85858176  0.75907558\n",
      "  0.75991885  0.6688454   0.61571922  0.66462904  0.80629885  0.66125595\n",
      "  0.79955267  0.82822394  0.72197158  0.85858176  0.78268721  0.76750831\n",
      "  0.72630841  0.84677594  0.83581339  0.81304503  0.80629885  0.84340285\n",
      "  0.82063449  0.70679267  0.82653739  0.85858176  0.78268721  0.79280649\n",
      "  0.77509776  0.7523294   0.76750831  0.44116177  0.80629885  0.88135012\n",
      "  0.77509776  0.75991885  0.79280649  0.66125595  0.69161376  0.67643486\n",
      "  0.83906602  0.73209085  0.65366649  0.69161376  0.54741413  0.47910905\n",
      "  0.5701825   0.25311196  0.66125595  0.53548785  0.60812977  0.18565015\n",
      "  0.45634068  0.61740577  0.4959745   0.42598287  0.57777195  0.46224359\n",
      "  0.4866985   0.33490941  0.21347815  0.45634068  0.30033523  0.35008832\n",
      "  0.37285669  0.2396196   0.25142542  0.04651015 -0.03022766 -0.1432262\n",
      " -0.3810291   0.06168906  0.29696214  0.07686797 -0.21153129 -0.05046621\n",
      "  0.3475585   0.41080396  0.44116177  0.55500359  0.63764431  0.66125595\n",
      "  0.64607704  0.61571922  0.60054031  0.59042104  0.70679267  0.78606031\n",
      "  0.83581339  0.73209085  0.69920322  0.7523294   0.81304503  0.81304503\n",
      "  0.79786612  0.7523294   0.82653739  0.82063449  0.26660433  0.89399921\n",
      "  0.80545558  0.77931412  0.81304503  0.37285669  0.18312033  0.88725303\n",
      "  0.7523294   0.86617121  0.75907558  0.69161376  0.75991885  0.86617121\n",
      "  0.74558322  0.87376067  0.81304503  0.86617121  0.81979121  0.7523294\n",
      "  0.89399921  0.94796866  0.79786612  0.82822394  0.88050685  0.81304503]\n",
      "\n",
      "trainXS.shape (149, 1, 20, 12)\n",
      "trainYS.shape (149, 12, 20, 1)\n",
      "testXS.shape (9, 1, 20, 12)\n",
      "testYS.shape (9, 12, 20, 1)\n",
      "\n",
      "First instance trainXS for first sensor: [0.94965521 0.94206575 0.99519193 0.99519193 0.94206575 0.99519193\n",
      " 0.99519193 0.90411848 0.95471484 0.94965521 0.8602683  0.97242357]\n",
      "\n",
      "First instance trainYS for first sensor: [0.83328358 0.87376067 0.77931412 0.88135012 0.87376067 0.81979121\n",
      " 0.83581339 0.83581339 0.94206575 0.77931412 0.86617121 0.90411848]\n",
      "\n",
      "Last instance trainXS for first sensor: [-2.12154394 -2.24550503 -1.94951631 -1.31959161  0.81304503  0.97495339\n",
      "  0.82822394  0.90074539  0.88135012  0.94796866  1.00278139  0.89652903]\n",
      "\n",
      "First instance testXS for first sensor: [0.81979121 0.90411848 0.75991885 1.0179603  0.88725303 0.75991885\n",
      " 0.87376067 0.96820721 0.91929739 0.8602683  0.82822394 0.70028743]\n",
      "\n",
      "First instance trainXS for second sensor: [0.75991885 0.75991885 0.72197158 0.66462904 0.72956104 0.74473994\n",
      " 0.70510613 0.84340285 0.77931412 0.79027667 0.82653739 0.77509776]\n",
      "\n",
      "First instance trainYS for second sensor: [0.73209085 0.8509923  0.77931412 0.79027667 0.82063449 0.84677594\n",
      " 0.76750831 0.80545558 0.72956104 0.76582176 0.79027667 0.79786612]\n",
      "\n",
      "spatialSplit_unseen all: trn/val/tst : 20 : 12 / 4 / 4\n",
      "spatialSplit_allNod all: trn/val/tst : 20 : 12 / 16 / 20\n",
      "\n",
      "spatialSplit_unseen.i_trn [18  1 19  8 10 17  6 13  4  2  5 14]\n",
      "spatialSplit_unseen.i_val [ 9  7 16 11]\n",
      "spatialSplit_unseen.i_tst [ 3  0 15 12]\n",
      "spatialSplit_allNod.i_trn [18  1 19  8 10 17  6 13  4  2  5 14]\n",
      "spatialSplit_allNod.i_val [18  1 19  8 10 17  6 13  4  2  5 14  9  7 16 11]\n",
      "spatialSplit_allNod.i_tst [18  1 19  8 10 17  6 13  4  2  5 14  9  7 16 11  3  0 15 12]\n",
      "\n",
      "train.shape torch.Size([132, 1, 12, 12]) torch.Size([132, 12, 12, 1])\n",
      "train_model.shape torch.Size([17, 1, 12, 12]) torch.Size([17, 12, 12, 1])\n",
      "val_u.shape torch.Size([17, 1, 4, 12]) torch.Size([17, 12, 4, 1])\n",
      "val_a.shape torch.Size([17, 1, 16, 12]) torch.Size([17, 12, 16, 1])\n",
      "tst_u.shape torch.Size([9, 1, 4, 12]) torch.Size([9, 12, 4, 1])\n",
      "tst_a.shape torch.Size([9, 1, 20, 12]) torch.Size([9, 12, 20, 1])\n",
      "\n",
      "For veryfication purposes\n",
      "Corresponding first sensor in org order in test tensor([0.8198, 0.9041, 0.7599, 1.0180, 0.8873, 0.7599, 0.8738, 0.9682, 0.9193,\n",
      "        0.8603, 0.8282, 0.7003])\n",
      "Corresponding second sensor in org order in train tensor([0.7599, 0.7599, 0.7220, 0.6646, 0.7296, 0.7447, 0.7051, 0.8434, 0.7793,\n",
      "        0.7903, 0.8265, 0.7751])\n",
      "\n",
      "adjacency matrix after normalization\n",
      "Entry (18,1): 0.0\n",
      "Entry (7,11): 0.20829022\n",
      "Entry (19,10): 0.42182183\n",
      "\n",
      "adj_train length of 2 torch.Size([12, 12])\n",
      "adj_val_u length of 2 torch.Size([4, 4])\n",
      "adj_val_a length of 2 torch.Size([16, 16])\n",
      "adj_tst_u length of 2 torch.Size([4, 4])\n",
      "adj_tst_a length of 2 torch.Size([20, 20])\n",
      "\n",
      "For veryfication purposes\n",
      "Corresponding Entry (18,1) tensor(0., device='mps:0')\n",
      "Corresponding Entry (7,11) tensor(0.2083, device='mps:0')\n",
      "Corresponding Entry (19,10) tensor(0.4218, device='mps:0')\n",
      "\n",
      "adjacency matrix after normalization\n",
      "train adj tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1862, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0658, 0.0312, 0.0374, 0.0677,\n",
      "         0.1968, 0.0391, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.4218, 0.1167, 0.0000, 0.0000, 0.1253,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.5814],\n",
      "        [0.0000, 0.0000, 0.3499, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0552, 0.0856, 0.0000, 0.0000, 1.0000, 0.0864, 0.0195, 0.1429,\n",
      "         0.0286, 0.0641, 0.0000],\n",
      "        [0.0000, 0.0738, 0.0000, 0.0000, 0.0000, 0.1071, 1.0000, 0.0000, 0.0988,\n",
      "         0.0349, 0.1714, 0.0000],\n",
      "        [0.0000, 0.1248, 0.4118, 0.0000, 0.4634, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0743, 0.0365, 0.0000, 0.0000, 0.1203, 0.1121, 0.0000, 1.0000,\n",
      "         0.0455, 0.0957, 0.0000],\n",
      "        [0.0000, 0.1584, 0.0000, 0.0000, 0.0000, 0.0847, 0.0475, 0.0460, 0.0866,\n",
      "         1.0000, 0.0568, 0.0000],\n",
      "        [0.0000, 0.0743, 0.0389, 0.0000, 0.0000, 0.1182, 0.0968, 0.0155, 0.1159,\n",
      "         0.0463, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2433, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000]], device='mps:0')\n",
      "val_u adj tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0448, 0.2083],\n",
      "        [0.0000, 0.0619, 1.0000, 0.0197],\n",
      "        [0.0000, 0.2109, 0.0408, 1.0000]], device='mps:0')\n",
      "val_a adj tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1862, 0.0000, 0.0000, 0.0000, 0.1968, 0.0000, 0.6170],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0658, 0.0312, 0.0374, 0.0677,\n",
      "         0.1968, 0.0391, 0.0000, 0.0000, 0.1967, 0.0616, 0.1214],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.4218, 0.1167, 0.0000, 0.0000, 0.1253,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.5814, 0.4186, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3499, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3609, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0552, 0.0856, 0.0000, 0.0000, 1.0000, 0.0864, 0.0195, 0.1429,\n",
      "         0.0286, 0.0641, 0.0000, 0.0000, 0.0285, 0.0847, 0.0000],\n",
      "        [0.0000, 0.0738, 0.0000, 0.0000, 0.0000, 0.1071, 1.0000, 0.0000, 0.0988,\n",
      "         0.0349, 0.1714, 0.0000, 0.0000, 0.0348, 0.1540, 0.0000],\n",
      "        [0.0000, 0.1248, 0.4118, 0.0000, 0.4634, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0743, 0.0365, 0.0000, 0.0000, 0.1203, 0.1121, 0.0000, 1.0000,\n",
      "         0.0455, 0.0957, 0.0000, 0.0000, 0.0454, 0.1110, 0.0137],\n",
      "        [0.0000, 0.1584, 0.0000, 0.0000, 0.0000, 0.0847, 0.0475, 0.0460, 0.0866,\n",
      "         1.0000, 0.0568, 0.0000, 0.0000, 0.1341, 0.0807, 0.0709],\n",
      "        [0.0000, 0.0743, 0.0389, 0.0000, 0.0000, 0.1182, 0.0968, 0.0155, 0.1159,\n",
      "         0.0463, 1.0000, 0.0000, 0.0000, 0.0462, 0.0956, 0.0144],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2433, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.6707, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2798, 0.2345, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4857, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0435, 0.1697, 0.0000, 0.0000, 0.0000, 0.0484, 0.0000, 0.0879, 0.0501,\n",
      "         0.2049, 0.0262, 0.0000, 0.0000, 1.0000, 0.0448, 0.2083],\n",
      "        [0.0000, 0.0981, 0.0000, 0.0000, 0.0000, 0.0993, 0.1215, 0.0215, 0.0942,\n",
      "         0.0620, 0.1317, 0.0000, 0.0000, 0.0619, 1.0000, 0.0197],\n",
      "        [0.0592, 0.1675, 0.0000, 0.0000, 0.0000, 0.0442, 0.0000, 0.1180, 0.0459,\n",
      "         0.2063, 0.0000, 0.0000, 0.0000, 0.2109, 0.0408, 1.0000]],\n",
      "       device='mps:0')\n",
      "tst_u adj tensor([[1.0000, 0.0000, 0.1292, 0.1079],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [0.1312, 0.0000, 1.0000, 0.0570],\n",
      "        [0.1197, 0.0000, 0.1376, 1.0000]], device='mps:0')\n",
      "tst_a adj tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1862, 0.0000, 0.0000, 0.0000, 0.1968, 0.0000, 0.6170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0658, 0.0312, 0.0374, 0.0677,\n",
      "         0.1968, 0.0391, 0.0000, 0.0000, 0.1967, 0.0616, 0.1214, 0.0717, 0.0000,\n",
      "         0.0814, 0.0291],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.4218, 0.1167, 0.0000, 0.0000, 0.1253,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1136, 0.2225],\n",
      "        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.5814, 0.4186, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3499, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3609, 0.0000, 0.0000, 0.0000, 0.0000, 0.2893,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0552, 0.0856, 0.0000, 0.0000, 1.0000, 0.0864, 0.0195, 0.1429,\n",
      "         0.0286, 0.0641, 0.0000, 0.0000, 0.0285, 0.0847, 0.0000, 0.1123, 0.0000,\n",
      "         0.1383, 0.1539],\n",
      "        [0.0000, 0.0738, 0.0000, 0.0000, 0.0000, 0.1071, 1.0000, 0.0000, 0.0988,\n",
      "         0.0349, 0.1714, 0.0000, 0.0000, 0.0348, 0.1540, 0.0000, 0.1456, 0.0000,\n",
      "         0.1317, 0.0478],\n",
      "        [0.0000, 0.1248, 0.4118, 0.0000, 0.4634, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0743, 0.0365, 0.0000, 0.0000, 0.1203, 0.1121, 0.0000, 1.0000,\n",
      "         0.0455, 0.0957, 0.0000, 0.0000, 0.0454, 0.1110, 0.0137, 0.1252, 0.0000,\n",
      "         0.1315, 0.0888],\n",
      "        [0.0000, 0.1584, 0.0000, 0.0000, 0.0000, 0.0847, 0.0475, 0.0460, 0.0866,\n",
      "         1.0000, 0.0568, 0.0000, 0.0000, 0.1341, 0.0807, 0.0709, 0.0904, 0.0000,\n",
      "         0.0991, 0.0448],\n",
      "        [0.0000, 0.0743, 0.0389, 0.0000, 0.0000, 0.1182, 0.0968, 0.0155, 0.1159,\n",
      "         0.0463, 1.0000, 0.0000, 0.0000, 0.0462, 0.0956, 0.0144, 0.1247, 0.0000,\n",
      "         0.1231, 0.0902],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2433, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.6707, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2798, 0.2345, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4857, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0435, 0.1697, 0.0000, 0.0000, 0.0000, 0.0484, 0.0000, 0.0879, 0.0501,\n",
      "         0.2049, 0.0262, 0.0000, 0.0000, 1.0000, 0.0448, 0.2083, 0.0537, 0.0000,\n",
      "         0.0626, 0.0000],\n",
      "        [0.0000, 0.0981, 0.0000, 0.0000, 0.0000, 0.0993, 0.1215, 0.0215, 0.0942,\n",
      "         0.0620, 0.1317, 0.0000, 0.0000, 0.0619, 1.0000, 0.0197, 0.1201, 0.0000,\n",
      "         0.1132, 0.0568],\n",
      "        [0.0592, 0.1675, 0.0000, 0.0000, 0.0000, 0.0442, 0.0000, 0.1180, 0.0459,\n",
      "         0.2063, 0.0000, 0.0000, 0.0000, 0.2109, 0.0408, 1.0000, 0.0493, 0.0000,\n",
      "         0.0580, 0.0000],\n",
      "        [0.0000, 0.0749, 0.0513, 0.0000, 0.0000, 0.1330, 0.0957, 0.0147, 0.1313,\n",
      "         0.0455, 0.0767, 0.0000, 0.0000, 0.0454, 0.0944, 0.0000, 1.0000, 0.0000,\n",
      "         0.1292, 0.1079],\n",
      "        [0.0000, 0.0890, 0.2582, 0.0000, 0.1438, 0.0000, 0.0000, 0.2137, 0.0000,\n",
      "         0.0887, 0.0000, 0.0000, 0.0000, 0.0939, 0.0000, 0.1127, 0.0000, 1.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0608, 0.0000, 0.0000, 0.0000, 0.1056, 0.1694, 0.0000, 0.0995,\n",
      "         0.0312, 0.1463, 0.0000, 0.0000, 0.0312, 0.1679, 0.0000, 0.1312, 0.0000,\n",
      "         1.0000, 0.0570],\n",
      "        [0.0000, 0.0686, 0.0442, 0.0000, 0.0000, 0.1384, 0.0984, 0.0000, 0.1403,\n",
      "         0.0393, 0.0776, 0.0000, 0.0000, 0.0392, 0.0968, 0.0000, 0.1197, 0.0000,\n",
      "         0.1376, 1.0000]], device='mps:0')\n",
      "\n",
      "pretrn_iter.dataset.tensors[0].shape torch.Size([12, 132])\n",
      "preval_iter.dataset.tensors[0].shape torch.Size([16, 132])\n",
      "\n",
      "For veryfication purposes\n",
      "Corresponding second instance pretrn_iter tensor([0.7599, 0.7599, 0.7220, 0.6646, 0.7296, 0.7447, 0.7051, 0.8434, 0.7793,\n",
      "        0.7903, 0.8265, 0.7751, 0.7321, 0.8510, 0.7793, 0.7903, 0.8206, 0.8468,\n",
      "        0.7675, 0.8055, 0.7296, 0.7658, 0.7903, 0.7979, 0.8282, 0.7793, 0.7599,\n",
      "        0.7388, 0.6537, 0.7456, 0.6764, 0.8198, 0.8358, 0.8468, 0.8510, 0.7591,\n",
      "        0.7675, 0.7751, 0.7119, 0.6764, 0.7051, 0.8586, 0.7658, 0.8434, 0.7523,\n",
      "        0.8130, 0.7599, 0.7675, 0.6157, 0.8333, 0.8586, 0.3880, 0.8055, 0.8130,\n",
      "        0.6385, 0.7861, 0.8198, 0.8044, 0.7903, 0.7861, 0.8130, 0.7979, 0.7675,\n",
      "        0.7296, 0.8670, 0.8282, 0.6992, 0.8130, 0.7599, 0.7599, 0.8586, 0.7591,\n",
      "        0.7599, 0.6688, 0.6157, 0.6646, 0.8063, 0.6613, 0.7996, 0.8282, 0.7220,\n",
      "        0.8586, 0.7827, 0.7675, 0.7263, 0.8468, 0.8358, 0.8130, 0.8063, 0.8434,\n",
      "        0.8206, 0.7068, 0.8265, 0.8586, 0.7827, 0.7928, 0.7751, 0.7523, 0.7675,\n",
      "        0.4412, 0.8063, 0.8814, 0.7751, 0.7599, 0.7928, 0.6613, 0.6916, 0.6764,\n",
      "        0.8391, 0.7321, 0.6537, 0.6916, 0.5474, 0.4791, 0.5702, 0.2531, 0.6613,\n",
      "        0.5355, 0.6081, 0.1857, 0.4563, 0.6174, 0.4960, 0.4260, 0.5778, 0.4622,\n",
      "        0.4867, 0.3349, 0.2135, 0.4563, 0.3003, 0.3501])\n",
      "Corresponding second instance preval_iter tensor([0.7599, 0.7599, 0.7220, 0.6646, 0.7296, 0.7447, 0.7051, 0.8434, 0.7793,\n",
      "        0.7903, 0.8265, 0.7751, 0.7321, 0.8510, 0.7793, 0.7903, 0.8206, 0.8468,\n",
      "        0.7675, 0.8055, 0.7296, 0.7658, 0.7903, 0.7979, 0.8282, 0.7793, 0.7599,\n",
      "        0.7388, 0.6537, 0.7456, 0.6764, 0.8198, 0.8358, 0.8468, 0.8510, 0.7591,\n",
      "        0.7675, 0.7751, 0.7119, 0.6764, 0.7051, 0.8586, 0.7658, 0.8434, 0.7523,\n",
      "        0.8130, 0.7599, 0.7675, 0.6157, 0.8333, 0.8586, 0.3880, 0.8055, 0.8130,\n",
      "        0.6385, 0.7861, 0.8198, 0.8044, 0.7903, 0.7861, 0.8130, 0.7979, 0.7675,\n",
      "        0.7296, 0.8670, 0.8282, 0.6992, 0.8130, 0.7599, 0.7599, 0.8586, 0.7591,\n",
      "        0.7599, 0.6688, 0.6157, 0.6646, 0.8063, 0.6613, 0.7996, 0.8282, 0.7220,\n",
      "        0.8586, 0.7827, 0.7675, 0.7263, 0.8468, 0.8358, 0.8130, 0.8063, 0.8434,\n",
      "        0.8206, 0.7068, 0.8265, 0.8586, 0.7827, 0.7928, 0.7751, 0.7523, 0.7675,\n",
      "        0.4412, 0.8063, 0.8814, 0.7751, 0.7599, 0.7928, 0.6613, 0.6916, 0.6764,\n",
      "        0.8391, 0.7321, 0.6537, 0.6916, 0.5474, 0.4791, 0.5702, 0.2531, 0.6613,\n",
      "        0.5355, 0.6081, 0.1857, 0.4563, 0.6174, 0.4960, 0.4260, 0.5778, 0.4622,\n",
      "        0.4867, 0.3349, 0.2135, 0.4563, 0.3003, 0.3501])\n",
      "\n",
      "pretrainModel Started ...\n",
      "\n",
      "For veryfication purposes\n",
      "adj_train for second sensor in original order tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0658, 0.0312, 0.0374, 0.0677,\n",
      "        0.1968, 0.0391, 0.0000])\n",
      "adj_val for second sensor in original order tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0658, 0.0312, 0.0374, 0.0677,\n",
      "        0.1968, 0.0391, 0.0000, 0.0000, 0.1967, 0.0616, 0.1214])\n",
      "there are  2 adjacency matrices in adj_train\n",
      "\n",
      "For pretraining, training dataset:\n",
      "x[0].shape torch.Size([12, 132])\n",
      "x[0] for second sensor in original order tensor([0.7599, 0.7599, 0.7220, 0.6646, 0.7296, 0.7447, 0.7051, 0.8434, 0.7793,\n",
      "        0.7903, 0.8265, 0.7751, 0.7321, 0.8510, 0.7793, 0.7903, 0.8206, 0.8468,\n",
      "        0.7675, 0.8055, 0.7296, 0.7658, 0.7903, 0.7979, 0.8282, 0.7793, 0.7599,\n",
      "        0.7388, 0.6537, 0.7456, 0.6764, 0.8198, 0.8358, 0.8468, 0.8510, 0.7591,\n",
      "        0.7675, 0.7751, 0.7119, 0.6764, 0.7051, 0.8586, 0.7658, 0.8434, 0.7523,\n",
      "        0.8130, 0.7599, 0.7675, 0.6157, 0.8333, 0.8586, 0.3880, 0.8055, 0.8130,\n",
      "        0.6385, 0.7861, 0.8198, 0.8044, 0.7903, 0.7861, 0.8130, 0.7979, 0.7675,\n",
      "        0.7296, 0.8670, 0.8282, 0.6992, 0.8130, 0.7599, 0.7599, 0.8586, 0.7591,\n",
      "        0.7599, 0.6688, 0.6157, 0.6646, 0.8063, 0.6613, 0.7996, 0.8282, 0.7220,\n",
      "        0.8586, 0.7827, 0.7675, 0.7263, 0.8468, 0.8358, 0.8130, 0.8063, 0.8434,\n",
      "        0.8206, 0.7068, 0.8265, 0.8586, 0.7827, 0.7928, 0.7751, 0.7523, 0.7675,\n",
      "        0.4412, 0.8063, 0.8814, 0.7751, 0.7599, 0.7928, 0.6613, 0.6916, 0.6764,\n",
      "        0.8391, 0.7321, 0.6537, 0.6916, 0.5474, 0.4791, 0.5702, 0.2531, 0.6613,\n",
      "        0.5355, 0.6081, 0.1857, 0.4563, 0.6174, 0.4960, 0.4260, 0.5778, 0.4622,\n",
      "        0.4867, 0.3349, 0.2135, 0.4563, 0.3003, 0.3501])\n",
      "\n",
      "the first augmentated input tensor([0.7599, 0.7583, 0.7196, 0.6673, 0.7302, 0.7431, 0.7109, 0.8407, 0.7798,\n",
      "        0.7918, 0.8244, 0.7733, 0.7370, 0.8480, 0.7798, 0.7915, 0.8217, 0.8435,\n",
      "        0.7691, 0.8023, 0.7311, 0.7668, 0.7906, 0.7991, 0.8262, 0.7785, 0.7590,\n",
      "        0.7353, 0.6575, 0.7427, 0.6824, 0.8205, 0.8363, 0.8470, 0.8472, 0.7594,\n",
      "        0.7678, 0.7725, 0.7104, 0.6776, 0.7115, 0.8547, 0.7691, 0.8396, 0.7549,\n",
      "        0.8108, 0.7602, 0.7612, 0.6248, 0.8343, 0.8390, 0.4054, 0.8058, 0.8058,\n",
      "        0.6446, 0.7875, 0.8191, 0.8038, 0.7901, 0.7872, 0.8124, 0.7966, 0.7659,\n",
      "        0.7353, 0.8654, 0.8228, 0.7039, 0.8108, 0.7599, 0.7640, 0.8544, 0.7591,\n",
      "        0.7561, 0.6666, 0.6178, 0.6705, 0.8003, 0.6670, 0.8007, 0.8238, 0.7277,\n",
      "        0.8554, 0.7821, 0.7658, 0.7313, 0.8463, 0.8349, 0.8128, 0.8078, 0.8425,\n",
      "        0.8159, 0.7118, 0.8279, 0.8554, 0.7831, 0.7921, 0.7741, 0.7530, 0.7539,\n",
      "        0.4564, 0.8094, 0.8769, 0.7745, 0.7613, 0.7873, 0.6625, 0.6910, 0.6832,\n",
      "        0.8346, 0.7288, 0.6552, 0.6856, 0.5446, 0.4829, 0.5570, 0.2701, 0.6560,\n",
      "        0.5385, 0.5905, 0.1969, 0.4630, 0.6123, 0.4931, 0.4323, 0.5730, 0.4633,\n",
      "        0.4804, 0.3299, 0.2236, 0.4498, 0.3024, 0.3024])\n",
      "the second augmentated input tensor([0.7599, 0.7563, 0.7166, 0.6707, 0.7310, 0.7410, 0.7181, 0.8374, 0.7803,\n",
      "        0.7937, 0.8217, 0.7710, 0.7433, 0.8442, 0.7803, 0.7931, 0.8231, 0.8393,\n",
      "        0.7711, 0.7983, 0.7330, 0.7681, 0.7910, 0.8007, 0.8236, 0.7775, 0.7579,\n",
      "        0.7308, 0.6623, 0.7391, 0.6899, 0.8213, 0.8368, 0.8472, 0.8423, 0.7599,\n",
      "        0.7682, 0.7691, 0.7085, 0.6791, 0.7196, 0.8498, 0.7731, 0.8348, 0.7581,\n",
      "        0.8080, 0.7606, 0.7532, 0.6362, 0.8357, 0.8142, 0.4274, 0.8062, 0.7966,\n",
      "        0.6524, 0.7892, 0.8183, 0.8030, 0.7899, 0.7886, 0.8116, 0.7950, 0.7639,\n",
      "        0.7425, 0.8634, 0.8161, 0.7099, 0.8080, 0.7599, 0.7692, 0.8492, 0.7592,\n",
      "        0.7513, 0.6638, 0.6203, 0.6780, 0.7926, 0.6743, 0.8023, 0.8182, 0.7348,\n",
      "        0.8514, 0.7813, 0.7636, 0.7377, 0.8457, 0.8337, 0.8124, 0.8098, 0.8413,\n",
      "        0.8099, 0.7181, 0.8296, 0.8514, 0.7836, 0.7911, 0.7730, 0.7538, 0.7368,\n",
      "        0.4756, 0.8134, 0.8713, 0.7737, 0.7630, 0.7804, 0.6641, 0.6902, 0.6918,\n",
      "        0.8290, 0.7247, 0.6572, 0.6780, 0.5410, 0.4877, 0.5403, 0.2916, 0.6494,\n",
      "        0.5423, 0.5683, 0.2112, 0.4715, 0.6060, 0.4894, 0.4403, 0.5669, 0.4645,\n",
      "        0.4724, 0.3235, 0.2364, 0.4416, 0.3050, 0.3050])\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([12, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([12, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "the data shape before loss calculation:\n",
      "x1.shape torch.Size([12, 32])\n",
      "x2.shape torch.Size([12, 32])\n",
      "\n",
      "The validation for encoder starts at index 12\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([16, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([16, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "the data shape before loss calculation:\n",
      "x1.shape torch.Size([4, 32])\n",
      "x2.shape torch.Size([4, 32])\n",
      "epoch 0 time used: 0  seconds  train loss: tensor(2.2672, grad_fn=<NegBackward0>) validation loss: tensor(1.8100)\n",
      "PRETIME DURATION: 0:00:00.024458\n",
      "pretrainModel Ended ...\n",
      "\n",
      "\n",
      "trainModel Started ...\n",
      "TIMESTEP_IN, TIMESTEP_OUT 12 12\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of adj_train torch.Size([12, 12])\n",
      "The shape of adj_val_u torch.Size([4, 4])\n",
      "The shape of adj_val_a torch.Size([16, 16])\n",
      "\n",
      "The shape of train_encoder_input torch.Size([12, 132])\n",
      "The shape of val_u_encoder_input torch.Size([4, 132])\n",
      "The shape of val_a_encoder_input torch.Size([16, 132])\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([12, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([4, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([16, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "ENCODER INFER DURATION IN MODEL TRAINING: 0:00:00.011159\n",
      "train_embed torch.Size([32, 12]) tensor(-0.0063, device='mps:0') tensor(0.0823, device='mps:0')\n",
      "val_u_embed torch.Size([32, 4]) tensor(-0.0106, device='mps:0') tensor(0.0911, device='mps:0')\n",
      "val_a_embed torch.Size([32, 16]) tensor(-0.0116, device='mps:0') tensor(0.0941, device='mps:0')\n",
      "\n",
      "For verification purposes\n",
      "The shape of model_input torch.Size([132, 1, 12, 12])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 64])\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "The corresponding second instance of y_pred tensor([-0.0810, -0.1490,  0.0825,  0.0300,  0.0638,  0.1379, -0.1175,  0.0731,\n",
      "        -0.0822, -0.0136,  0.0693, -0.0688], device='mps:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "The corresponding second instance of y tensor([0.7321, 0.8510, 0.7793, 0.7903, 0.8206, 0.8468, 0.7675, 0.8055, 0.7296,\n",
      "        0.7658, 0.7903, 0.7979])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 64])\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "The corresponding second instance of y_pred tensor([-0.0267, -0.0410,  0.1036,  0.1578,  0.0979,  0.2042,  0.0298,  0.1961,\n",
      "         0.0761,  0.0770,  0.1910, -0.0020], device='mps:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "The corresponding second instance of y tensor([0.8063, 0.6613, 0.7996, 0.8282, 0.7220, 0.8586, 0.7827, 0.7675, 0.7263,\n",
      "        0.8468, 0.8358, 0.8130])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([4, 12, 12, 64])\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of y_pred torch.Size([4, 12, 12, 1])\n",
      "The shape of y torch.Size([4, 12, 12, 1])\n",
      "The corresponding second instance of y_pred tensor([-0.0330,  0.0794,  0.1279,  0.2004,  0.1344,  0.1437,  0.1335,  0.2090,\n",
      "         0.1572,  0.1512,  0.2328,  0.0655], device='mps:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "The corresponding second instance of y tensor([ 0.2970,  0.0769, -0.2115, -0.0505,  0.3476,  0.4108,  0.4412,  0.5550,\n",
      "         0.6376,  0.6613,  0.6461,  0.6157])\n",
      "\n",
      "The validation for model training starts at index 12\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([17, 4, 12, 64])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([17, 12, 4, 1])\n",
      "The shape of y torch.Size([17, 12, 4, 1])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([17, 16, 12, 64])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([17, 12, 4, 1])\n",
      "The shape of y torch.Size([17, 12, 4, 1])\n",
      "epoch 0 time used: 1  seconds  train loss: 0.6583450292095994 validation unseen nodes loss: 0.8681050539016724 validation all nodes loss: 0.8677999973297119\n",
      "MODEL TRAINING DURATION: 0:00:01.208488\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 64])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 64])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([4, 12, 12, 64])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([4, 12, 12, 1])\n",
      "The shape of y torch.Size([4, 12, 12, 1])\n",
      "trainModel Ended ...\n",
      "\n",
      "Model Testing test_a Started ...\n",
      "Model Infer Start ...\n",
      "\n",
      "The shape of tst_encoder_input torch.Size([20, 132])\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([20, 32, 10])\n",
      "GCN is enabled\n",
      "ENCODER INFER DURATION: 0:00:00.006538\n",
      "\n",
      "The inference for model starts at index 16\n",
      "\n",
      "MODEL INFER START ...\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([9, 20, 12, 64])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([9, 12, 4, 1])\n",
      "The shape of y torch.Size([9, 12, 4, 1])\n",
      "Model Infer End ... 2024-04-25 16:04:09.438183\n",
      "MODEL INFER DURATION: 0:00:00.037145\n",
      "YS.shape, YS_pred.shape, (9, 12, 4, 1) (9, 12, 4, 1)\n",
      "****************************************\n",
      "LSTM, test_a, Torch MSE, 5.3207093477e-01, 0.5320709348\n",
      "all pred steps, LSTM, test_a, MSE, RMSE, MAE, MAPE, 94.7131042480, 9.7320661545, 8.7633285522, 13.5688364506\n",
      "1 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 132.7569732666, 11.5220212936, 10.5589637756, 16.4532497525\n",
      "2 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 107.3859481812, 10.3627195358, 9.2498207092, 14.3052086234\n",
      "3 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 85.2503814697, 9.2331132889, 8.0405511856, 12.3570099473\n",
      "4 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 82.7712326050, 9.0978698730, 7.9561529160, 12.2214078903\n",
      "5 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 82.6289825439, 9.0900487900, 7.9514288902, 12.2505225241\n",
      "6 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 85.3382644653, 9.2378711700, 8.2290143967, 12.6773536205\n",
      "7 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 112.5978927612, 10.6112155914, 9.7704477310, 15.1629373431\n",
      "8 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 67.9483184814, 8.2430772781, 7.3915166855, 11.4603906870\n",
      "9 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 93.2726058960, 9.6577739716, 8.9334983826, 13.8726949692\n",
      "10 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 100.6059265137, 10.0302505493, 9.2762565613, 14.3876343966\n",
      "11 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 71.3471755981, 8.4467258453, 7.7547540665, 12.0361000299\n",
      "12 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 114.6536483765, 10.7076444626, 10.0475282669, 15.6415283680\n",
      "Model Testing Ended ... Thu Apr 25 16:04:09 2024\n"
     ]
    }
   ],
   "source": [
    "%run -i 'experiment.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
