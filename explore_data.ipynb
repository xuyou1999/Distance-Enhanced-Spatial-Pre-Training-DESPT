{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from itertools import permutations\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METR-LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>773869</th>\n",
       "      <th>767541</th>\n",
       "      <th>767542</th>\n",
       "      <th>717447</th>\n",
       "      <th>717446</th>\n",
       "      <th>717445</th>\n",
       "      <th>773062</th>\n",
       "      <th>767620</th>\n",
       "      <th>737529</th>\n",
       "      <th>717816</th>\n",
       "      <th>...</th>\n",
       "      <th>772167</th>\n",
       "      <th>769372</th>\n",
       "      <th>774204</th>\n",
       "      <th>769806</th>\n",
       "      <th>717590</th>\n",
       "      <th>717592</th>\n",
       "      <th>717595</th>\n",
       "      <th>772168</th>\n",
       "      <th>718141</th>\n",
       "      <th>769373</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:00:00</th>\n",
       "      <td>64.375000</td>\n",
       "      <td>67.625000</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>66.875000</td>\n",
       "      <td>68.750000</td>\n",
       "      <td>65.125</td>\n",
       "      <td>67.125</td>\n",
       "      <td>59.625000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.625000</td>\n",
       "      <td>65.500</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>66.428571</td>\n",
       "      <td>66.875</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>61.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:05:00</th>\n",
       "      <td>62.666667</td>\n",
       "      <td>68.555556</td>\n",
       "      <td>65.444444</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>64.444444</td>\n",
       "      <td>68.111111</td>\n",
       "      <td>65.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>57.444444</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>69.875</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>58.555556</td>\n",
       "      <td>62.000</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>64.444444</td>\n",
       "      <td>55.888889</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>62.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:10:00</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>64.500</td>\n",
       "      <td>64.250</td>\n",
       "      <td>63.875000</td>\n",
       "      <td>65.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>68.125</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>61.375000</td>\n",
       "      <td>69.857143</td>\n",
       "      <td>62.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:15:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:20:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        773869     767541     767542     717447     717446  \\\n",
       "2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n",
       "2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  64.444444   \n",
       "2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
       "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "                        717445  773062  767620     737529     717816  ...  \\\n",
       "2012-03-01 00:00:00  68.750000  65.125  67.125  59.625000  62.750000  ...   \n",
       "2012-03-01 00:05:00  68.111111  65.000  65.000  57.444444  63.333333  ...   \n",
       "2012-03-01 00:10:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n",
       "2012-03-01 00:15:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
       "2012-03-01 00:20:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
       "\n",
       "                        772167  769372     774204     769806  717590  \\\n",
       "2012-03-01 00:00:00  45.625000  65.500  64.500000  66.428571  66.875   \n",
       "2012-03-01 00:05:00  50.666667  69.875  66.666667  58.555556  62.000   \n",
       "2012-03-01 00:10:00  44.125000  69.000  56.500000  59.250000  68.125   \n",
       "2012-03-01 00:15:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
       "2012-03-01 00:20:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
       "\n",
       "                        717592     717595     772168     718141  769373  \n",
       "2012-03-01 00:00:00  59.375000  69.000000  59.250000  69.000000  61.875  \n",
       "2012-03-01 00:05:00  61.111111  64.444444  55.888889  68.444444  62.875  \n",
       "2012-03-01 00:10:00  62.500000  65.625000  61.375000  69.857143  62.000  \n",
       "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
       "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf('data/METRLA/metr-la.h5')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>773869</th>\n",
       "      <th>767541</th>\n",
       "      <th>767542</th>\n",
       "      <th>717447</th>\n",
       "      <th>717446</th>\n",
       "      <th>717445</th>\n",
       "      <th>773062</th>\n",
       "      <th>767620</th>\n",
       "      <th>737529</th>\n",
       "      <th>717816</th>\n",
       "      <th>...</th>\n",
       "      <th>772167</th>\n",
       "      <th>769372</th>\n",
       "      <th>774204</th>\n",
       "      <th>769806</th>\n",
       "      <th>717590</th>\n",
       "      <th>717592</th>\n",
       "      <th>717595</th>\n",
       "      <th>772168</th>\n",
       "      <th>718141</th>\n",
       "      <th>769373</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:35:00</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.888889</td>\n",
       "      <td>68.555556</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.555556</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>59.222222</td>\n",
       "      <td>65.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>52.888889</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>65.111111</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>66.777778</td>\n",
       "      <td>64.888889</td>\n",
       "      <td>69.666667</td>\n",
       "      <td>62.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:40:00</th>\n",
       "      <td>61.375000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>69.250000</td>\n",
       "      <td>60.125000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>61.250000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:45:00</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>59.666667</td>\n",
       "      <td>69.555556</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.777778</td>\n",
       "      <td>64.222222</td>\n",
       "      <td>63.777778</td>\n",
       "      <td>59.777778</td>\n",
       "      <td>57.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>51.333333</td>\n",
       "      <td>67.888889</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>67.444444</td>\n",
       "      <td>61.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:50:00</th>\n",
       "      <td>66.750000</td>\n",
       "      <td>62.250000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>59.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>64.125000</td>\n",
       "      <td>60.875000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.125000</td>\n",
       "      <td>69.375000</td>\n",
       "      <td>61.625000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>66.375000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.875000</td>\n",
       "      <td>63.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-27 23:55:00</th>\n",
       "      <td>65.111111</td>\n",
       "      <td>66.888889</td>\n",
       "      <td>66.777778</td>\n",
       "      <td>61.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.555556</td>\n",
       "      <td>65.777778</td>\n",
       "      <td>65.111111</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>67.444444</td>\n",
       "      <td>64.888889</td>\n",
       "      <td>60.888889</td>\n",
       "      <td>64.222222</td>\n",
       "      <td>66.444444</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>63.555556</td>\n",
       "      <td>68.666667</td>\n",
       "      <td>61.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        773869     767541     767542     717447  717446  \\\n",
       "2012-06-27 23:35:00  65.000000  65.888889  68.555556  61.666667     0.0   \n",
       "2012-06-27 23:40:00  61.375000  65.625000  66.500000  62.750000     0.0   \n",
       "2012-06-27 23:45:00  67.000000  59.666667  69.555556  61.000000     0.0   \n",
       "2012-06-27 23:50:00  66.750000  62.250000  66.000000  59.625000     0.0   \n",
       "2012-06-27 23:55:00  65.111111  66.888889  66.777778  61.222222     0.0   \n",
       "\n",
       "                        717445     773062     767620     737529     717816  \\\n",
       "2012-06-27 23:35:00  54.555556  62.444444  63.333333  59.222222  65.333333   \n",
       "2012-06-27 23:40:00  50.500000  62.000000  67.000000  65.250000  67.125000   \n",
       "2012-06-27 23:45:00  44.777778  64.222222  63.777778  59.777778  57.666667   \n",
       "2012-06-27 23:50:00  53.000000  64.285714  64.125000  60.875000  66.250000   \n",
       "2012-06-27 23:55:00  49.555556  65.777778  65.111111  63.000000  61.666667   \n",
       "\n",
       "                     ...     772167     769372     774204     769806  \\\n",
       "2012-06-27 23:35:00  ...  52.888889  69.000000  65.111111  55.666667   \n",
       "2012-06-27 23:40:00  ...  54.000000  69.250000  60.125000  60.500000   \n",
       "2012-06-27 23:45:00  ...  51.333333  67.888889  64.333333  57.000000   \n",
       "2012-06-27 23:50:00  ...  51.125000  69.375000  61.625000  60.500000   \n",
       "2012-06-27 23:55:00  ...  56.000000  67.444444  64.888889  60.888889   \n",
       "\n",
       "                        717590     717592     717595     772168     718141  \\\n",
       "2012-06-27 23:35:00  66.333333  62.444444  66.777778  64.888889  69.666667   \n",
       "2012-06-27 23:40:00  67.250000  59.375000  66.000000  61.250000  69.000000   \n",
       "2012-06-27 23:45:00  66.000000  62.666667  68.666667  63.333333  67.444444   \n",
       "2012-06-27 23:50:00  65.625000  66.375000  69.500000  63.000000  67.875000   \n",
       "2012-06-27 23:55:00  64.222222  66.444444  68.444444  63.555556  68.666667   \n",
       "\n",
       "                        769373  \n",
       "2012-06-27 23:35:00  62.333333  \n",
       "2012-06-27 23:40:00  62.000000  \n",
       "2012-06-27 23:45:00  61.222222  \n",
       "2012-06-27 23:50:00  63.500000  \n",
       "2012-06-27 23:55:00  61.777778  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>773869</th>\n",
       "      <th>767541</th>\n",
       "      <th>767542</th>\n",
       "      <th>717447</th>\n",
       "      <th>717446</th>\n",
       "      <th>717445</th>\n",
       "      <th>773062</th>\n",
       "      <th>767620</th>\n",
       "      <th>737529</th>\n",
       "      <th>717816</th>\n",
       "      <th>...</th>\n",
       "      <th>772167</th>\n",
       "      <th>769372</th>\n",
       "      <th>774204</th>\n",
       "      <th>769806</th>\n",
       "      <th>717590</th>\n",
       "      <th>717592</th>\n",
       "      <th>717595</th>\n",
       "      <th>772168</th>\n",
       "      <th>718141</th>\n",
       "      <th>769373</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "      <td>34272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.631359</td>\n",
       "      <td>60.452789</td>\n",
       "      <td>60.726120</td>\n",
       "      <td>49.524287</td>\n",
       "      <td>46.079798</td>\n",
       "      <td>50.952003</td>\n",
       "      <td>54.471684</td>\n",
       "      <td>57.255095</td>\n",
       "      <td>56.068044</td>\n",
       "      <td>52.871841</td>\n",
       "      <td>...</td>\n",
       "      <td>37.803342</td>\n",
       "      <td>58.156679</td>\n",
       "      <td>51.217523</td>\n",
       "      <td>59.795754</td>\n",
       "      <td>59.329923</td>\n",
       "      <td>56.915083</td>\n",
       "      <td>62.484679</td>\n",
       "      <td>54.697381</td>\n",
       "      <td>58.920210</td>\n",
       "      <td>51.197504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.619199</td>\n",
       "      <td>15.970239</td>\n",
       "      <td>18.313353</td>\n",
       "      <td>15.843261</td>\n",
       "      <td>19.350345</td>\n",
       "      <td>16.681760</td>\n",
       "      <td>17.984761</td>\n",
       "      <td>18.751065</td>\n",
       "      <td>18.240361</td>\n",
       "      <td>23.343805</td>\n",
       "      <td>...</td>\n",
       "      <td>13.525743</td>\n",
       "      <td>20.690411</td>\n",
       "      <td>22.224997</td>\n",
       "      <td>16.126225</td>\n",
       "      <td>19.849950</td>\n",
       "      <td>18.260438</td>\n",
       "      <td>16.959238</td>\n",
       "      <td>16.303651</td>\n",
       "      <td>19.080474</td>\n",
       "      <td>21.239354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.364583</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>65.444444</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>49.555556</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>58.222222</td>\n",
       "      <td>43.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>30.444444</td>\n",
       "      <td>64.111111</td>\n",
       "      <td>53.444444</td>\n",
       "      <td>61.714286</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>60.222222</td>\n",
       "      <td>65.888889</td>\n",
       "      <td>50.125000</td>\n",
       "      <td>62.888889</td>\n",
       "      <td>54.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64.888889</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.375000</td>\n",
       "      <td>53.875000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>56.111111</td>\n",
       "      <td>62.111111</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>65.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.222222</td>\n",
       "      <td>67.111111</td>\n",
       "      <td>61.777778</td>\n",
       "      <td>64.875000</td>\n",
       "      <td>66.777778</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.625000</td>\n",
       "      <td>61.125000</td>\n",
       "      <td>66.125000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66.875000</td>\n",
       "      <td>66.375000</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>58.125000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>60.333333</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>64.888889</td>\n",
       "      <td>67.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.625000</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>64.375000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>68.250000</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>68.625000</td>\n",
       "      <td>64.444444</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>63.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             773869        767541        767542        717447        717446  \\\n",
       "count  34272.000000  34272.000000  34272.000000  34272.000000  34272.000000   \n",
       "mean      54.631359     60.452789     60.726120     49.524287     46.079798   \n",
       "std       22.619199     15.970239     18.313353     15.843261     19.350345   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       60.364583     63.000000     65.444444     50.333333     34.666667   \n",
       "50%       64.888889     65.000000     67.375000     53.875000     46.000000   \n",
       "75%       66.875000     66.375000     68.444444     58.125000     64.500000   \n",
       "max       70.000000     70.000000     70.000000     70.000000     70.000000   \n",
       "\n",
       "             717445        773062        767620        737529        717816  \\\n",
       "count  34272.000000  34272.000000  34272.000000  34272.000000  34272.000000   \n",
       "mean      50.952003     54.471684     57.255095     56.068044     52.871841   \n",
       "std       16.681760     17.984761     18.751065     18.240361     23.343805   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       49.555556     55.750000     61.000000     58.222222     43.428571   \n",
       "50%       56.111111     62.111111     63.333333     62.444444     65.875000   \n",
       "75%       60.333333     65.000000     65.000000     64.888889     67.625000   \n",
       "max       70.000000     70.000000     70.000000     70.000000     70.000000   \n",
       "\n",
       "       ...        772167        769372        774204        769806  \\\n",
       "count  ...  34272.000000  34272.000000  34272.000000  34272.000000   \n",
       "mean   ...     37.803342     58.156679     51.217523     59.795754   \n",
       "std    ...     13.525743     20.690411     22.224997     16.126225   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...     30.444444     64.111111     53.444444     61.714286   \n",
       "50%    ...     43.222222     67.111111     61.777778     64.875000   \n",
       "75%    ...     46.625000     68.444444     64.375000     66.500000   \n",
       "max    ...     65.000000     70.000000     70.000000     70.000000   \n",
       "\n",
       "             717590        717592        717595        772168        718141  \\\n",
       "count  34272.000000  34272.000000  34272.000000  34272.000000  34272.000000   \n",
       "mean      59.329923     56.915083     62.484679     54.697381     58.920210   \n",
       "std       19.849950     18.260438     16.959238     16.303651     19.080474   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       63.666667     60.222222     65.888889     50.125000     62.888889   \n",
       "50%       66.777778     63.000000     67.625000     61.125000     66.125000   \n",
       "75%       68.250000     64.750000     68.625000     64.444444     67.750000   \n",
       "max       70.000000     70.000000     70.000000     70.000000     70.000000   \n",
       "\n",
       "             769373  \n",
       "count  34272.000000  \n",
       "mean      51.197504  \n",
       "std       21.239354  \n",
       "min        0.000000  \n",
       "25%       54.125000  \n",
       "50%       62.000000  \n",
       "75%       63.444444  \n",
       "max       70.000000  \n",
       "\n",
       "[8 rows x 207 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.109350825676486"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_entries = df.size\n",
    "zero_entries = (df == 0).sum().sum()\n",
    "percentage_zeros = (zero_entries / total_entries) * 100\n",
    "percentage_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEMS-BAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sensor_id</th>\n",
       "      <th>400001</th>\n",
       "      <th>400017</th>\n",
       "      <th>400030</th>\n",
       "      <th>400040</th>\n",
       "      <th>400045</th>\n",
       "      <th>400052</th>\n",
       "      <th>400057</th>\n",
       "      <th>400059</th>\n",
       "      <th>400065</th>\n",
       "      <th>400069</th>\n",
       "      <th>...</th>\n",
       "      <th>409525</th>\n",
       "      <th>409526</th>\n",
       "      <th>409528</th>\n",
       "      <th>409529</th>\n",
       "      <th>413026</th>\n",
       "      <th>413845</th>\n",
       "      <th>413877</th>\n",
       "      <th>413878</th>\n",
       "      <th>414284</th>\n",
       "      <th>414694</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>71.4</td>\n",
       "      <td>67.8</td>\n",
       "      <td>70.5</td>\n",
       "      <td>67.4</td>\n",
       "      <td>68.8</td>\n",
       "      <td>66.6</td>\n",
       "      <td>66.8</td>\n",
       "      <td>68.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.8</td>\n",
       "      <td>67.9</td>\n",
       "      <td>68.8</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>68.9</td>\n",
       "      <td>70.4</td>\n",
       "      <td>68.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:05:00</th>\n",
       "      <td>71.6</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.6</td>\n",
       "      <td>67.5</td>\n",
       "      <td>68.7</td>\n",
       "      <td>66.6</td>\n",
       "      <td>66.8</td>\n",
       "      <td>67.8</td>\n",
       "      <td>66.5</td>\n",
       "      <td>68.2</td>\n",
       "      <td>...</td>\n",
       "      <td>68.4</td>\n",
       "      <td>67.3</td>\n",
       "      <td>68.4</td>\n",
       "      <td>67.6</td>\n",
       "      <td>70.4</td>\n",
       "      <td>68.8</td>\n",
       "      <td>70.1</td>\n",
       "      <td>68.4</td>\n",
       "      <td>70.8</td>\n",
       "      <td>67.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:10:00</th>\n",
       "      <td>71.6</td>\n",
       "      <td>67.6</td>\n",
       "      <td>70.2</td>\n",
       "      <td>67.4</td>\n",
       "      <td>68.7</td>\n",
       "      <td>66.1</td>\n",
       "      <td>66.8</td>\n",
       "      <td>67.8</td>\n",
       "      <td>66.2</td>\n",
       "      <td>67.8</td>\n",
       "      <td>...</td>\n",
       "      <td>68.4</td>\n",
       "      <td>67.4</td>\n",
       "      <td>68.4</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.2</td>\n",
       "      <td>68.3</td>\n",
       "      <td>69.8</td>\n",
       "      <td>68.4</td>\n",
       "      <td>70.5</td>\n",
       "      <td>67.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:15:00</th>\n",
       "      <td>71.1</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>66.7</td>\n",
       "      <td>66.6</td>\n",
       "      <td>67.7</td>\n",
       "      <td>65.9</td>\n",
       "      <td>67.8</td>\n",
       "      <td>...</td>\n",
       "      <td>68.5</td>\n",
       "      <td>67.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>67.5</td>\n",
       "      <td>70.4</td>\n",
       "      <td>68.7</td>\n",
       "      <td>70.2</td>\n",
       "      <td>68.4</td>\n",
       "      <td>70.8</td>\n",
       "      <td>67.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:20:00</th>\n",
       "      <td>71.7</td>\n",
       "      <td>67.8</td>\n",
       "      <td>70.2</td>\n",
       "      <td>68.1</td>\n",
       "      <td>68.4</td>\n",
       "      <td>66.9</td>\n",
       "      <td>66.1</td>\n",
       "      <td>67.7</td>\n",
       "      <td>66.1</td>\n",
       "      <td>67.8</td>\n",
       "      <td>...</td>\n",
       "      <td>68.5</td>\n",
       "      <td>67.7</td>\n",
       "      <td>68.5</td>\n",
       "      <td>67.4</td>\n",
       "      <td>69.6</td>\n",
       "      <td>69.1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sensor_id            400001  400017  400030  400040  400045  400052  400057  \\\n",
       "2017-01-01 00:00:00    71.4    67.8    70.5    67.4    68.8    66.6    66.8   \n",
       "2017-01-01 00:05:00    71.6    67.5    70.6    67.5    68.7    66.6    66.8   \n",
       "2017-01-01 00:10:00    71.6    67.6    70.2    67.4    68.7    66.1    66.8   \n",
       "2017-01-01 00:15:00    71.1    67.5    70.3    68.0    68.5    66.7    66.6   \n",
       "2017-01-01 00:20:00    71.7    67.8    70.2    68.1    68.4    66.9    66.1   \n",
       "\n",
       "sensor_id            400059  400065  400069  ...  409525  409526  409528  \\\n",
       "2017-01-01 00:00:00    68.0    66.8    69.0  ...    68.8    67.9    68.8   \n",
       "2017-01-01 00:05:00    67.8    66.5    68.2  ...    68.4    67.3    68.4   \n",
       "2017-01-01 00:10:00    67.8    66.2    67.8  ...    68.4    67.4    68.4   \n",
       "2017-01-01 00:15:00    67.7    65.9    67.8  ...    68.5    67.5    68.5   \n",
       "2017-01-01 00:20:00    67.7    66.1    67.8  ...    68.5    67.7    68.5   \n",
       "\n",
       "sensor_id            409529  413026  413845  413877  413878  414284  414694  \n",
       "2017-01-01 00:00:00    68.0    69.2    68.9    70.4    68.8    71.1    68.0  \n",
       "2017-01-01 00:05:00    67.6    70.4    68.8    70.1    68.4    70.8    67.4  \n",
       "2017-01-01 00:10:00    67.5    70.2    68.3    69.8    68.4    70.5    67.9  \n",
       "2017-01-01 00:15:00    67.5    70.4    68.7    70.2    68.4    70.8    67.6  \n",
       "2017-01-01 00:20:00    67.4    69.6    69.1    70.0    68.4    71.0    67.9  \n",
       "\n",
       "[5 rows x 325 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_hdf('data/PEMSBAY/PEMS-BAY.h5')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sensor_id</th>\n",
       "      <th>400001</th>\n",
       "      <th>400017</th>\n",
       "      <th>400030</th>\n",
       "      <th>400040</th>\n",
       "      <th>400045</th>\n",
       "      <th>400052</th>\n",
       "      <th>400057</th>\n",
       "      <th>400059</th>\n",
       "      <th>400065</th>\n",
       "      <th>400069</th>\n",
       "      <th>...</th>\n",
       "      <th>409525</th>\n",
       "      <th>409526</th>\n",
       "      <th>409528</th>\n",
       "      <th>409529</th>\n",
       "      <th>413026</th>\n",
       "      <th>413845</th>\n",
       "      <th>413877</th>\n",
       "      <th>413878</th>\n",
       "      <th>414284</th>\n",
       "      <th>414694</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-30 23:35:00</th>\n",
       "      <td>70.9</td>\n",
       "      <td>66.3</td>\n",
       "      <td>68.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.8</td>\n",
       "      <td>66.9</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>65.4</td>\n",
       "      <td>69.3</td>\n",
       "      <td>...</td>\n",
       "      <td>64.6</td>\n",
       "      <td>66.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>61.1</td>\n",
       "      <td>68.4</td>\n",
       "      <td>61.4</td>\n",
       "      <td>70.5</td>\n",
       "      <td>68.2</td>\n",
       "      <td>71.6</td>\n",
       "      <td>66.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 23:40:00</th>\n",
       "      <td>71.3</td>\n",
       "      <td>66.6</td>\n",
       "      <td>68.7</td>\n",
       "      <td>60.9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>66.5</td>\n",
       "      <td>68.2</td>\n",
       "      <td>64.9</td>\n",
       "      <td>69.1</td>\n",
       "      <td>...</td>\n",
       "      <td>65.1</td>\n",
       "      <td>67.3</td>\n",
       "      <td>64.8</td>\n",
       "      <td>60.8</td>\n",
       "      <td>69.8</td>\n",
       "      <td>62.2</td>\n",
       "      <td>69.4</td>\n",
       "      <td>68.6</td>\n",
       "      <td>71.6</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 23:45:00</th>\n",
       "      <td>71.4</td>\n",
       "      <td>66.9</td>\n",
       "      <td>68.1</td>\n",
       "      <td>61.1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>65.8</td>\n",
       "      <td>68.2</td>\n",
       "      <td>64.2</td>\n",
       "      <td>69.1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.9</td>\n",
       "      <td>66.5</td>\n",
       "      <td>64.6</td>\n",
       "      <td>61.3</td>\n",
       "      <td>69.5</td>\n",
       "      <td>63.8</td>\n",
       "      <td>70.6</td>\n",
       "      <td>68.4</td>\n",
       "      <td>71.6</td>\n",
       "      <td>66.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 23:50:00</th>\n",
       "      <td>72.2</td>\n",
       "      <td>66.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>61.1</td>\n",
       "      <td>62.5</td>\n",
       "      <td>65.8</td>\n",
       "      <td>67.1</td>\n",
       "      <td>68.3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.3</td>\n",
       "      <td>...</td>\n",
       "      <td>64.1</td>\n",
       "      <td>65.9</td>\n",
       "      <td>64.8</td>\n",
       "      <td>61.3</td>\n",
       "      <td>69.6</td>\n",
       "      <td>64.2</td>\n",
       "      <td>70.2</td>\n",
       "      <td>68.7</td>\n",
       "      <td>71.6</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 23:55:00</th>\n",
       "      <td>71.5</td>\n",
       "      <td>66.2</td>\n",
       "      <td>68.4</td>\n",
       "      <td>61.5</td>\n",
       "      <td>62.8</td>\n",
       "      <td>66.1</td>\n",
       "      <td>67.7</td>\n",
       "      <td>68.4</td>\n",
       "      <td>64.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.3</td>\n",
       "      <td>66.5</td>\n",
       "      <td>64.8</td>\n",
       "      <td>60.9</td>\n",
       "      <td>70.9</td>\n",
       "      <td>63.4</td>\n",
       "      <td>70.3</td>\n",
       "      <td>68.7</td>\n",
       "      <td>71.6</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sensor_id            400001  400017  400030  400040  400045  400052  400057  \\\n",
       "2017-06-30 23:35:00    70.9    66.3    68.4    61.0    61.8    66.9    66.0   \n",
       "2017-06-30 23:40:00    71.3    66.6    68.7    60.9    62.0    66.2    66.5   \n",
       "2017-06-30 23:45:00    71.4    66.9    68.1    61.1    62.0    66.7    65.8   \n",
       "2017-06-30 23:50:00    72.2    66.5    68.0    61.1    62.5    65.8    67.1   \n",
       "2017-06-30 23:55:00    71.5    66.2    68.4    61.5    62.8    66.1    67.7   \n",
       "\n",
       "sensor_id            400059  400065  400069  ...  409525  409526  409528  \\\n",
       "2017-06-30 23:35:00    67.4    65.4    69.3  ...    64.6    66.8    64.7   \n",
       "2017-06-30 23:40:00    68.2    64.9    69.1  ...    65.1    67.3    64.8   \n",
       "2017-06-30 23:45:00    68.2    64.2    69.1  ...    64.9    66.5    64.6   \n",
       "2017-06-30 23:50:00    68.3    64.0    67.3  ...    64.1    65.9    64.8   \n",
       "2017-06-30 23:55:00    68.4    64.9    68.0  ...    64.3    66.5    64.8   \n",
       "\n",
       "sensor_id            409529  413026  413845  413877  413878  414284  414694  \n",
       "2017-06-30 23:35:00    61.1    68.4    61.4    70.5    68.2    71.6    66.2  \n",
       "2017-06-30 23:40:00    60.8    69.8    62.2    69.4    68.6    71.6    68.4  \n",
       "2017-06-30 23:45:00    61.3    69.5    63.8    70.6    68.4    71.6    66.6  \n",
       "2017-06-30 23:50:00    61.3    69.6    64.2    70.2    68.7    71.6    68.4  \n",
       "2017-06-30 23:55:00    60.9    70.9    63.4    70.3    68.7    71.6    68.0  \n",
       "\n",
       "[5 rows x 325 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sensor_id</th>\n",
       "      <th>400001</th>\n",
       "      <th>400017</th>\n",
       "      <th>400030</th>\n",
       "      <th>400040</th>\n",
       "      <th>400045</th>\n",
       "      <th>400052</th>\n",
       "      <th>400057</th>\n",
       "      <th>400059</th>\n",
       "      <th>400065</th>\n",
       "      <th>400069</th>\n",
       "      <th>...</th>\n",
       "      <th>409525</th>\n",
       "      <th>409526</th>\n",
       "      <th>409528</th>\n",
       "      <th>409529</th>\n",
       "      <th>413026</th>\n",
       "      <th>413845</th>\n",
       "      <th>413877</th>\n",
       "      <th>413878</th>\n",
       "      <th>414284</th>\n",
       "      <th>414694</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.00000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "      <td>52116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.568557</td>\n",
       "      <td>59.019079</td>\n",
       "      <td>59.138577</td>\n",
       "      <td>62.137407</td>\n",
       "      <td>61.195873</td>\n",
       "      <td>63.314788</td>\n",
       "      <td>58.777483</td>\n",
       "      <td>63.565579</td>\n",
       "      <td>62.069533</td>\n",
       "      <td>57.726957</td>\n",
       "      <td>...</td>\n",
       "      <td>65.795827</td>\n",
       "      <td>63.61541</td>\n",
       "      <td>63.815680</td>\n",
       "      <td>60.647717</td>\n",
       "      <td>66.148728</td>\n",
       "      <td>57.203082</td>\n",
       "      <td>67.566198</td>\n",
       "      <td>64.604361</td>\n",
       "      <td>67.351650</td>\n",
       "      <td>64.328245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.119154</td>\n",
       "      <td>13.250178</td>\n",
       "      <td>11.658612</td>\n",
       "      <td>8.617881</td>\n",
       "      <td>11.019177</td>\n",
       "      <td>11.159615</td>\n",
       "      <td>13.078931</td>\n",
       "      <td>8.434674</td>\n",
       "      <td>10.557263</td>\n",
       "      <td>18.113331</td>\n",
       "      <td>...</td>\n",
       "      <td>5.645500</td>\n",
       "      <td>6.42068</td>\n",
       "      <td>8.381049</td>\n",
       "      <td>4.622528</td>\n",
       "      <td>4.511122</td>\n",
       "      <td>10.932359</td>\n",
       "      <td>5.992427</td>\n",
       "      <td>4.753887</td>\n",
       "      <td>7.060815</td>\n",
       "      <td>8.455986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>67.300000</td>\n",
       "      <td>62.200000</td>\n",
       "      <td>55.800000</td>\n",
       "      <td>59.400000</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>58.400000</td>\n",
       "      <td>64.200000</td>\n",
       "      <td>63.300000</td>\n",
       "      <td>61.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>64.700000</td>\n",
       "      <td>63.80000</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>57.800000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>62.900000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>64.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.300000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>62.700000</td>\n",
       "      <td>66.200000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>66.400000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>65.10000</td>\n",
       "      <td>66.100000</td>\n",
       "      <td>61.600000</td>\n",
       "      <td>66.700000</td>\n",
       "      <td>60.900000</td>\n",
       "      <td>69.400000</td>\n",
       "      <td>66.100000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>66.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.300000</td>\n",
       "      <td>65.100000</td>\n",
       "      <td>66.600000</td>\n",
       "      <td>67.700000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>66.300000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>66.40000</td>\n",
       "      <td>67.300000</td>\n",
       "      <td>62.600000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>62.600000</td>\n",
       "      <td>70.400000</td>\n",
       "      <td>67.900000</td>\n",
       "      <td>70.400000</td>\n",
       "      <td>67.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.400000</td>\n",
       "      <td>71.600000</td>\n",
       "      <td>77.700000</td>\n",
       "      <td>76.900000</td>\n",
       "      <td>78.900000</td>\n",
       "      <td>78.700000</td>\n",
       "      <td>78.200000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>72.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.600000</td>\n",
       "      <td>73.70000</td>\n",
       "      <td>78.900000</td>\n",
       "      <td>69.900000</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>79.900000</td>\n",
       "      <td>79.900000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>80.400000</td>\n",
       "      <td>74.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sensor_id        400001        400017        400030        400040  \\\n",
       "count      52116.000000  52116.000000  52116.000000  52116.000000   \n",
       "mean          67.568557     59.019079     59.138577     62.137407   \n",
       "std            8.119154     13.250178     11.658612      8.617881   \n",
       "min            0.000000     11.000000      3.400000      0.000000   \n",
       "25%           67.300000     62.200000     55.800000     59.400000   \n",
       "50%           70.300000     64.000000     62.700000     66.200000   \n",
       "75%           71.300000     65.100000     66.600000     67.700000   \n",
       "max           80.400000     71.600000     77.700000     76.900000   \n",
       "\n",
       "sensor_id        400045        400052        400057        400059  \\\n",
       "count      52116.000000  52116.000000  52116.000000  52116.000000   \n",
       "mean          61.195873     63.314788     58.777483     63.565579   \n",
       "std           11.019177     11.159615     13.078931      8.434674   \n",
       "min            7.400000      0.000000      0.000000      0.000000   \n",
       "25%           57.500000     65.000000     58.400000     64.200000   \n",
       "50%           63.500000     66.500000     63.700000     66.400000   \n",
       "75%           69.500000     67.500000     66.300000     67.500000   \n",
       "max           78.900000     78.700000     78.200000     80.000000   \n",
       "\n",
       "sensor_id        400065        400069  ...        409525       409526  \\\n",
       "count      52116.000000  52116.000000  ...  52116.000000  52116.00000   \n",
       "mean          62.069533     57.726957  ...     65.795827     63.61541   \n",
       "std           10.557263     18.113331  ...      5.645500      6.42068   \n",
       "min            0.000000      5.300000  ...      0.000000      0.00000   \n",
       "25%           63.300000     61.300000  ...     64.700000     63.80000   \n",
       "50%           65.500000     65.500000  ...     67.500000     65.10000   \n",
       "75%           67.000000     67.400000  ...     68.500000     66.40000   \n",
       "max           75.400000     72.300000  ...     78.600000     73.70000   \n",
       "\n",
       "sensor_id        409528        409529        413026        413845  \\\n",
       "count      52116.000000  52116.000000  52116.000000  52116.000000   \n",
       "mean          63.815680     60.647717     66.148728     57.203082   \n",
       "std            8.381049      4.622528      4.511122     10.932359   \n",
       "min            0.000000      0.000000      0.000000      0.000000   \n",
       "25%           63.700000     60.000000     63.700000     57.800000   \n",
       "50%           66.100000     61.600000     66.700000     60.900000   \n",
       "75%           67.300000     62.600000     69.500000     62.600000   \n",
       "max           78.900000     69.900000     76.800000     79.900000   \n",
       "\n",
       "sensor_id        413877        413878        414284        414694  \n",
       "count      52116.000000  52116.000000  52116.000000  52116.000000  \n",
       "mean          67.566198     64.604361     67.351650     64.328245  \n",
       "std            5.992427      4.753887      7.060815      8.455986  \n",
       "min            0.000000      0.000000      0.000000      0.000000  \n",
       "25%           67.200000     62.900000     67.000000     64.600000  \n",
       "50%           69.400000     66.100000     69.000000     66.400000  \n",
       "75%           70.400000     67.900000     70.400000     67.700000  \n",
       "max           79.900000     72.500000     80.400000     74.300000  \n",
       "\n",
       "[8 rows x 325 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003075978438630983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_entries = df2.size\n",
    "zero_entries = (df2 == 0).sum().sum()\n",
    "percentage_zeros = (zero_entries / total_entries) * 100\n",
    "percentage_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_hdf('data/Hauge/hague_comp_filled.h5', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K502-S1</th>\n",
       "      <th>K502-111</th>\n",
       "      <th>K502-051</th>\n",
       "      <th>K263-081</th>\n",
       "      <th>K263-N1</th>\n",
       "      <th>K263-031</th>\n",
       "      <th>K263-S1</th>\n",
       "      <th>K503-N1</th>\n",
       "      <th>K503-07_1</th>\n",
       "      <th>K503-S1</th>\n",
       "      <th>...</th>\n",
       "      <th>K074-052</th>\n",
       "      <th>K414-N1</th>\n",
       "      <th>K414-N2</th>\n",
       "      <th>K414-S1</th>\n",
       "      <th>K414-S2</th>\n",
       "      <th>K415-021</th>\n",
       "      <th>K415-081</th>\n",
       "      <th>K250-N1</th>\n",
       "      <th>K250-S1</th>\n",
       "      <th>K250-N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:05:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:10:00</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:15:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:20:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     K502-S1  K502-111  K502-051  K263-081  K263-N1  K263-031  \\\n",
       "2018-01-01 00:00:00      4.0       1.0       1.0       1.0      3.0       1.0   \n",
       "2018-01-01 00:05:00      1.0       1.0       1.0       1.0      3.0       1.0   \n",
       "2018-01-01 00:10:00      1.5       1.0       1.0       1.0      1.0       1.0   \n",
       "2018-01-01 00:15:00      2.5       1.0       1.0       1.0      4.0       1.0   \n",
       "2018-01-01 00:20:00      4.0       2.0       3.0       1.0      1.0       3.0   \n",
       "\n",
       "                      K263-S1  K503-N1  K503-07_1  K503-S1  ...  K074-052  \\\n",
       "2018-01-01 00:00:00  1.000000      4.0        1.0      1.0  ...       3.0   \n",
       "2018-01-01 00:05:00  1.000000      4.0        1.0      1.0  ...       2.0   \n",
       "2018-01-01 00:10:00  1.500000      1.0        1.0      1.0  ...       2.0   \n",
       "2018-01-01 00:15:00  1.583333      3.0        1.0      2.0  ...       2.0   \n",
       "2018-01-01 00:20:00  1.666667      1.5        1.0      3.0  ...       4.0   \n",
       "\n",
       "                     K414-N1  K414-N2  K414-S1  K414-S2  K415-021  K415-081  \\\n",
       "2018-01-01 00:00:00      1.0      2.0      3.0      1.0       2.0       4.0   \n",
       "2018-01-01 00:05:00      1.0      2.0      3.0      1.0       2.0       4.0   \n",
       "2018-01-01 00:10:00      1.0      7.0      2.0      1.0       1.5       2.5   \n",
       "2018-01-01 00:15:00      1.0      4.0      1.0      1.0       1.0       1.0   \n",
       "2018-01-01 00:20:00      1.0      3.5      1.5      1.0       3.0       3.0   \n",
       "\n",
       "                     K250-N1   K250-S1  K250-N2  \n",
       "2018-01-01 00:00:00      1.0  2.333333      2.0  \n",
       "2018-01-01 00:05:00      1.0  2.333333      2.0  \n",
       "2018-01-01 00:10:00      1.0  2.000000      2.0  \n",
       "2018-01-01 00:15:00      1.5  2.000000      2.0  \n",
       "2018-01-01 00:20:00      2.0  2.000000      2.0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K502-S1</th>\n",
       "      <th>K502-111</th>\n",
       "      <th>K502-051</th>\n",
       "      <th>K263-081</th>\n",
       "      <th>K263-N1</th>\n",
       "      <th>K263-031</th>\n",
       "      <th>K263-S1</th>\n",
       "      <th>K503-N1</th>\n",
       "      <th>K503-07_1</th>\n",
       "      <th>K503-S1</th>\n",
       "      <th>...</th>\n",
       "      <th>K074-052</th>\n",
       "      <th>K414-N1</th>\n",
       "      <th>K414-N2</th>\n",
       "      <th>K414-S1</th>\n",
       "      <th>K414-S2</th>\n",
       "      <th>K415-021</th>\n",
       "      <th>K415-081</th>\n",
       "      <th>K250-N1</th>\n",
       "      <th>K250-S1</th>\n",
       "      <th>K250-N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:35:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:40:00</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:45:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:50:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:55:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     K502-S1  K502-111  K502-051  K263-081  K263-N1  K263-031  \\\n",
       "2019-12-31 23:35:00      1.0       1.0       3.0       1.0      4.0       1.0   \n",
       "2019-12-31 23:40:00      4.5       1.5       1.0       2.0      3.0       1.0   \n",
       "2019-12-31 23:45:00      1.0       2.0       1.0       1.0      1.0       1.0   \n",
       "2019-12-31 23:50:00      3.0       1.0       1.0       1.0      1.5       1.0   \n",
       "2019-12-31 23:55:00      1.0       1.0       1.0       1.0      1.5       1.0   \n",
       "\n",
       "                     K263-S1  K503-N1  K503-07_1  K503-S1  ...  K074-052  \\\n",
       "2019-12-31 23:35:00      1.5      1.0        1.0      1.0  ...       5.0   \n",
       "2019-12-31 23:40:00      2.0      2.0        3.0      2.0  ...       2.0   \n",
       "2019-12-31 23:45:00      2.0      1.0        1.0      1.0  ...       4.0   \n",
       "2019-12-31 23:50:00      1.0      1.0        2.0      2.0  ...       1.0   \n",
       "2019-12-31 23:55:00      1.5      1.0        2.0      2.0  ...       3.0   \n",
       "\n",
       "                     K414-N1  K414-N2  K414-S1  K414-S2  K415-021  K415-081  \\\n",
       "2019-12-31 23:35:00      1.0      4.0      1.0     1.25      10.0       1.0   \n",
       "2019-12-31 23:40:00      4.0      2.5      2.0     1.00       8.0       4.0   \n",
       "2019-12-31 23:45:00      3.0      3.0      3.5     1.50       7.0       7.0   \n",
       "2019-12-31 23:50:00      2.0      2.0      1.0     3.50       7.0       4.0   \n",
       "2019-12-31 23:55:00      2.0      4.0      4.0     2.00       7.0       6.0   \n",
       "\n",
       "                     K250-N1  K250-S1  K250-N2  \n",
       "2019-12-31 23:35:00      6.0      4.0     1.25  \n",
       "2019-12-31 23:40:00      3.5      1.5     1.50  \n",
       "2019-12-31 23:45:00      5.5      3.0     1.75  \n",
       "2019-12-31 23:50:00      3.5      2.0     2.00  \n",
       "2019-12-31 23:55:00      2.5      2.5     1.50  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K502-S1</th>\n",
       "      <th>K502-111</th>\n",
       "      <th>K502-051</th>\n",
       "      <th>K263-081</th>\n",
       "      <th>K263-N1</th>\n",
       "      <th>K263-031</th>\n",
       "      <th>K263-S1</th>\n",
       "      <th>K503-N1</th>\n",
       "      <th>K503-07_1</th>\n",
       "      <th>K503-S1</th>\n",
       "      <th>...</th>\n",
       "      <th>K074-052</th>\n",
       "      <th>K414-N1</th>\n",
       "      <th>K414-N2</th>\n",
       "      <th>K414-S1</th>\n",
       "      <th>K414-S2</th>\n",
       "      <th>K415-021</th>\n",
       "      <th>K415-081</th>\n",
       "      <th>K250-N1</th>\n",
       "      <th>K250-S1</th>\n",
       "      <th>K250-N2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.021291</td>\n",
       "      <td>12.110011</td>\n",
       "      <td>14.205948</td>\n",
       "      <td>5.129366</td>\n",
       "      <td>10.613917</td>\n",
       "      <td>5.416760</td>\n",
       "      <td>7.049675</td>\n",
       "      <td>10.852411</td>\n",
       "      <td>13.082478</td>\n",
       "      <td>10.543281</td>\n",
       "      <td>...</td>\n",
       "      <td>7.369044</td>\n",
       "      <td>5.384001</td>\n",
       "      <td>10.667049</td>\n",
       "      <td>4.454023</td>\n",
       "      <td>4.429249</td>\n",
       "      <td>18.812483</td>\n",
       "      <td>13.862488</td>\n",
       "      <td>14.017416</td>\n",
       "      <td>8.920681</td>\n",
       "      <td>4.334206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.527325</td>\n",
       "      <td>9.078076</td>\n",
       "      <td>10.529551</td>\n",
       "      <td>3.905994</td>\n",
       "      <td>7.141836</td>\n",
       "      <td>6.103183</td>\n",
       "      <td>4.493896</td>\n",
       "      <td>8.549293</td>\n",
       "      <td>9.859049</td>\n",
       "      <td>8.209062</td>\n",
       "      <td>...</td>\n",
       "      <td>6.184567</td>\n",
       "      <td>5.119420</td>\n",
       "      <td>8.552480</td>\n",
       "      <td>3.092587</td>\n",
       "      <td>3.551510</td>\n",
       "      <td>16.719564</td>\n",
       "      <td>11.438625</td>\n",
       "      <td>11.395264</td>\n",
       "      <td>6.275446</td>\n",
       "      <td>3.353168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>258.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>56.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             K502-S1       K502-111       K502-051       K263-081  \\\n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000   \n",
       "mean       13.021291      12.110011      14.205948       5.129366   \n",
       "std         9.527325       9.078076      10.529551       3.905994   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         4.000000       3.000000       3.000000       1.750000   \n",
       "50%        12.500000      11.000000      14.000000       4.000000   \n",
       "75%        20.000000      19.000000      23.000000       8.000000   \n",
       "max       258.000000      96.000000      89.000000      38.000000   \n",
       "\n",
       "             K263-N1       K263-031        K263-S1        K503-N1  \\\n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000   \n",
       "mean       10.613917       5.416760       7.049675      10.852411   \n",
       "std         7.141836       6.103183       4.493896       8.549293   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         4.000000       1.000000       3.000000       4.000000   \n",
       "50%        10.000000       3.000000       6.750000       9.000000   \n",
       "75%        16.000000       8.000000      10.250000      16.500000   \n",
       "max        50.000000     148.000000      42.000000     190.000000   \n",
       "\n",
       "           K503-07_1        K503-S1  ...       K074-052        K414-N1  \\\n",
       "count  209027.000000  209027.000000  ...  209027.000000  209027.000000   \n",
       "mean       13.082478      10.543281  ...       7.369044       5.384001   \n",
       "std         9.859049       8.209062  ...       6.184567       5.119420   \n",
       "min         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "25%         5.000000       3.000000  ...       2.000000       1.875000   \n",
       "50%        12.000000       9.000000  ...       6.000000       4.000000   \n",
       "75%        20.000000      16.500000  ...      11.000000       7.000000   \n",
       "max        91.000000      51.000000  ...      46.000000      45.500000   \n",
       "\n",
       "             K414-N2        K414-S1        K414-S2       K415-021  \\\n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000   \n",
       "mean       10.667049       4.454023       4.429249      18.812483   \n",
       "std         8.552480       3.092587       3.551510      16.719564   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         3.250000       2.000000       1.500000       5.000000   \n",
       "50%         8.500000       4.000000       3.500000      15.000000   \n",
       "75%        16.000000       6.000000       6.000000      28.000000   \n",
       "max        69.000000      36.000000      33.500000     109.000000   \n",
       "\n",
       "            K415-081        K250-N1        K250-S1        K250-N2  \n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000  \n",
       "mean       13.862488      14.017416       8.920681       4.334206  \n",
       "std        11.438625      11.395264       6.275446       3.353168  \n",
       "min         1.000000       1.000000       1.000000       1.000000  \n",
       "25%         4.000000       4.000000       3.500000       1.500000  \n",
       "50%        11.000000      11.000000       7.666667       3.500000  \n",
       "75%        21.000000      22.000000      13.333333       6.500000  \n",
       "max       105.000000      81.000000      55.500000      56.500000  \n",
       "\n",
       "[8 rows x 89 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_entries = df3.size\n",
    "zero_entries = (df3 == 0).sum().sum()\n",
    "percentage_zeros = (zero_entries / total_entries) * 100\n",
    "percentage_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_hdf('data/Hauge/hague_filled.h5', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K074-051</th>\n",
       "      <th>K074-052</th>\n",
       "      <th>K101-051</th>\n",
       "      <th>K101-081</th>\n",
       "      <th>K101-082</th>\n",
       "      <th>K101-121</th>\n",
       "      <th>K101-621</th>\n",
       "      <th>K101-622</th>\n",
       "      <th>K101-711</th>\n",
       "      <th>K128-061</th>\n",
       "      <th>...</th>\n",
       "      <th>K703-08_1</th>\n",
       "      <th>K703-08_2</th>\n",
       "      <th>K703-09_1</th>\n",
       "      <th>K704-02_1</th>\n",
       "      <th>K704-11_1</th>\n",
       "      <th>K704-11_2</th>\n",
       "      <th>K704-11_3</th>\n",
       "      <th>K704-12_1</th>\n",
       "      <th>K704-65_1</th>\n",
       "      <th>K704-65_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "      <td>209027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.201892</td>\n",
       "      <td>7.369044</td>\n",
       "      <td>14.019154</td>\n",
       "      <td>21.918629</td>\n",
       "      <td>21.118975</td>\n",
       "      <td>2.845001</td>\n",
       "      <td>21.916782</td>\n",
       "      <td>23.547300</td>\n",
       "      <td>6.728244</td>\n",
       "      <td>7.657631</td>\n",
       "      <td>...</td>\n",
       "      <td>8.204991</td>\n",
       "      <td>11.878595</td>\n",
       "      <td>6.306285</td>\n",
       "      <td>5.852868</td>\n",
       "      <td>14.671818</td>\n",
       "      <td>13.875118</td>\n",
       "      <td>11.966330</td>\n",
       "      <td>6.460515</td>\n",
       "      <td>20.881299</td>\n",
       "      <td>15.376109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.955736</td>\n",
       "      <td>6.184567</td>\n",
       "      <td>9.458659</td>\n",
       "      <td>12.454072</td>\n",
       "      <td>14.422103</td>\n",
       "      <td>1.977640</td>\n",
       "      <td>13.704861</td>\n",
       "      <td>16.872028</td>\n",
       "      <td>4.515344</td>\n",
       "      <td>8.109553</td>\n",
       "      <td>...</td>\n",
       "      <td>6.339753</td>\n",
       "      <td>8.130951</td>\n",
       "      <td>5.251719</td>\n",
       "      <td>4.826105</td>\n",
       "      <td>11.959692</td>\n",
       "      <td>11.562566</td>\n",
       "      <td>12.530202</td>\n",
       "      <td>5.632539</td>\n",
       "      <td>14.775188</td>\n",
       "      <td>13.395197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.838608</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>9.750878</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2531.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            K074-051       K074-052       K101-051       K101-081  \\\n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000   \n",
       "mean       10.201892       7.369044      14.019154      21.918629   \n",
       "std         6.955736       6.184567       9.458659      12.454072   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         4.000000       2.000000       5.000000      11.000000   \n",
       "50%        10.000000       6.000000      14.000000      22.000000   \n",
       "75%        15.000000      11.000000      21.000000      31.000000   \n",
       "max        67.000000      46.000000      65.000000      72.000000   \n",
       "\n",
       "            K101-082       K101-121       K101-621       K101-622  \\\n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000   \n",
       "mean       21.118975       2.845001      21.916782      23.547300   \n",
       "std        14.422103       1.977640      13.704861      16.872028   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         8.000000       1.000000       9.000000       7.000000   \n",
       "50%        20.000000       2.000000      22.000000      22.000000   \n",
       "75%        32.000000       4.000000      32.000000      37.000000   \n",
       "max        81.000000      25.000000      66.000000      85.000000   \n",
       "\n",
       "            K101-711       K128-061  ...      K703-08_1      K703-08_2  \\\n",
       "count  209027.000000  209027.000000  ...  209027.000000  209027.000000   \n",
       "mean        6.728244       7.657631  ...       8.204991      11.878595   \n",
       "std         4.515344       8.109553  ...       6.339753       8.130951   \n",
       "min         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "25%         3.000000       3.000000  ...       2.000000       4.000000   \n",
       "50%         6.000000       7.000000  ...       7.000000      12.000000   \n",
       "75%        10.000000      11.000000  ...      13.000000      18.000000   \n",
       "max        43.000000    2531.000000  ...     104.000000      94.000000   \n",
       "\n",
       "           K703-09_1      K704-02_1      K704-11_1      K704-11_2  \\\n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000   \n",
       "mean        6.306285       5.852868      14.671818      13.875118   \n",
       "std         5.251719       4.826105      11.959692      11.562566   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         1.800000       1.838608       3.000000       2.000000   \n",
       "50%         5.000000       5.000000      13.000000      12.000000   \n",
       "75%         9.750878       9.000000      23.000000      21.000000   \n",
       "max        89.000000     114.000000     114.000000     100.000000   \n",
       "\n",
       "           K704-11_3      K704-12_1      K704-65_1      K704-65_2  \n",
       "count  209027.000000  209027.000000  209027.000000  209027.000000  \n",
       "mean       11.966330       6.460515      20.881299      15.376109  \n",
       "std        12.530202       5.632539      14.775188      13.395197  \n",
       "min         1.000000       1.000000       1.000000       1.000000  \n",
       "25%         1.000000       2.000000       7.000000       2.500000  \n",
       "50%         8.000000       5.000000      20.000000      13.000000  \n",
       "75%        19.000000       9.000000      32.000000      24.000000  \n",
       "max        83.000000      77.000000      87.000000     118.000000  \n",
       "\n",
       "[8 rows x 137 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate new distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of two points on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "from IPython.display import display\n",
    "\n",
    "def compute_and_visualize_distances(sensor_a, sensor_b):\n",
    "    osrm_server = \"http://router.project-osrm.org\"\n",
    "\n",
    "    # Compute the direct distance using the Haversine formula\n",
    "    direct_distance = geodesic((sensor_a['latitude'], sensor_a['longitude']), (sensor_b['latitude'], sensor_b['longitude'])).meters\n",
    "    \n",
    "    # Compute the routing distance using the OSRM API\n",
    "    request_url = f\"{osrm_server}/route/v1/driving/{sensor_a['longitude']},{sensor_a['latitude']};{sensor_b['longitude']},{sensor_b['latitude']}?overview=full&geometries=geojson\"\n",
    "    response = requests.get(request_url)\n",
    "    route_data = response.json()\n",
    "    \n",
    "    if route_data['code'] == 'Ok':\n",
    "        routing_distance = route_data['routes'][0]['distance']  # Distance in meters\n",
    "        route_geometry = route_data['routes'][0]['geometry']\n",
    "    else:\n",
    "        routing_distance = float('inf')  # An arbitrary large number to denote failure to get distance\n",
    "        route_geometry = None\n",
    "    \n",
    "    # Create a map centered around the midpoint of the two sensors\n",
    "    midpoint = ((sensor_a['latitude'] + sensor_b['latitude']) / 2, (sensor_a['longitude'] + sensor_b['longitude']) / 2)\n",
    "    m = folium.Map(location=midpoint, zoom_start=13, tiles='CartoDB Positron')\n",
    "    \n",
    "    # Add markers for the two sensors\n",
    "    folium.Marker([sensor_a['latitude'], sensor_a['longitude']], popup=f\"Sensor A: {sensor_a['sensor_id']}\").add_to(m)\n",
    "    folium.Marker([sensor_b['latitude'], sensor_b['longitude']], popup=f\"Sensor B: {sensor_b['sensor_id']}\").add_to(m)\n",
    "    \n",
    "    # Draw a line for the direct distance\n",
    "    folium.PolyLine(\n",
    "        locations=[(sensor_a['latitude'], sensor_a['longitude']), (sensor_b['latitude'], sensor_b['longitude'])],\n",
    "        color='blue',\n",
    "        weight=2,\n",
    "        opacity=0.6,\n",
    "        tooltip=f\"Direct distance: {direct_distance:.2f} meters\"\n",
    "    ).add_to(m)\n",
    "    \n",
    "    # Draw a line for the routing distance if available\n",
    "    if route_geometry:\n",
    "        folium.PolyLine(\n",
    "            locations=[(coord[1], coord[0]) for coord in route_geometry['coordinates']],\n",
    "            color='green',\n",
    "            weight=2,\n",
    "            opacity=0.6,\n",
    "            tooltip=f\"Routing distance: {routing_distance:.2f} meters\"\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Display the map\n",
    "    display(m)\n",
    "\n",
    "    # Print distances\n",
    "    print(f\"Direct distance: {direct_distance:.2f} meters\")\n",
    "    print(f\"Routing distance: {routing_distance:.2f} meters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_37035b160a3f837b011c3f812c116c2a {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_37035b160a3f837b011c3f812c116c2a&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_37035b160a3f837b011c3f812c116c2a = L.map(\n",
       "                &quot;map_37035b160a3f837b011c3f812c116c2a&quot;,\n",
       "                {\n",
       "                    center: [34.155665, -118.450665],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 13,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_cfb2f6f0b755bd05810ee1b2dc9d4e3c = L.tileLayer(\n",
       "                &quot;https://cartodb-basemaps-{s}.global.ssl.fastly.net/light_all/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://cartodb.com/attributions\\&quot;\\u003eCartoDB\\u003c/a\\u003e, CartoDB \\u003ca target=\\&quot;_blank\\&quot; href =\\&quot;http://cartodb.com/attributions\\&quot;\\u003eattributions\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_37035b160a3f837b011c3f812c116c2a);\n",
       "        \n",
       "    \n",
       "            var marker_761530051c5fed5ba9884f26031cf16f = L.marker(\n",
       "                [34.15562, -118.4686],\n",
       "                {}\n",
       "            ).addTo(map_37035b160a3f837b011c3f812c116c2a);\n",
       "        \n",
       "    \n",
       "        var popup_16c2f83427dc20e79338edda0048b0b1 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_cbd49ef8862912e29907dd1edcba4fdc = $(`&lt;div id=&quot;html_cbd49ef8862912e29907dd1edcba4fdc&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Sensor A: 9&lt;/div&gt;`)[0];\n",
       "                popup_16c2f83427dc20e79338edda0048b0b1.setContent(html_cbd49ef8862912e29907dd1edcba4fdc);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_761530051c5fed5ba9884f26031cf16f.bindPopup(popup_16c2f83427dc20e79338edda0048b0b1)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_827153767911f783c2aa86f36ae73294 = L.marker(\n",
       "                [34.15571, -118.43273],\n",
       "                {}\n",
       "            ).addTo(map_37035b160a3f837b011c3f812c116c2a);\n",
       "        \n",
       "    \n",
       "        var popup_7472ace77261c2719b828dafa11f379d = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_96ddf0be7413cfb9f6ef5ab9b8888cd4 = $(`&lt;div id=&quot;html_96ddf0be7413cfb9f6ef5ab9b8888cd4&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Sensor B: 75&lt;/div&gt;`)[0];\n",
       "                popup_7472ace77261c2719b828dafa11f379d.setContent(html_96ddf0be7413cfb9f6ef5ab9b8888cd4);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_827153767911f783c2aa86f36ae73294.bindPopup(popup_7472ace77261c2719b828dafa11f379d)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var poly_line_af29533ae691f45b5566f12c4d2656bd = L.polyline(\n",
       "                [[34.15562, -118.4686], [34.15571, -118.43273]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 0.6, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 2}\n",
       "            ).addTo(map_37035b160a3f837b011c3f812c116c2a);\n",
       "        \n",
       "    \n",
       "            poly_line_af29533ae691f45b5566f12c4d2656bd.bindTooltip(\n",
       "                `&lt;div&gt;\n",
       "                     Direct distance: 3307.80 meters\n",
       "                 &lt;/div&gt;`,\n",
       "                {&quot;sticky&quot;: true}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            var poly_line_fdf83915e11e9c77c6609e0f830af7e2 = L.polyline(\n",
       "                [[34.155607, -118.46865], [34.155374, -118.468562], [34.154804, -118.468385], [34.154419, -118.468285], [34.153933, -118.468201], [34.153589, -118.468155], [34.153231, -118.468142], [34.152828, -118.468148], [34.152434, -118.468173], [34.15201, -118.468226], [34.151552, -118.468315], [34.151037, -118.468444], [34.150594, -118.468601], [34.150421, -118.468836], [34.149947, -118.469115], [34.149667, -118.469286], [34.149367, -118.469476], [34.149003, -118.469702], [34.148907, -118.469776], [34.148854, -118.469838], [34.148816, -118.469891], [34.148782, -118.469952], [34.148744, -118.470025], [34.148714, -118.470094], [34.148359, -118.469951], [34.148284, -118.469918], [34.148168, -118.469866], [34.14854, -118.469002], [34.148616, -118.468833], [34.148713, -118.468749], [34.148814, -118.468524], [34.148922, -118.468289], [34.148998, -118.468171], [34.149081, -118.468028], [34.149176, -118.467894], [34.149266, -118.467803], [34.149368, -118.467707], [34.149443, -118.467653], [34.149566, -118.467567], [34.14967, -118.467509], [34.149699, -118.467493], [34.149843, -118.467437], [34.149968, -118.467398], [34.150095, -118.467376], [34.150346, -118.467353], [34.150565, -118.467347], [34.151043, -118.467333], [34.15123, -118.467313], [34.151389, -118.467276], [34.151527, -118.467226], [34.151733, -118.467111], [34.151844, -118.467044], [34.151895, -118.467006], [34.15201, -118.466905], [34.152167, -118.46673], [34.152274, -118.466593], [34.152358, -118.466492], [34.152412, -118.466433], [34.152471, -118.466379], [34.15253, -118.466335], [34.152598, -118.46629], [34.152738, -118.466245], [34.152796, -118.466229], [34.152858, -118.466218], [34.152942, -118.466212], [34.153076, -118.466212], [34.153191, -118.466212], [34.153287, -118.466212], [34.153684, -118.466213], [34.15382, -118.466211], [34.153968, -118.466202], [34.154549, -118.466181], [34.154694, -118.466175], [34.154784, -118.466172], [34.15518, -118.466169], [34.155344, -118.466171], [34.155939, -118.466178], [34.156807, -118.466169], [34.157508, -118.466175], [34.157596, -118.466173], [34.157685, -118.466173], [34.15799, -118.466173], [34.158279, -118.466172], [34.158506, -118.466173], [34.158864, -118.466171], [34.15905, -118.466172], [34.159049, -118.466022], [34.15905, -118.465992], [34.15906, -118.465387], [34.159136, -118.464369], [34.159201, -118.463499], [34.159339, -118.461273], [34.159328, -118.461128], [34.159262, -118.460506], [34.159189, -118.460038], [34.159024, -118.459268], [34.158798, -118.458501], [34.158517, -118.457612], [34.158407, -118.457271], [34.158214, -118.456644], [34.158042, -118.45607], [34.157911, -118.455513], [34.157825, -118.455075], [34.15776, -118.454662], [34.157716, -118.45428], [34.157688, -118.45388], [34.157609, -118.452735], [34.157529, -118.451764], [34.157445, -118.451053], [34.157365, -118.450532], [34.157267, -118.45], [34.157133, -118.449453], [34.157006, -118.44901], [34.1568, -118.448427], [34.156702, -118.448163], [34.156554, -118.447817], [34.156138, -118.446927], [34.155846, -118.446281], [34.155765, -118.446101], [34.155704, -118.44596], [34.155656, -118.445845], [34.155609, -118.445721], [34.155565, -118.445599], [34.155525, -118.445483], [34.155476, -118.445336], [34.155429, -118.445189], [34.155388, -118.44505], [34.155351, -118.444905], [34.155313, -118.444755], [34.155281, -118.444603], [34.15525, -118.444458], [34.155223, -118.4443], [34.155196, -118.444142], [34.155153, -118.443817], [34.155126, -118.443531], [34.15511, -118.443231], [34.155111, -118.442763], [34.155122, -118.442433], [34.155154, -118.442086], [34.15519, -118.441793], [34.155284, -118.441253], [34.15545, -118.440279], [34.15549, -118.440015], [34.155528, -118.439715], [34.155564, -118.43924], [34.155577, -118.438808], [34.155562, -118.434805], [34.155552, -118.431432], [34.155547, -118.431057], [34.155531, -118.427995], [34.155563, -118.427391], [34.155674, -118.426585], [34.155802, -118.42591], [34.156264, -118.423941], [34.156433, -118.42319], [34.156482, -118.422956], [34.156532, -118.422677], [34.156579, -118.422367], [34.156623, -118.421997], [34.156671, -118.421479], [34.156693, -118.421015], [34.15668, -118.417419], [34.156576, -118.416585], [34.156496, -118.41546], [34.156442, -118.414922], [34.156359, -118.413925], [34.156363, -118.413795], [34.156452, -118.413794], [34.157054, -118.413792], [34.157045, -118.414698], [34.156997, -118.415358], [34.156948, -118.416153], [34.156851, -118.416988], [34.156862, -118.420939], [34.156846, -118.421436], [34.156799, -118.421959], [34.156753, -118.422362], [34.156709, -118.422677], [34.156641, -118.423069], [34.155901, -118.426411], [34.15581, -118.427001], [34.155739, -118.427618], [34.155721, -118.427946], [34.15571, -118.42834], [34.15572, -118.431059], [34.155723, -118.431432], [34.155726, -118.43273]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;green&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;green&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 0.6, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 2}\n",
       "            ).addTo(map_37035b160a3f837b011c3f812c116c2a);\n",
       "        \n",
       "    \n",
       "            poly_line_fdf83915e11e9c77c6609e0f830af7e2.bindTooltip(\n",
       "                `&lt;div&gt;\n",
       "                     Routing distance: 9009.10 meters\n",
       "                 &lt;/div&gt;`,\n",
       "                {&quot;sticky&quot;: true}\n",
       "            );\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x3006002d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct distance: 3307.80 meters\n",
      "Routing distance: 9009.10 meters\n"
     ]
    }
   ],
   "source": [
    "sensor_a = {'sensor_id': 9, 'latitude': 34.15562, 'longitude': -118.46860}  # Example coordinates for sensor A\n",
    "sensor_b = {'sensor_id': 75, 'latitude': 34.15571, 'longitude': -118.43273}  # Example coordinates for sensor B\n",
    "\n",
    "compute_and_visualize_distances(sensor_a, sensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sensors_and_group_by_trajectory(csv_file_path):\n",
    "    trajectory_groups = {'T1N': [], 'T1S': [], 'T2N': [], 'T2S': []}\n",
    "    with open(csv_file_path, mode='r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            trajectories = row['trajectory'].split('+')\n",
    "            for trajectory in trajectories:\n",
    "                trajectory_groups[trajectory].append(row)\n",
    "    return trajectory_groups\n",
    "\n",
    "def calculate_distances_osrm_grouped(sensors_grouped):\n",
    "    # osrm_server = \"http://router.project-osrm.org\"\n",
    "    osrm_server = \"http://127.0.0.1:5001\"\n",
    "    results = []\n",
    "\n",
    "    for trajectory, sensors in sensors_grouped.items():\n",
    "        # Prepare the combinations and wrap it with tqdm for the progress bar\n",
    "        sensor_pairs = list(permutations(sensors, 2))\n",
    "        for sensor_a, sensor_b in tqdm(sensor_pairs, desc=f\"Calculating distances for {trajectory}\"):\n",
    "            request_url = f\"{osrm_server}/route/v1/driving/{sensor_a['longitude']},{sensor_a['latitude']};{sensor_b['longitude']},{sensor_b['latitude']}?overview=false\"\n",
    "            \n",
    "            response = requests.get(request_url)\n",
    "            route_data = response.json()\n",
    "            \n",
    "            if route_data['code'] == 'Ok':\n",
    "                cost = route_data['routes'][0]['distance']  # Distance in meters\n",
    "            else:\n",
    "                cost = float('inf')  # Indicate failure\n",
    "            \n",
    "            results.append({\n",
    "                'trajectory': trajectory,\n",
    "                'from': sensor_a['sensor_id'],\n",
    "                'to': sensor_b['sensor_id'],\n",
    "                'cost': cost\n",
    "            })\n",
    "            # print(f\"From {sensor_a['sensor_id']} to {sensor_b['sensor_id']} cost: {cost}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/Hauge/location_std.csv'\n",
    "sensors_grouped = read_sensors_and_group_by_trajectory(csv_file_path)\n",
    "results = calculate_distances_osrm_grouped(sensors_grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save distances betwee each sensor on the same trajectory into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Hauge/distances.csv', mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['trajectory', 'from', 'to', 'cost'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METR-LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sensors(csv_file_path):\n",
    "    sensors = []\n",
    "    with open(csv_file_path, mode='r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            sensors.append(row)\n",
    "    return sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances_osrm(sensors):\n",
    "    results = []\n",
    "    osrm_server = \"http://router.project-osrm.org\"  # Example server, replace with your own if you have one\n",
    "    # osrm_server = \"http://127.0.0.1:5001\"\n",
    "    for sensor_a in tqdm(sensors, desc=\"Calculating distances\"):\n",
    "        for sensor_b in sensors:\n",
    "            if sensor_a['sensor_id'] == sensor_b['sensor_id']:\n",
    "                cost = 0.0  # Cost is zero when it's the same sensor\n",
    "            else:\n",
    "                # Constructing the request URL\n",
    "                request_url = f\"{osrm_server}/route/v1/driving/{sensor_a['longitude']},{sensor_a['latitude']};{sensor_b['longitude']},{sensor_b['latitude']}?overview=false\"\n",
    "                print(request_url)\n",
    "                # Making the request to the OSRM API\n",
    "                response = requests.get(request_url)\n",
    "                route_data = response.json()\n",
    "                \n",
    "                # Parsing the distance from the response\n",
    "                # Note: Make sure to handle any errors or unexpected response formats in a real application\n",
    "                if route_data['code'] == 'Ok':\n",
    "                    cost = route_data['routes'][0]['distance']  # Distance in meters\n",
    "                else:\n",
    "                    cost = float('inf')  # An arbitrary large number to denote failure to get distance\n",
    "                # print(cost)\n",
    "            results.append({'from': sensor_a['sensor_id'], 'to': sensor_b['sensor_id'], 'cost': cost})\n",
    "            # print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/METRLA/graph_sensor_locations.csv'\n",
    "output_csv_file_path = 'data/METRLA/distances_la_route.csv'\n",
    "\n",
    "sensors = read_sensors(csv_file_path)\n",
    "distance_results = calculate_distances_osrm(sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_csv_file_path, mode='w', newline='') as csvfile:\n",
    "    fieldnames = ['from', 'to', 'cost']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for result in distance_results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Distances saved to {output_csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PeMS-BAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data/PEMSBAY/graph_sensor_locations_bay.csv'\n",
    "output_csv_file_path = 'data/PEMSBAY/distances_bay_route.csv'\n",
    "sensors = read_sensors(csv_file_path)\n",
    "distance_results = calculate_distances_osrm(sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_csv_file_path, mode='w', newline='') as csvfile:\n",
    "    fieldnames = ['from', 'to', 'cost']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for result in distance_results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Distances saved to {output_csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METR-LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df = pd.read_csv('data/METRLA/distances_la_route.csv')\n",
    "df = pd.read_hdf('data/METRLA/metr-la.h5')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(dist_mx_array, normalized_k=0.1):\n",
    "    # Calculate the standard deviation as theta for normalization\n",
    "    distances = dist_mx_array[~np.isinf(dist_mx_array)].flatten()\n",
    "    std = distances.std()\n",
    "    adj_mx_array = np.exp(-np.square(dist_mx_array / std))\n",
    "    \n",
    "    # Set entries below a threshold to zero for sparsity\n",
    "    adj_mx_array[adj_mx_array < normalized_k] = 0\n",
    "    return adj_mx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = df.columns.astype(str).tolist()\n",
    "\n",
    "# Efficiently convert sensor IDs to index for quick lookup (now all as strings)\n",
    "sensor_id_to_index = {str(sensor_id): index for index, sensor_id in enumerate(sensor_ids)}\n",
    "\n",
    "# Initialize an empty distance matrix\n",
    "num_sensors = len(sensor_ids)\n",
    "dist_mx_array = np.full((num_sensors, num_sensors), np.inf)\n",
    "\n",
    "# Make sure 'from' and 'to' in distances_df are also strings\n",
    "distances_df['from'] = distances_df['from'].astype(str)\n",
    "distances_df['to'] = distances_df['to'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the distance matrix with the data from distances_df\n",
    "for _, row in distances_df.iterrows():\n",
    "    from_sensor = row['from']\n",
    "    to_sensor = row['to']\n",
    "    if from_sensor in sensor_id_to_index and to_sensor in sensor_id_to_index:\n",
    "        i = sensor_id_to_index[from_sensor]\n",
    "        j = sensor_id_to_index[to_sensor]\n",
    "        dist_mx_array[i, j] = row['cost']\n",
    "\n",
    "# Replace the diagonal with zeros since the distance from a sensor to itself is zero\n",
    "np.fill_diagonal(dist_mx_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx_array = get_adjacency_matrix(dist_mx_array).astype(np.float32)\n",
    "adj_mx = [sensor_ids, sensor_id_to_index, adj_mx_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/METRLA'\n",
    "file_name = 'adj_mx_new.pkl'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the adj_mx to a .pkl file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(adj_mx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PeMS-BAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load distances from CSV\n",
    "distances_df = pd.read_csv('data/PEMSBAY/distances_bay_route.csv')\n",
    "df = pd.read_hdf('data/PEMSBAY/pems-bay.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(dist_mx_array, normalized_k=0.1):\n",
    "    # Calculate the standard deviation as theta for normalization\n",
    "    distances = dist_mx_array[~np.isinf(dist_mx_array)].flatten()\n",
    "    std = distances.std()\n",
    "    adj_mx_array = np.exp(-np.square(dist_mx_array / std))\n",
    "    \n",
    "    # Set entries below a threshold to zero for sparsity\n",
    "    adj_mx_array[adj_mx_array < normalized_k] = 0\n",
    "    return adj_mx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = df.columns.astype(str).tolist()\n",
    "\n",
    "# Efficiently convert sensor IDs to index for quick lookup (now all as strings)\n",
    "sensor_id_to_index = {str(sensor_id): index for index, sensor_id in enumerate(sensor_ids)}\n",
    "\n",
    "# Initialize an empty distance matrix\n",
    "num_sensors = len(sensor_ids)\n",
    "dist_mx_array = np.full((num_sensors, num_sensors), np.inf)\n",
    "\n",
    "# Make sure 'from' and 'to' in distances_df are also strings\n",
    "distances_df['from'] = distances_df['from'].astype(str)\n",
    "distances_df['to'] = distances_df['to'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the distance matrix with the data from distances_df\n",
    "for _, row in distances_df.iterrows():\n",
    "    from_sensor = row['from']\n",
    "    to_sensor = row['to']\n",
    "    if from_sensor in sensor_id_to_index and to_sensor in sensor_id_to_index:\n",
    "        i = sensor_id_to_index[from_sensor]\n",
    "        j = sensor_id_to_index[to_sensor]\n",
    "        dist_mx_array[i, j] = row['cost']\n",
    "\n",
    "# Replace the diagonal with zeros since the distance from a sensor to itself is zero\n",
    "np.fill_diagonal(dist_mx_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx_array = get_adjacency_matrix(dist_mx_array).astype(np.float32)\n",
    "\n",
    "# Construct the adj_mx list as specified with the updated adj_mx_array\n",
    "adj_mx = [sensor_ids, sensor_id_to_index, adj_mx_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/PEMSBAY'\n",
    "file_name = 'adj_mx_new.pkl'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the adj_mx to a .pkl file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(adj_mx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleansing Hague data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K159-2018-7-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"data/Hauge/K159/K159-2018-7-1.csv\", delimiter=';')\n",
    "\n",
    "# Convert the first column to datetime, assuming the format \"day-month-year hours:minutes\"\n",
    "# Note: Adjust the 'dayfirst=True' parameter if your date format varies\n",
    "first_column_name = df.columns[0]\n",
    "df[first_column_name] = pd.to_datetime(df[first_column_name], dayfirst=True)\n",
    "\n",
    "# Format the date in the desired output format \"year-month-day hours:minutes\"\n",
    "df[first_column_name] = df[first_column_name].dt.strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"K159-2018-7-1_modified.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K159-2018-7-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"data/Hauge/K159/K159-2018-7-2.csv\", delimiter=';')\n",
    "df.loc[:len(df)-2, first_column_name] = pd.to_datetime(df[first_column_name].iloc[:-1], dayfirst=True).dt.strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"K159-2018-7-2_modified.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K182-2019-9-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"data/Hauge/K182/K182-2019-9-1.csv\", delimiter=';')\n",
    "\n",
    "# Convert the first column to datetime, assuming the format \"day-month-year hours:minutes\"\n",
    "# Note: Adjust the 'dayfirst=True' parameter if your date format varies\n",
    "first_column_name = df.columns[0]\n",
    "df[first_column_name] = pd.to_datetime(df[first_column_name], dayfirst=True)\n",
    "\n",
    "# Format the date in the desired output format \"year-month-day hours:minutes\"\n",
    "df[first_column_name] = df[first_column_name].dt.strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"K182-2019-9-1_modified.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K182-2019-9-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Hauge/K182/K182-2019-9-2.csv\", delimiter=';')\n",
    "df.loc[:len(df)-2, first_column_name] = pd.to_datetime(df[first_column_name].iloc[:-1], dayfirst=True).dt.strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"K182-2019-9-2_modified.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create adjacency matrix HAUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_dict = {\n",
    "        'K502': ['082', '051', '111', '081'],\n",
    "        'K504': ['08_2', '12_1', '02_1', '08_1', '11_1', '09_1', '12_2', '02_2', '04_2', '05_1', '04_1', '05_2'],\n",
    "        'K503': ['02_1', '03_1', '11_1', '07_1', '09_1', '05_1', '05_2', '11_2'],\n",
    "        'K263': ['052', '041', '061', '112', '051', '031', '111', '081'],\n",
    "        'K556': ['08_2', '02_1', '08_1', '11_1', '02_2', '10_1', '05_1', '04_1'],\n",
    "        'K557': ['08_2', '02_1', '08_1', '11_1', '02_2', '10_1'],\n",
    "        'K559': ['08_2', '12_1', '02_1', '08_1', '02_2', '10_1'],\n",
    "        'K561': ['08_2', '01_1', '02_1', '08_1', '09_1', '02_2', '10_1', '05_1', '05_2', '06_1'],\n",
    "        'K198': ['052', '061', '112', '021', '051', '111', '081'],\n",
    "        'K704': ['12_1', '02_1', '69_1', '11_1', '65_2', '11_3', '65_1', '11_2'],\n",
    "        'K702': ['03_1', '11_1', '05_1', '04_1', '05_2', '11_2'],\n",
    "        'K703': ['08_2', '02_1', '08_1', '03_1', '09_1', '05_1', '05_2'],\n",
    "        # 'K159': ['021', '051', '713', '111', '081'],\n",
    "        'K159': ['021', '051', '111', '081'],\n",
    "        'K182': ['621', '682', '681', '622', '121'],\n",
    "        'K183': ['082', '021', '051', '022', '111', '081'],\n",
    "        'K128': ['131', '161', '061', '112', '162', '062'],\n",
    "        # 'K139': ['101', '082', '021', '022', '121', '081'],\n",
    "        # 'K104': ['082', '021', '051', '022', '111', '081'],\n",
    "        'K101': ['621', '082', '051', '711', '622', '121', '081'],\n",
    "        'K206': ['091', '052', '101', '082', '061', '021', '051', '022', '092', '081'],\n",
    "        'K074': ['052', '051'],\n",
    "        'K414': ['091', '122', '082', '051', '011', '012', '121', '092', '081'],\n",
    "        'K415': ['061', '021', '081', '041'],\n",
    "        'K250': ['091', '101', '102', '021', '022', '092', '081']\n",
    "        }\n",
    "\n",
    "# Base path for the sensor data\n",
    "base_path = 'data/Hauge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify missing timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a complete DateTimeIndex from 2018-01-01 00:00:00 to 2019-12-31 23:55:00 with 5-minute intervals\n",
    "complete_index = pd.date_range(start='2018-01-01 00:00:00', end='2019-12-31 23:55:00', freq='5T')\n",
    "\n",
    "intersections = []\n",
    "missing_timestamps_dict = {}  # Initialize a dictionary to store missing timestamps for each sensor\n",
    "\n",
    "for sensor, codes in sensors_dict.items():\n",
    "    sensor_folder_path = os.path.join(base_path, sensor)\n",
    "    csv_files = glob.glob(f\"{sensor_folder_path}/{sensor}-201[89]-*-*.csv\")\n",
    "    all_data = []\n",
    "    for file in tqdm(csv_files, desc=f\"Processing {sensor}\"):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file, delimiter=';', parse_dates=[0], index_col=0)\n",
    "        \n",
    "        # Clean the column names of quotes\n",
    "        df.columns = [col.replace('\"', '').replace(\"'\", \"\") for col in df.columns]\n",
    "        df = df[~df.index.astype(str).str.contains('totaal')]\n",
    "    \n",
    "        df.index.name = None\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Keep only the filtered columns\n",
    "        df = df.loc[:, codes]\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        all_data.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    final_df = pd.concat(all_data)\n",
    "\n",
    "    # Sort the DataFrame by the index (date and time)\n",
    "    final_df.sort_index(inplace=True)\n",
    "    final_df.columns = [sensor + \"-\" + col for col in final_df.columns]\n",
    "    final_df = final_df[final_df.index.year.isin([2018, 2019])]\n",
    "    \n",
    "    # Identify missing timestamps\n",
    "    missing_timestamps = complete_index.difference(final_df.index)\n",
    "    \n",
    "    # Store the missing timestamps in the dictionary\n",
    "    missing_timestamps_dict[sensor] = missing_timestamps\n",
    "\n",
    "    # Print the first few rows to verify\n",
    "    # print(final_df.head())\n",
    "#     intersections.append(final_df)\n",
    "\n",
    "# hague = pd.concat(intersections, axis=1)\n",
    "# hague = hague.sort_index(axis=1)\n",
    "# missing_timestamps_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the missing timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert datetime objects to strings in missing_timestamps_dict\n",
    "for sensor, timestamps in missing_timestamps_dict.items():\n",
    "    missing_timestamps_dict[sensor] = [timestamp.isoformat() for timestamp in timestamps]\n",
    "\n",
    "# Save missing_timestamps_dict to a JSON file\n",
    "with open('missing_timestamps.json', 'w') as f:\n",
    "    json.dump(missing_timestamps_dict, f, indent=4)\n",
    "\n",
    "# The file missing_timestamps.json now contains the missing timestamps data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare and generate the standardized data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections = []\n",
    "\n",
    "for sensor, codes in sensors_dict.items():\n",
    "    sensor_folder_path = os.path.join(base_path, sensor)\n",
    "    print(sensor_folder_path)\n",
    "\n",
    "    # List all CSV files in the sensor folder for the date range 2018-01 to 2019-12\n",
    "    csv_files = glob.glob(f\"{sensor_folder_path}/{sensor}-201[89]-*-*.csv\")\n",
    "    all_data = []\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file, delimiter=';', parse_dates=[0], index_col=0)\n",
    "        \n",
    "        # Clean the column names of quotes\n",
    "        df.columns = [col.replace('\"', '').replace(\"'\", \"\") for col in df.columns]\n",
    "        df = df[~df.index.astype(str).str.contains('totaal')]\n",
    "    \n",
    "        df.index.name = None\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        # print(df.head())\n",
    "        \n",
    "        # Keep only the filtered columns\n",
    "        df = df.loc[:, codes]\n",
    "        # print(df.head())\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        all_data.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    final_df = pd.concat(all_data)\n",
    "\n",
    "    # Sort the DataFrame by the index (date and time)\n",
    "    final_df.sort_index(inplace=True)\n",
    "    final_df.columns = [sensor + \"-\" + col for col in final_df.columns]\n",
    "    final_df = final_df[final_df.index.year.isin([2018, 2019])]\n",
    "    \n",
    "\n",
    "    # Print the first few rows to verify\n",
    "    # print(final_df.head())\n",
    "    non_unique_indices = final_df.index.duplicated(keep=False)\n",
    "    non_unique_rows = final_df[non_unique_indices]\n",
    "\n",
    "    if not non_unique_rows.empty:\n",
    "        print(non_unique_rows)\n",
    "    intersections.append(final_df)\n",
    "# hague = pd.concat(intersections, axis=1)\n",
    "# hague = hague.sort_index(axis=1)\n",
    "\n",
    "# hague.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hague = pd.concat(intersections, axis=1)\n",
    "hague = hague.sort_index(axis=1)\n",
    "\n",
    "hague.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hague.to_csv(\"data/Hauge/hague.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to impute the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only select the columns with missing values < 34%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_percentage = hague.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nan_percentage.sort_values(ascending=False)[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_below_34_nan = nan_percentage[nan_percentage < 34].index.tolist()\n",
    "\n",
    "# Selecting the columns in 'hague' DataFrame where the NaN percentage is less than 34%\n",
    "filtered_hague = hague[columns_below_34_nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation based on https://www.geo.fu-berlin.de/en/v/soga-py/Advanced-statistics/time-series-analysis/Dealing-with-missing-values/Imputing-missing-values/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_NA_inter = filtered_hague.interpolate(method=\"time\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_NA_bfill = temp_NA_inter.fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_NA_bfill.to_hdf('data/Hauge/hague_filled.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new adjacency matrix Hague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df = pd.read_csv('data/Hauge/distances.csv')\n",
    "df = pd.read_hdf('data/Hauge/hague_filled.h5')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = df.columns.astype(str).tolist()\n",
    "\n",
    "# Efficiently convert sensor IDs to index for quick lookup (now all as strings)\n",
    "sensor_id_to_index = {str(sensor_id): index for index, sensor_id in enumerate(sensor_ids)}\n",
    "\n",
    "# Initialize an empty distance matrix\n",
    "num_sensors = len(sensor_ids)\n",
    "dist_mx_array = np.full((num_sensors, num_sensors), np.inf)\n",
    "\n",
    "# Make sure 'from' and 'to' in distances_df are also strings\n",
    "distances_df['from'] = distances_df['from'].astype(str)\n",
    "distances_df['to'] = distances_df['to'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the distance matrix with the data from distances_df\n",
    "for _, row in distances_df.iterrows():\n",
    "    from_sensor = row['from']\n",
    "    to_sensor = row['to']\n",
    "    if from_sensor in sensor_id_to_index and to_sensor in sensor_id_to_index:\n",
    "        i = sensor_id_to_index[from_sensor]\n",
    "        j = sensor_id_to_index[to_sensor]\n",
    "        dist_mx_array[i, j] = row['cost']\n",
    "\n",
    "# Replace the diagonal with zeros since the distance from a sensor to itself is zero\n",
    "np.fill_diagonal(dist_mx_array, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(dist_mx_array, normalized_k=0.1):\n",
    "    # Calculate the standard deviation as theta for normalization\n",
    "    distances = dist_mx_array[~np.isinf(dist_mx_array)].flatten()\n",
    "    std = distances.std()\n",
    "    adj_mx_array = np.exp(-np.square(dist_mx_array / std))\n",
    "    \n",
    "    # Set entries below a threshold to zero for sparsity\n",
    "    adj_mx_array[adj_mx_array < normalized_k] = 0\n",
    "    return adj_mx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx_array = get_adjacency_matrix(dist_mx_array).astype(np.float32)\n",
    "\n",
    "# Construct the adj_mx list as specified with the updated adj_mx_array\n",
    "adj_mx = [sensor_ids, sensor_id_to_index, adj_mx_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the file path\n",
    "directory = 'data/Hauge'\n",
    "file_name = 'adj_mx.pkl'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the adj_mx to a .pkl file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(adj_mx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a smaller size of the Hague data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_hdf('data/Hauge/hague_filled.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df)\n",
    "\n",
    "# Calculate indices for 12.5th and 87.5th percentiles\n",
    "start_index = int(total_rows * 0.125)\n",
    "end_index = int(total_rows * 0.875)\n",
    "\n",
    "# Select the middle 75% of the rows\n",
    "middle_75_df = df.iloc[start_index:end_index]\n",
    "middle_75_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_75_df.to_hdf('data/Hauge/hague_filled_75.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Hauge to a compressed sensor datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/Hauge/Hague_comp_sensor_ref.xlsx'\n",
    "df1 = pd.read_excel(file_path)\n",
    "df2 = pd.read_csv('data/Hauge/hague.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframes(df1, df2):\n",
    "    # New dataframe to hold results\n",
    "    df3 = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over rows in df1\n",
    "    for idx, row in df1.iterrows():\n",
    "        intersection = row['Intersection']\n",
    "        original_columns = str(row['Original']).split(',')\n",
    "\n",
    "        # Create full column names in df2 and sum them\n",
    "        if len(original_columns) > 1:\n",
    "            new_column_name = intersection + '-' + row['New']\n",
    "            # Create a list of full names to search in df2\n",
    "            df2_column_names = [intersection + '-' + orig for orig in original_columns]\n",
    "            # Average the columns in df2 that are in our list if they exist\n",
    "            df3[new_column_name] = df2[df2_column_names].mean(axis=1)\n",
    "        else:\n",
    "            # Just copy the column from df2\n",
    "            df2_column_name = intersection + '-' + original_columns[0]\n",
    "            df3[df2_column_name] = df2[df2_column_name] if df2_column_name in df2.columns else pd.Series()\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = process_dataframes(df1, df2)\n",
    "df3.to_csv(\"data/Hauge/hague_comp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_percentage = df3.isna().mean() * 100\n",
    "print(nan_percentage.sort_values(ascending=False)[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_below_34_nan = nan_percentage[nan_percentage < 30].index.tolist()\n",
    "\n",
    "# Selecting the columns in 'hague' DataFrame where the NaN percentage is less than 34%\n",
    "filtered_hague = df3[columns_below_34_nan]\n",
    "filtered_hague.index = pd.to_datetime(filtered_hague.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_NA_inter = filtered_hague.interpolate(method=\"time\").copy()\n",
    "temp_NA_bfill = temp_NA_inter.fillna(method=\"bfill\")\n",
    "temp_NA_bfill.to_hdf('data/Hauge/hague_comp_filled.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New adj based on combined sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/HAUGE/distances.csv')\n",
    "df2 = pd.read_hdf('data/Hauge/hague_comp_filled.h5')\n",
    "df3 = pd.read_excel('data/Hauge/Hague_comp_sensor_ref.xlsx')\n",
    "df4 = pd.read_csv('data/Hauge/location_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_id(sensor_id, trajectory, df3):\n",
    "    # Split the sensor_id by '-'\n",
    "    parts = sensor_id.split('-')\n",
    "    if len(parts) != 2:\n",
    "        return None  # Return None if sensor_id does not match expected format\n",
    "    \n",
    "    # Find matching row in df3 with the same trajectory\n",
    "    mask = (df3['Intersection'] == parts[0]) & (df3['Representation'] == parts[1]) & (df3['Trajectory'] == trajectory)\n",
    "    if mask.any():\n",
    "        # If a matching row is found, replace with the 'New' value\n",
    "        return parts[0] + '-' + df3.loc[mask, 'New'].values[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>trajectory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K502-S1</td>\n",
       "      <td>52.051972</td>\n",
       "      <td>4.229278</td>\n",
       "      <td>T1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K502-051</td>\n",
       "      <td>52.051750</td>\n",
       "      <td>4.228972</td>\n",
       "      <td>T1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K502-111</td>\n",
       "      <td>52.052000</td>\n",
       "      <td>4.229806</td>\n",
       "      <td>T1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K504-N1</td>\n",
       "      <td>52.042250</td>\n",
       "      <td>4.240278</td>\n",
       "      <td>T1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>K504-11_1</td>\n",
       "      <td>52.042500</td>\n",
       "      <td>4.239972</td>\n",
       "      <td>T1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>K415-021</td>\n",
       "      <td>52.071609</td>\n",
       "      <td>4.341984</td>\n",
       "      <td>T2N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>K415-081</td>\n",
       "      <td>52.071553</td>\n",
       "      <td>4.341502</td>\n",
       "      <td>T2S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>K250-N1</td>\n",
       "      <td>52.067711</td>\n",
       "      <td>4.353475</td>\n",
       "      <td>T2N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>K250-N2</td>\n",
       "      <td>52.067414</td>\n",
       "      <td>4.353624</td>\n",
       "      <td>T2N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>K250-S1</td>\n",
       "      <td>52.067564</td>\n",
       "      <td>4.352998</td>\n",
       "      <td>T2S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor_id   latitude  longitude trajectory\n",
       "1      K502-S1  52.051972   4.229278        T1N\n",
       "2     K502-051  52.051750   4.228972        T1N\n",
       "3     K502-111  52.052000   4.229806        T1N\n",
       "11     K504-N1  52.042250   4.240278        T1N\n",
       "14   K504-11_1  52.042500   4.239972        T1N\n",
       "..         ...        ...        ...        ...\n",
       "164   K415-021  52.071609   4.341984        T2N\n",
       "165   K415-081  52.071553   4.341502        T2S\n",
       "167    K250-N1  52.067711   4.353475        T2N\n",
       "169    K250-N2  52.067414   4.353624        T2N\n",
       "171    K250-S1  52.067564   4.352998        T2S\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_transform_or_keep_original(row, df3):\n",
    "    trajectories = row['trajectory'].split('+')\n",
    "    new_ids = []\n",
    "\n",
    "    for trajectory in trajectories:\n",
    "        new_id = transform_id(row['sensor_id'], trajectory, df3)\n",
    "        if new_id is not None:\n",
    "            new_ids.append(new_id)\n",
    "\n",
    "    # If no new ID was found for either trajectory, keep the original sensor_id\n",
    "    if not new_ids:\n",
    "        new_ids.append(row['sensor_id'])\n",
    "\n",
    "    # Return a list of dictionaries for each new_id to expand into new rows\n",
    "    return [{'sensor_id': new_id, 'latitude': row['latitude'], 'longitude': row['longitude'], 'trajectory': trajectory} for new_id, trajectory in zip(new_ids, trajectories)]\n",
    "\n",
    "# Apply the transformation to generate new rows\n",
    "expanded_rows = df4.apply(lambda row: apply_transform_or_keep_original(row, df3), axis=1)\n",
    "\n",
    "# Flatten the list of lists into a single DataFrame\n",
    "df4_expanded = pd.DataFrame([item for sublist in expanded_rows for item in sublist])\n",
    "\n",
    "# Keep only the sensor IDs that are present in the columns of df2\n",
    "df2_columns = set(df2.columns)\n",
    "df4_filtered = df4_expanded[df4_expanded['sensor_id'].isin(df2_columns)]\n",
    "df4_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_filtered.to_csv('data/Hauge/location_std_comp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['new_from'] = df1.apply(lambda row: transform_id(row['from'], row['trajectory'], df3), axis=1)\n",
    "df1['new_to'] = df1.apply(lambda row: transform_id(row['to'], row['trajectory'], df3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_columns = set(df2.columns)\n",
    "df4 = df1[(df1['new_from'].isin(df2_columns)) & (df1['new_to'].isin(df2_columns))]\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['from'] = df4['new_from']\n",
    "df4['to'] = df4['new_to']\n",
    "df4 = df4.drop(['new_from', 'new_to'], axis=1)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('data/Hauge/distances_comp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the adjacency matrix for the combined sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df = pd.read_csv('data/Hauge/distances_comp.csv')\n",
    "df = pd.read_hdf('data/Hauge/hague_comp_filled.h5')\n",
    "\n",
    "sensor_ids = df.columns.astype(str).tolist()\n",
    "\n",
    "# Efficiently convert sensor IDs to index for quick lookup (now all as strings)\n",
    "sensor_id_to_index = {str(sensor_id): index for index, sensor_id in enumerate(sensor_ids)}\n",
    "\n",
    "# Initialize an empty distance matrix\n",
    "num_sensors = len(sensor_ids)\n",
    "dist_mx_array = np.full((num_sensors, num_sensors), np.inf)\n",
    "\n",
    "# Make sure 'from' and 'to' in distances_df are also strings\n",
    "distances_df['from'] = distances_df['from'].astype(str)\n",
    "distances_df['to'] = distances_df['to'].astype(str)\n",
    "\n",
    "# Populate the distance matrix with the data from distances_df\n",
    "for _, row in distances_df.iterrows():\n",
    "    from_sensor = row['from']\n",
    "    to_sensor = row['to']\n",
    "    if from_sensor in sensor_id_to_index and to_sensor in sensor_id_to_index:\n",
    "        i = sensor_id_to_index[from_sensor]\n",
    "        j = sensor_id_to_index[to_sensor]\n",
    "        dist_mx_array[i, j] = row['cost']\n",
    "\n",
    "# Replace the diagonal with zeros since the distance from a sensor to itself is zero\n",
    "np.fill_diagonal(dist_mx_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(dist_mx_array, normalized_k=0.1):\n",
    "    # Calculate the standard deviation as theta for normalization\n",
    "    distances = dist_mx_array[~np.isinf(dist_mx_array)].flatten()\n",
    "    std = distances.std()\n",
    "    adj_mx_array = np.exp(-np.square(dist_mx_array / std))\n",
    "    \n",
    "    # Set entries below a threshold to zero for sparsity\n",
    "    adj_mx_array[adj_mx_array < normalized_k] = 0\n",
    "    return adj_mx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx_array = get_adjacency_matrix(dist_mx_array).astype(np.float32)\n",
    "\n",
    "# Construct the adj_mx list as specified with the updated adj_mx_array\n",
    "adj_mx = [sensor_ids, sensor_id_to_index, adj_mx_array]\n",
    "adj_mx[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the file path\n",
    "directory = 'data/Hauge'\n",
    "file_name = 'adj_mx_comp1.pkl'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the adj_mx to a .pkl file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(adj_mx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the adjacency matrix for the combined sensors with direction applied to only count in foward direction that are connected by lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df = pd.read_csv('data/Hauge/distances_comp_directed.csv')\n",
    "df = pd.read_hdf('data/Hauge/hague_comp_filled.h5')\n",
    "\n",
    "sensor_ids = df.columns.astype(str).tolist()\n",
    "\n",
    "# Efficiently convert sensor IDs to index for quick lookup (now all as strings)\n",
    "sensor_id_to_index = {str(sensor_id): index for index, sensor_id in enumerate(sensor_ids)}\n",
    "\n",
    "# Initialize an empty distance matrix\n",
    "num_sensors = len(sensor_ids)\n",
    "dist_mx_array = np.full((num_sensors, num_sensors), np.inf)\n",
    "\n",
    "# Make sure 'from' and 'to' in distances_df are also strings\n",
    "distances_df['from'] = distances_df['from'].astype(str)\n",
    "distances_df['to'] = distances_df['to'].astype(str)\n",
    "\n",
    "# Populate the distance matrix with the data from distances_df\n",
    "for _, row in distances_df.iterrows():\n",
    "    from_sensor = row['from']\n",
    "    to_sensor = row['to']\n",
    "    if from_sensor in sensor_id_to_index and to_sensor in sensor_id_to_index:\n",
    "        i = sensor_id_to_index[from_sensor]\n",
    "        j = sensor_id_to_index[to_sensor]\n",
    "        dist_mx_array[i, j] = row['cost']\n",
    "\n",
    "# Replace the diagonal with zeros since the distance from a sensor to itself is zero\n",
    "np.fill_diagonal(dist_mx_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(dist_mx_array, normalized_k=0.1):\n",
    "    # Calculate the standard deviation as theta for normalization\n",
    "    distances = dist_mx_array[~np.isinf(dist_mx_array)].flatten()\n",
    "    std = distances.std()\n",
    "    adj_mx_array = np.exp(-np.square(dist_mx_array / std))\n",
    "    \n",
    "    # Set entries below a threshold to zero for sparsity\n",
    "    adj_mx_array[adj_mx_array < normalized_k] = 0\n",
    "    return adj_mx_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx_array = get_adjacency_matrix(dist_mx_array).astype(np.float32)\n",
    "\n",
    "# Construct the adj_mx list as specified with the updated adj_mx_array\n",
    "adj_mx = [sensor_ids, sensor_id_to_index, adj_mx_array]\n",
    "adj_mx[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the file path\n",
    "directory = 'data/Hauge'\n",
    "file_name = 'adj_mx_comp2.pkl'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the adj_mx to a .pkl file\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(adj_mx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a copy of adjacency matrix to csv file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METR-LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/METRLA/adj_mx.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')\n",
    "np.savetxt(\"data/METRLA/adj_mx.csv\", adj_mx[2], delimiter=\",\", fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/METRLA/adj_mx_new1.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')\n",
    "np.savetxt(\"data/METRLA/adj_mx_new1.csv\", adj_mx[2], delimiter=\",\", fmt='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PeMS-BAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/PEMSBAY/adj_mx_bay.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')\n",
    "np.savetxt(\"data/PEMSBAY/adj_mx_bay.csv\", adj_mx[2], delimiter=\",\", fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/PEMSBAY/adj_mx_new1.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')\n",
    "np.savetxt(\"data/PEMSBAY/adj_mx_new1.csv\", adj_mx[2], delimiter=\",\", fmt='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/Hauge/adj_mx1.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')\n",
    "np.savetxt(\"data/Hauge/adj_mx1.csv\", adj_mx[2], delimiter=\",\", fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/Hauge/adj_mx_comp1.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')\n",
    "np.savetxt(\"data/Hauge/adj_mx_comp1.csv\", adj_mx[2], delimiter=\",\", fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/Hauge/adj_mx_comp2.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    adj_mx = pickle.load(f, encoding='latin1')\n",
    "np.savetxt(\"data/Hauge/adj_mx_comp2.csv\", adj_mx[2], delimiter=\",\", fmt='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A even smaller size dataset Hague for cost model (memory saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('data/Hauge/hague_comp_filled.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middle 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate indices for the middle 20%\n",
    "start_idx = int(len(df) * 0.40)\n",
    "end_idx = int(len(df) * 0.60)\n",
    "\n",
    "# Select the middle 20% chunk\n",
    "df_middle_20_percent = df.iloc[start_idx:end_idx]\n",
    "\n",
    "# Convert index to datetime\n",
    "df_middle_20_percent.index = pd.to_datetime(df_middle_20_percent.index, unit='ns')\n",
    "\n",
    "# Save to HDF5 file\n",
    "df_middle_20_percent.to_hdf('data/Hauge/hague_comp_filled_20_2.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate indices for the middle 20%\n",
    "start_idx = int(len(df) * 0.0)\n",
    "end_idx = int(len(df) * 0.2)\n",
    "\n",
    "# Select the middle 20% chunk\n",
    "df_first_20_percent = df.iloc[start_idx:end_idx]\n",
    "\n",
    "# Convert index to datetime\n",
    "df_first_20_percent.index = pd.to_datetime(df_first_20_percent.index, unit='ns')\n",
    "\n",
    "# Save to HDF5 file\n",
    "df_first_20_percent.to_hdf('data/Hauge/hague_comp_filled_20_3.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations of all sensors in 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Load the CSV data\n",
    "csv_file_path = 'data/METRLA/graph_sensor_locations.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a folium map centered around the mean latitude and longitude\n",
    "center_lat = data['latitude'].mean()\n",
    "center_lon = data['longitude'].mean()\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=10, tiles='OpenStreetMap')\n",
    "\n",
    "# Add sensor locations to the map\n",
    "for idx, row in data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.7,\n",
    "        popup=f'Sensor ID: {row[\"sensor_id\"]}'\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save('sensor_locations_map_METRLA.html')\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Load the CSV data\n",
    "csv_file_path = 'data/PEMSBAY/graph_sensor_locations_bay.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a folium map centered around the mean latitude and longitude\n",
    "center_lat = data['latitude'].mean()\n",
    "center_lon = data['longitude'].mean()\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=10, tiles='OpenStreetMap')\n",
    "\n",
    "# Add sensor locations to the map\n",
    "for idx, row in data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.7,\n",
    "        popup=f'Sensor ID: {row[\"sensor_id\"]}'\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save('sensor_locations_map_bay.html')\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Load the CSV data\n",
    "csv_file_path = 'data/Hauge/location_std.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Extract the first trajectory if multiple are concatenated\n",
    "data['trajectory'] = data['trajectory'].apply(lambda x: x.split('+')[0])\n",
    "\n",
    "# Predefined colors for the trajectories\n",
    "color_mapping = {\n",
    "    'T1N': 'red',\n",
    "    'T1S': 'orange',\n",
    "    'T2N': 'blue',\n",
    "    'T2S': 'purple'\n",
    "}\n",
    "\n",
    "# Create a folium map centered around the mean latitude and longitude\n",
    "center_lat = data['latitude'].mean()\n",
    "center_lon = data['longitude'].mean()\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=10, tiles='OpenStreetMap')\n",
    "\n",
    "# Add sensor locations to the map with specific colors for each trajectory\n",
    "for idx, row in data.iterrows():\n",
    "    trajectory = row['trajectory']\n",
    "    color = color_mapping.get(trajectory, 'gray')  # Default to gray if trajectory is not in color_mapping\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f'Sensor ID: {row[\"sensor_id\"]}, Trajectory: {row[\"trajectory\"]}'\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save('sensor_locations_map_Hauge.html')\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
