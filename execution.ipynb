{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.dataname == METRLA\n",
      "\n",
      "trainXS.shape (11972, 1, 207, 12)\n",
      "trainYS.shape (11972, 12, 207, 1)\n",
      "testXS.shape (22266, 1, 207, 12)\n",
      "testYS.shape (22266, 12, 207, 1)\n",
      "\n",
      "spatialSplit_unseen all: trn/val/tst : 207 : 144 / 21 / 42\n",
      "spatialSplit_allNod all: trn/val/tst : 207 : 144 / 165 / 207\n",
      "spatialSplit_unseen.i_tst [ 57  31  65 140  89 158  30  86  92 141 126 153  13  77 188 179 177 190\n",
      "  33  62 122 107  88  54 139 100  16 115 164  40   0  73   8 202 157 156\n",
      " 123 113  64  15 125   9]\n",
      "\n",
      "train.shape torch.Size([6841, 1, 144, 12]) torch.Size([6841, 12, 144, 1])\n",
      "train_model.shape torch.Size([5131, 1, 144, 12]) torch.Size([5131, 12, 144, 1])\n",
      "val_u.shape torch.Size([5131, 1, 21, 12]) torch.Size([5131, 12, 21, 1])\n",
      "val_a.shape torch.Size([5131, 1, 165, 12]) torch.Size([5131, 12, 165, 1])\n",
      "tst_u.shape torch.Size([22266, 1, 42, 12]) torch.Size([22266, 12, 42, 1])\n",
      "tst_a.shape torch.Size([22266, 1, 207, 12]) torch.Size([22266, 12, 207, 1])\n",
      "\n",
      "adj_train length of 2 torch.Size([144, 144])\n",
      "adj_val_u length of 2 torch.Size([21, 21])\n",
      "adj_val_a length of 2 torch.Size([165, 165])\n",
      "adj_tst_u length of 2 torch.Size([42, 42])\n",
      "adj_tst_a length of 2 torch.Size([207, 207])\n",
      "\n",
      "pretrn_iter.dataset.tensors[0].shape torch.Size([144, 6841])\n",
      "preval_iter.dataset.tensors[0].shape torch.Size([165, 6841])\n",
      "\n",
      "pretrainModel Started ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m P\u001b[38;5;241m.\u001b[39mis_tune \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Execute the experiment script\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m experiment\u001b[38;5;241m.\u001b[39mmain(P)\n",
      "File \u001b[0;32m~/Desktop/master_graduation_project/experiment.py:959\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(P)\u001b[0m\n\u001b[1;32m    957\u001b[0m         encoder_log \u001b[38;5;241m=\u001b[39m pretrainModel(P, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrn_iter, preval_iter, adj_train, adj_val_a, device_cpu, spatialSplit_allNod, mongodb)\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 959\u001b[0m         encoder_log \u001b[38;5;241m=\u001b[39m pretrainModel(P, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrn_iter, preval_iter, adj_train, adj_val_a, device_gpu, spatialSplit_allNod, mongodb)\n\u001b[1;32m    961\u001b[0m model_log \u001b[38;5;241m=\u001b[39m trainModel(P, P\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    962\u001b[0m     train_iter, train_model_iter, val_u_iter, val_a_iter,\n\u001b[1;32m    963\u001b[0m     adj_train, adj_val_u, adj_val_a,\n\u001b[1;32m    964\u001b[0m     spatialSplit_unseen, spatialSplit_allNod, device_cpu, device_gpu, mongodb)\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m P\u001b[38;5;241m.\u001b[39mis_tune \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/master_graduation_project/experiment.py:304\u001b[0m, in \u001b[0;36mpretrainModel\u001b[0;34m(P, name, pretrain_iter, preval_iter, adj_train, adj_val, device, spatialSplit_allNod, mongodb)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m P\u001b[38;5;241m.\u001b[39mexample_verbose:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAugmented input for input smoothing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 304\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcontrast(x1,x2, adj_train, adj_train, \u001b[38;5;241m0\u001b[39m, P\u001b[38;5;241m.\u001b[39mexample_verbose)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[1;32m    307\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Desktop/master_graduation_project/encoder.py:180\u001b[0m, in \u001b[0;36mContrastive_FeatureExtractor_conv.contrast\u001b[0;34m(self, x1, x2, support1, support2, sensor_idx_start, is_example)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrast\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2, support1, support2, sensor_idx_start, is_example):\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    x1 and x2 are two input samples\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    support1 and support2 are adjacency matrix for each sample\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    An additional projection head is applied to conduct loss calculation\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x1, support1, is_example)\n\u001b[1;32m    181\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x2, support2, is_example)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# Projection\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/master_graduation_project/encoder.py:135\u001b[0m, in \u001b[0;36mContrastive_FeatureExtractor_conv.forward\u001b[0;34m(self, x, support, is_example)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_example \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m--> 135\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n\u001b[1;32m    136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03mIf the sampler is enabled, the input x is sampled by half of latent features\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2484\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import experiment\n",
    "\n",
    "for i in range(1):\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "    P = type('Parameters', (object,), {})()\n",
    "    P.dataname = 'METRLA'\n",
    "    P.model = 'LSTM'\n",
    "    P.pre_model = 'TCN'\n",
    "    P.track_id = 0\n",
    "    P.replication = i + 1\n",
    "    P.seed = 10\n",
    "\n",
    "    P.t_train = 0.2\n",
    "    P.t_val = 0.15\n",
    "    P.s_train = 0.7\n",
    "    P.s_val = 0.1\n",
    "    P.fold = 2\n",
    "\n",
    "    P.timestep_in = 12\n",
    "    P.timestep_out = 12\n",
    "    P.n_channel = 1\n",
    "    P.batch_size = 64\n",
    "\n",
    "    P.lstm_hidden_dim = 128\n",
    "    P.lstm_layers = 2\n",
    "    P.lstm_dropout = 0.2\n",
    "    P.gwnet_is_adp_adj = True\n",
    "    P.gwnet_is_SGA = False\n",
    "\n",
    "    P.adj_type = 'doubletransition'\n",
    "    P.adj_method = 1\n",
    "    P.adj_diag = 0\n",
    "    P.cost_kernals = [1, 2, 4, 8, 16]\n",
    "    P.cost_alpha = 0.5\n",
    "    P.cl_temperature = 1.4\n",
    "    P.is_pretrain = True\n",
    "    P.is_GCN_encoder = False\n",
    "    P.is_GCN_after_CL = False\n",
    "    P.gcn_order = 2\n",
    "    P.gcn_dropout = 0\n",
    "    P.augmentation = 'input_smoothing'\n",
    "    P.temporal_shifting_r = 0.8\n",
    "    P.input_smoothing_r = 0.9\n",
    "    P.input_smoothing_e = 20\n",
    "    P.encoder_to_model_ratio = 1\n",
    "    P.is_concat_encoder_model = True\n",
    "    P.is_layer_after_concat = False\n",
    "    P.is_always_augmentation = True\n",
    "\n",
    "    P.tolerance = 10\n",
    "    P.learn_rate = 0.001\n",
    "    P.pretrain_epoch = 2\n",
    "    P.train_epoch = 2\n",
    "    P.weight_decay = 0\n",
    "    P.is_testunseen = True\n",
    "    P.train_model_datasplit = 'B'\n",
    "    P.train_encoder_on = 'gpu'\n",
    "\n",
    "    P.is_mongo = True\n",
    "    P.example_verbose = False\n",
    "    P.is_tune = True\n",
    "\n",
    "    # Execute the experiment script\n",
    "    experiment.main(P)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
