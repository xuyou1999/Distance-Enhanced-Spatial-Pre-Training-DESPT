{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.dataname == EXAMPLE\n",
      "\n",
      "First row at 10 am: [68.25       65.125      31.75       49.75       48.5        58.75\n",
      " 67.         62.5        55.         13.28571429 58.125      64.75\n",
      " 17.         66.5        10.25       43.75       33.         52.875\n",
      " 59.875      63.875     ]\n",
      "\n",
      "Second row at 10:05: [68.125 65.125 26.875 51.    45.    59.125 64.5   65.    60.375 11.\n",
      " 62.5   63.75  20.75  67.25   7.5   44.5   33.    52.875 63.875 63.75 ]\n",
      "data.shape: (192, 20)\n",
      "\n",
      "First row at 10 am after scaling: [ 0.94965521  0.75991885 -1.26646543 -0.17358402 -0.24947856  0.37285669\n",
      "  0.87376067  0.60054031  0.14517306 -2.38753624  0.33490941  0.73715049\n",
      " -2.16202103  0.84340285 -2.57185156 -0.53787782 -1.19057089  0.01615234\n",
      "  0.44116177  0.68402431]\n",
      "\n",
      "Second row at 10:05 after scaling: [ 0.94206575  0.75991885 -1.56245415 -0.09768948 -0.46198328  0.39562505\n",
      "  0.72197158  0.7523294   0.47151959 -2.52631483  0.60054031  0.67643486\n",
      " -1.9343374   0.88893957 -2.73881955 -0.4923411  -1.19057089  0.01615234\n",
      "  0.68402431  0.67643486]\n",
      "\n",
      "First sensor data: [ 0.94965521  0.94206575  0.99519193  0.99519193  0.94206575  0.99519193\n",
      "  0.99519193  0.90411848  0.95471484  0.94965521  0.8602683   0.97242357\n",
      "  0.83328358  0.87376067  0.77931412  0.88135012  0.87376067  0.81979121\n",
      "  0.83581339  0.83581339  0.94206575  0.77931412  0.86617121  0.90411848\n",
      "  0.8509923   0.86701448  0.81304503  0.75907558  0.82822394  0.83328358\n",
      "  0.79027667  0.80629885  0.71438213  0.75907558  0.64607704  0.73209085\n",
      "  0.7523294   0.69920322  0.54994395  0.67643486  0.52295923  0.5701825\n",
      "  0.69161376  0.72197158  0.69835995  0.69835995  0.64607704  0.6688454\n",
      "  0.78268721  0.65788286  0.63848758  0.79280649  0.82822394  0.69835995\n",
      "  0.6688454   0.54319777  0.73883703  0.7523294   0.69161376  0.64439049\n",
      "  0.60812977  0.69920322  0.78268721  0.84340285  0.70510613  0.74473994\n",
      "  0.80545558  0.80629885  0.63089813  0.83581339  0.84340285  0.72534467\n",
      "  0.84340285  0.74473994  0.75991885  0.72534467  0.84677594  0.73715049\n",
      "  0.69835995  0.63848758  0.72956104  0.70679267  0.79786612  0.82063449\n",
      "  0.81304503  0.8602683   0.73715049  0.81304503  0.86701448  0.79027667\n",
      "  0.82063449  0.76750831  0.84002976  0.82063449  0.8509923   0.75907558\n",
      "  0.79027667  0.7523294   0.81304503  0.78268721  0.84002976  0.86617121\n",
      "  0.88135012  0.80545558  0.87376067  0.86617121  0.89652903  0.82822394\n",
      "  0.79569771  0.84002976  0.91170794  0.89399921  0.84340285  0.84340285\n",
      "  0.79955267  0.65788286  0.87376067  0.84773968  0.78268721  0.72534467\n",
      "  0.69161376  0.83328358  0.71185231  0.66125595  0.4866985   0.32057378\n",
      "  0.55500359  0.71438213  0.6688454  -0.46198328  0.15191924  0.69161376\n",
      "  0.31214105 -0.33380583 -2.40488357 -2.35175739 -2.41162975 -2.60979883\n",
      " -2.40488357 -2.33657848 -2.40488357 -2.22273666 -2.37452575 -2.38464502\n",
      " -2.37789884 -2.2834523  -2.47318865 -2.32139957 -2.12154394 -2.24550503\n",
      " -1.94951631 -1.31959161  0.81304503  0.97495339  0.82822394  0.90074539\n",
      "  0.88135012  0.94796866  1.00278139  0.89652903  0.81979121  0.90411848\n",
      "  0.75991885  1.0179603   0.88725303  0.75991885  0.87376067  0.96820721\n",
      "  0.91929739  0.8602683   0.82822394  0.70028743  0.85858176  0.92773012\n",
      "  0.96483412  0.96483412  0.88725303  0.84340285  0.99519193  0.68402431\n",
      "  0.9344763   0.91170794  0.95471484  0.94206575  0.88050685  0.9344763\n",
      "  0.70173304  0.66462904  0.74473994  0.91929739  0.67137522  0.76750831]\n",
      "\n",
      "Second sensor data: [ 0.75991885  0.75991885  0.72197158  0.66462904  0.72956104  0.74473994\n",
      "  0.70510613  0.84340285  0.77931412  0.79027667  0.82653739  0.77509776\n",
      "  0.73209085  0.8509923   0.77931412  0.79027667  0.82063449  0.84677594\n",
      "  0.76750831  0.80545558  0.72956104  0.76582176  0.79027667  0.79786612\n",
      "  0.82822394  0.77931412  0.75991885  0.73883703  0.65366649  0.74558322\n",
      "  0.67643486  0.81979121  0.83581339  0.84677594  0.8509923   0.75907558\n",
      "  0.76750831  0.77509776  0.71185231  0.67643486  0.70510613  0.85858176\n",
      "  0.76582176  0.84340285  0.7523294   0.81304503  0.75991885  0.76750831\n",
      "  0.61571922  0.83328358  0.85858176  0.38803559  0.80545558  0.81304503\n",
      "  0.63848758  0.78606031  0.81979121  0.80437137  0.79027667  0.78606031\n",
      "  0.81304503  0.79786612  0.76750831  0.72956104  0.86701448  0.82822394\n",
      "  0.69920322  0.81304503  0.75991885  0.75991885  0.85858176  0.75907558\n",
      "  0.75991885  0.6688454   0.61571922  0.66462904  0.80629885  0.66125595\n",
      "  0.79955267  0.82822394  0.72197158  0.85858176  0.78268721  0.76750831\n",
      "  0.72630841  0.84677594  0.83581339  0.81304503  0.80629885  0.84340285\n",
      "  0.82063449  0.70679267  0.82653739  0.85858176  0.78268721  0.79280649\n",
      "  0.77509776  0.7523294   0.76750831  0.44116177  0.80629885  0.88135012\n",
      "  0.77509776  0.75991885  0.79280649  0.66125595  0.69161376  0.67643486\n",
      "  0.83906602  0.73209085  0.65366649  0.69161376  0.54741413  0.47910905\n",
      "  0.5701825   0.25311196  0.66125595  0.53548785  0.60812977  0.18565015\n",
      "  0.45634068  0.61740577  0.4959745   0.42598287  0.57777195  0.46224359\n",
      "  0.4866985   0.33490941  0.21347815  0.45634068  0.30033523  0.35008832\n",
      "  0.37285669  0.2396196   0.25142542  0.04651015 -0.03022766 -0.1432262\n",
      " -0.3810291   0.06168906  0.29696214  0.07686797 -0.21153129 -0.05046621\n",
      "  0.3475585   0.41080396  0.44116177  0.55500359  0.63764431  0.66125595\n",
      "  0.64607704  0.61571922  0.60054031  0.59042104  0.70679267  0.78606031\n",
      "  0.83581339  0.73209085  0.69920322  0.7523294   0.81304503  0.81304503\n",
      "  0.79786612  0.7523294   0.82653739  0.82063449  0.26660433  0.89399921\n",
      "  0.80545558  0.77931412  0.81304503  0.37285669  0.18312033  0.88725303\n",
      "  0.7523294   0.86617121  0.75907558  0.69161376  0.75991885  0.86617121\n",
      "  0.74558322  0.87376067  0.81304503  0.86617121  0.81979121  0.7523294\n",
      "  0.89399921  0.94796866  0.79786612  0.82822394  0.88050685  0.81304503]\n",
      "\n",
      "trainXS.shape (149, 1, 20, 12)\n",
      "trainYS.shape (149, 12, 20, 1)\n",
      "testXS.shape (9, 1, 20, 12)\n",
      "testYS.shape (9, 12, 20, 1)\n",
      "\n",
      "First instance trainXS for first sensor: [0.94965521 0.94206575 0.99519193 0.99519193 0.94206575 0.99519193\n",
      " 0.99519193 0.90411848 0.95471484 0.94965521 0.8602683  0.97242357]\n",
      "\n",
      "First instance trainYS for first sensor: [0.83328358 0.87376067 0.77931412 0.88135012 0.87376067 0.81979121\n",
      " 0.83581339 0.83581339 0.94206575 0.77931412 0.86617121 0.90411848]\n",
      "\n",
      "Last instance trainXS for first sensor: [-2.12154394 -2.24550503 -1.94951631 -1.31959161  0.81304503  0.97495339\n",
      "  0.82822394  0.90074539  0.88135012  0.94796866  1.00278139  0.89652903]\n",
      "\n",
      "First instance testXS for first sensor: [0.81979121 0.90411848 0.75991885 1.0179603  0.88725303 0.75991885\n",
      " 0.87376067 0.96820721 0.91929739 0.8602683  0.82822394 0.70028743]\n",
      "\n",
      "First instance trainXS for second sensor: [0.75991885 0.75991885 0.72197158 0.66462904 0.72956104 0.74473994\n",
      " 0.70510613 0.84340285 0.77931412 0.79027667 0.82653739 0.77509776]\n",
      "\n",
      "First instance trainYS for second sensor: [0.73209085 0.8509923  0.77931412 0.79027667 0.82063449 0.84677594\n",
      " 0.76750831 0.80545558 0.72956104 0.76582176 0.79027667 0.79786612]\n",
      "\n",
      "spatialSplit_unseen all: trn/val/tst : 20 : 12 / 4 / 4\n",
      "spatialSplit_allNod all: trn/val/tst : 20 : 12 / 16 / 20\n",
      "\n",
      "spatialSplit_unseen.i_trn [ 7 10  5  6  3 18 13  2 14  8 17 16]\n",
      "spatialSplit_unseen.i_val [19 12 11  1]\n",
      "spatialSplit_unseen.i_tst [ 0 15  4  9]\n",
      "spatialSplit_allNod.i_trn [ 7 10  5  6  3 18 13  2 14  8 17 16]\n",
      "spatialSplit_allNod.i_val [ 7 10  5  6  3 18 13  2 14  8 17 16 19 12 11  1]\n",
      "spatialSplit_allNod.i_tst [ 7 10  5  6  3 18 13  2 14  8 17 16 19 12 11  1  0 15  4  9]\n",
      "\n",
      "train.shape torch.Size([132, 1, 12, 12]) torch.Size([132, 12, 12, 1])\n",
      "train_model.shape torch.Size([17, 1, 12, 12]) torch.Size([17, 12, 12, 1])\n",
      "val_u.shape torch.Size([17, 1, 4, 12]) torch.Size([17, 12, 4, 1])\n",
      "val_a.shape torch.Size([17, 1, 16, 12]) torch.Size([17, 12, 16, 1])\n",
      "tst_u.shape torch.Size([9, 1, 4, 12]) torch.Size([9, 12, 4, 1])\n",
      "tst_a.shape torch.Size([9, 1, 20, 12]) torch.Size([9, 12, 20, 1])\n",
      "\n",
      "For veryfication purposes\n",
      "Corresponding first sensor in org order in test tensor([0.5702, 0.5550, 0.6233, 0.6916, 0.5432, 0.6992, 0.6613, 0.6511, 0.6613,\n",
      "        0.6688, 0.0010, 0.5019])\n",
      "Corresponding second sensor in org order in train tensor([0.3349, 0.6005, 0.5854, 0.5837, 0.4715, 0.6081, 0.4150, 0.2742, 0.4285,\n",
      "        0.5626, 0.3745, 0.5246])\n",
      "\n",
      "adjacency matrix after (or not) normalization\n",
      "frist row of the first adjacency matrix [0.         0.08902086 0.08869454 0.         0.         0.\n",
      " 0.         0.09385308 0.         0.         0.14376543 0.1127307\n",
      " 0.         0.21371688 0.         0.         0.         0.\n",
      " 0.         0.25821844]\n",
      "Entry (18,1): 0.0\n",
      "Entry (7,11): 0.20829022\n",
      "Entry (19,10): 0.42182183\n",
      "\n",
      "adj_train length of 2 torch.Size([12, 12])\n",
      "adj_val_u length of 2 torch.Size([4, 4])\n",
      "adj_val_a length of 2 torch.Size([16, 16])\n",
      "adj_tst_u length of 2 torch.Size([4, 4])\n",
      "adj_tst_a length of 2 torch.Size([20, 20])\n",
      "\n",
      "For veryfication purposes\n",
      "Corresponding Entry (18,1) tensor(0., device='mps:0')\n",
      "Corresponding Entry (7,11) tensor(0.0686, device='mps:0')\n",
      "Corresponding Entry (19,10) tensor(0.1247, device='mps:0')\n",
      "\n",
      "adjacency matrix after normalization\n",
      "train adj tensor([[0.0000, 0.0000, 0.0262, 0.0000, 0.0537, 0.0435, 0.0879, 0.2049, 0.0000,\n",
      "         0.0000, 0.0484, 0.0448],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0462, 0.0000, 0.0000, 0.0968, 0.1247, 0.0000, 0.0155, 0.0463, 0.0000,\n",
      "         0.0000, 0.1182, 0.0956],\n",
      "        [0.0348, 0.0000, 0.1714, 0.0000, 0.1456, 0.0000, 0.0000, 0.0349, 0.0000,\n",
      "         0.0000, 0.1071, 0.1540],\n",
      "        [0.0454, 0.0000, 0.0767, 0.0957, 0.0000, 0.0000, 0.0147, 0.0455, 0.0000,\n",
      "         0.0000, 0.1330, 0.0944],\n",
      "        [0.1968, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1862, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4634, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.1341, 0.0000, 0.0568, 0.0475, 0.0904, 0.0000, 0.0460, 0.0000, 0.0000,\n",
      "         0.0000, 0.0847, 0.0807],\n",
      "        [0.0000, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2433, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5814,\n",
      "         0.0000, 0.0000, 0.0000],\n",
      "        [0.0285, 0.0000, 0.0641, 0.0864, 0.1123, 0.0000, 0.0195, 0.0286, 0.0000,\n",
      "         0.0000, 0.0000, 0.0847],\n",
      "        [0.0619, 0.0000, 0.1317, 0.1215, 0.1201, 0.0000, 0.0215, 0.0620, 0.0000,\n",
      "         0.0000, 0.0993, 0.0000]], device='mps:0')\n",
      "val_u adj tensor([[0.0000, 0.2225, 0.0000, 0.0000],\n",
      "        [0.0442, 0.0000, 0.0000, 0.0686],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1675],\n",
      "        [0.0000, 0.0291, 0.1214, 0.0000]], device='mps:0')\n",
      "val_a adj tensor([[0.0000, 0.0000, 0.0262, 0.0000, 0.0537, 0.0435, 0.0879, 0.2049, 0.0000,\n",
      "         0.0000, 0.0484, 0.0448, 0.0000, 0.0000, 0.2083, 0.1697],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3499, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0462, 0.0000, 0.0000, 0.0968, 0.1247, 0.0000, 0.0155, 0.0463, 0.0000,\n",
      "         0.0000, 0.1182, 0.0956, 0.0389, 0.0902, 0.0144, 0.0743],\n",
      "        [0.0348, 0.0000, 0.1714, 0.0000, 0.1456, 0.0000, 0.0000, 0.0349, 0.0000,\n",
      "         0.0000, 0.1071, 0.1540, 0.0000, 0.0478, 0.0000, 0.0738],\n",
      "        [0.0454, 0.0000, 0.0767, 0.0957, 0.0000, 0.0000, 0.0147, 0.0455, 0.0000,\n",
      "         0.0000, 0.1330, 0.0944, 0.0513, 0.1079, 0.0000, 0.0749],\n",
      "        [0.1968, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1862, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6170, 0.0000],\n",
      "        [0.0000, 0.4634, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.4118, 0.0000, 0.0000, 0.1248],\n",
      "        [0.1341, 0.0000, 0.0568, 0.0475, 0.0904, 0.0000, 0.0460, 0.0000, 0.0000,\n",
      "         0.0000, 0.0847, 0.0807, 0.0000, 0.0448, 0.0709, 0.1584],\n",
      "        [0.0000, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2433, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5814,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0285, 0.0000, 0.0641, 0.0864, 0.1123, 0.0000, 0.0195, 0.0286, 0.0000,\n",
      "         0.0000, 0.0000, 0.0847, 0.0856, 0.1539, 0.0000, 0.0552],\n",
      "        [0.0619, 0.0000, 0.1317, 0.1215, 0.1201, 0.0000, 0.0215, 0.0620, 0.0000,\n",
      "         0.0000, 0.0993, 0.0000, 0.0000, 0.0568, 0.0197, 0.0981],\n",
      "        [0.0000, 0.4218, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1167, 0.0000, 0.0000, 0.2225, 0.0000, 0.0000],\n",
      "        [0.0392, 0.0000, 0.0776, 0.0984, 0.1197, 0.0000, 0.0000, 0.0393, 0.0000,\n",
      "         0.0000, 0.1384, 0.0968, 0.0442, 0.0000, 0.0000, 0.0686],\n",
      "        [0.2109, 0.0000, 0.0000, 0.0000, 0.0493, 0.0592, 0.1180, 0.2063, 0.0000,\n",
      "         0.0000, 0.0442, 0.0408, 0.0000, 0.0000, 0.0000, 0.1675],\n",
      "        [0.1967, 0.0000, 0.0391, 0.0312, 0.0717, 0.0000, 0.0374, 0.1968, 0.0000,\n",
      "         0.0000, 0.0658, 0.0616, 0.0000, 0.0291, 0.1214, 0.0000]],\n",
      "       device='mps:0')\n",
      "tst_u adj tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0995, 0.0000],\n",
      "        [0.0000, 0.1315, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]], device='mps:0')\n",
      "tst_a adj tensor([[0.0000, 0.0000, 0.0262, 0.0000, 0.0537, 0.0435, 0.0879, 0.2049, 0.0000,\n",
      "         0.0000, 0.0484, 0.0448, 0.0000, 0.0000, 0.2083, 0.1697, 0.0000, 0.0626,\n",
      "         0.0501, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3499, 0.0000, 0.0000, 0.0000, 0.2893, 0.0000,\n",
      "         0.0000, 0.3609],\n",
      "        [0.0462, 0.0000, 0.0000, 0.0968, 0.1247, 0.0000, 0.0155, 0.0463, 0.0000,\n",
      "         0.0000, 0.1182, 0.0956, 0.0389, 0.0902, 0.0144, 0.0743, 0.0000, 0.1231,\n",
      "         0.1159, 0.0000],\n",
      "        [0.0348, 0.0000, 0.1714, 0.0000, 0.1456, 0.0000, 0.0000, 0.0349, 0.0000,\n",
      "         0.0000, 0.1071, 0.1540, 0.0000, 0.0478, 0.0000, 0.0738, 0.0000, 0.1317,\n",
      "         0.0988, 0.0000],\n",
      "        [0.0454, 0.0000, 0.0767, 0.0957, 0.0000, 0.0000, 0.0147, 0.0455, 0.0000,\n",
      "         0.0000, 0.1330, 0.0944, 0.0513, 0.1079, 0.0000, 0.0749, 0.0000, 0.1292,\n",
      "         0.1313, 0.0000],\n",
      "        [0.1968, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1862, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.4634, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.4118, 0.0000, 0.0000, 0.1248, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1341, 0.0000, 0.0568, 0.0475, 0.0904, 0.0000, 0.0460, 0.0000, 0.0000,\n",
      "         0.0000, 0.0847, 0.0807, 0.0000, 0.0448, 0.0709, 0.1584, 0.0000, 0.0991,\n",
      "         0.0866, 0.0000],\n",
      "        [0.0000, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2433, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.6707],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5814,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.4186],\n",
      "        [0.0285, 0.0000, 0.0641, 0.0864, 0.1123, 0.0000, 0.0195, 0.0286, 0.0000,\n",
      "         0.0000, 0.0000, 0.0847, 0.0856, 0.1539, 0.0000, 0.0552, 0.0000, 0.1383,\n",
      "         0.1429, 0.0000],\n",
      "        [0.0619, 0.0000, 0.1317, 0.1215, 0.1201, 0.0000, 0.0215, 0.0620, 0.0000,\n",
      "         0.0000, 0.0993, 0.0000, 0.0000, 0.0568, 0.0197, 0.0981, 0.0000, 0.1132,\n",
      "         0.0942, 0.0000],\n",
      "        [0.0000, 0.4218, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1167, 0.0000, 0.0000, 0.2225, 0.0000, 0.0000, 0.0000, 0.1136,\n",
      "         0.1253, 0.0000],\n",
      "        [0.0392, 0.0000, 0.0776, 0.0984, 0.1197, 0.0000, 0.0000, 0.0393, 0.0000,\n",
      "         0.0000, 0.1384, 0.0968, 0.0442, 0.0000, 0.0000, 0.0686, 0.0000, 0.1376,\n",
      "         0.1403, 0.0000],\n",
      "        [0.2109, 0.0000, 0.0000, 0.0000, 0.0493, 0.0592, 0.1180, 0.2063, 0.0000,\n",
      "         0.0000, 0.0442, 0.0408, 0.0000, 0.0000, 0.0000, 0.1675, 0.0000, 0.0580,\n",
      "         0.0459, 0.0000],\n",
      "        [0.1967, 0.0000, 0.0391, 0.0312, 0.0717, 0.0000, 0.0374, 0.1968, 0.0000,\n",
      "         0.0000, 0.0658, 0.0616, 0.0000, 0.0291, 0.1214, 0.0000, 0.0000, 0.0814,\n",
      "         0.0677, 0.0000],\n",
      "        [0.0939, 0.1438, 0.0000, 0.0000, 0.0000, 0.0000, 0.2137, 0.0887, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2582, 0.0000, 0.1127, 0.0890, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0312, 0.0000, 0.1463, 0.1694, 0.1312, 0.0000, 0.0000, 0.0312, 0.0000,\n",
      "         0.0000, 0.1056, 0.1679, 0.0000, 0.0570, 0.0000, 0.0608, 0.0000, 0.0000,\n",
      "         0.0995, 0.0000],\n",
      "        [0.0454, 0.0000, 0.0957, 0.1121, 0.1252, 0.0000, 0.0000, 0.0455, 0.0000,\n",
      "         0.0000, 0.1203, 0.1110, 0.0365, 0.0888, 0.0137, 0.0743, 0.0000, 0.1315,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.2345, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4857,\n",
      "         0.2798, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], device='mps:0')\n",
      "\n",
      "pretrn_iter.dataset.tensors[0].shape torch.Size([12, 132])\n",
      "preval_iter.dataset.tensors[0].shape torch.Size([16, 132])\n",
      "\n",
      "For veryfication purposes\n",
      "Corresponding second instance pretrn_iter tensor([0.3349, 0.6005, 0.5854, 0.5837, 0.4715, 0.6081, 0.4150, 0.2742, 0.4285,\n",
      "        0.5626, 0.3745, 0.5246, 0.5499, 0.5398, 0.6444, 0.5778, 0.5778, 0.6984,\n",
      "        0.2211, 0.7979, 0.4943, 0.6984, 0.5854, 0.7675, 0.6764, 0.5702, 0.6992,\n",
      "        0.6579, 0.6688, 0.6984, 0.6157, 0.6376, 0.7675, 0.5702, 0.7599, 0.5162,\n",
      "        0.4639, 0.4412, 0.5027, 0.4715, 0.5027, 0.0010, 0.5837, 0.5930, 0.6376,\n",
      "        0.3273, 0.7296, 0.6005, 0.4260, 0.5162, 0.4639, 0.4825, 0.4639, 0.6579,\n",
      "        0.5019, 0.1924, 0.6174, 0.5008, 0.4488, 0.6107, 0.5095, 0.3425, 0.5474,\n",
      "        0.6537, 0.5162, 0.6385, 0.5854, 0.1722, 0.5550, 0.6537, 0.6461, 0.5432,\n",
      "        0.5095, 0.4639, 0.5019, 0.3611, 0.5230, 0.4791, 0.5432, 0.5778, 0.2514,\n",
      "        0.7068, 0.6233, 0.5095, 0.5442, 0.6984, 0.6005, 0.6233, 0.6714, 0.5930,\n",
      "        0.5550, 0.6157, 0.5634, 0.5398, 0.5778, 0.5162, 0.5171, 0.4825, 0.5171,\n",
      "        0.4867, 0.4757, 0.6005, 0.5322, 0.5322, 0.5432, 0.5171, 0.6309, 0.5095,\n",
      "        0.6569, 0.5027, 0.4563, 0.2126, 0.6992, 0.6461, 0.5702, 0.5365, 0.6081,\n",
      "        0.6743, 0.7523, 0.5432, 0.6005, 0.6984, 0.6309, 0.6385, 0.7220, 0.6916,\n",
      "        0.6157, 0.5930, 0.6461, 0.6309, 0.5230, 0.5930])\n",
      "Corresponding second instance preval_iter tensor([0.3349, 0.6005, 0.5854, 0.5837, 0.4715, 0.6081, 0.4150, 0.2742, 0.4285,\n",
      "        0.5626, 0.3745, 0.5246, 0.5499, 0.5398, 0.6444, 0.5778, 0.5778, 0.6984,\n",
      "        0.2211, 0.7979, 0.4943, 0.6984, 0.5854, 0.7675, 0.6764, 0.5702, 0.6992,\n",
      "        0.6579, 0.6688, 0.6984, 0.6157, 0.6376, 0.7675, 0.5702, 0.7599, 0.5162,\n",
      "        0.4639, 0.4412, 0.5027, 0.4715, 0.5027, 0.0010, 0.5837, 0.5930, 0.6376,\n",
      "        0.3273, 0.7296, 0.6005, 0.4260, 0.5162, 0.4639, 0.4825, 0.4639, 0.6579,\n",
      "        0.5019, 0.1924, 0.6174, 0.5008, 0.4488, 0.6107, 0.5095, 0.3425, 0.5474,\n",
      "        0.6537, 0.5162, 0.6385, 0.5854, 0.1722, 0.5550, 0.6537, 0.6461, 0.5432,\n",
      "        0.5095, 0.4639, 0.5019, 0.3611, 0.5230, 0.4791, 0.5432, 0.5778, 0.2514,\n",
      "        0.7068, 0.6233, 0.5095, 0.5442, 0.6984, 0.6005, 0.6233, 0.6714, 0.5930,\n",
      "        0.5550, 0.6157, 0.5634, 0.5398, 0.5778, 0.5162, 0.5171, 0.4825, 0.5171,\n",
      "        0.4867, 0.4757, 0.6005, 0.5322, 0.5322, 0.5432, 0.5171, 0.6309, 0.5095,\n",
      "        0.6569, 0.5027, 0.4563, 0.2126, 0.6992, 0.6461, 0.5702, 0.5365, 0.6081,\n",
      "        0.6743, 0.7523, 0.5432, 0.6005, 0.6984, 0.6309, 0.6385, 0.7220, 0.6916,\n",
      "        0.6157, 0.5930, 0.6461, 0.6309, 0.5230, 0.5930])\n",
      "\n",
      "pretrainModel Started ...\n",
      "\n",
      "For veryfication purposes\n",
      "adj_train for second sensor in original order tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='mps:0')\n",
      "adj_val for second sensor in original order tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.3499, 0.0000, 0.0000, 0.0000],\n",
      "       device='mps:0')\n",
      "there are  2 adjacency matrices in adj_train\n",
      "\n",
      "For pretraining, training dataset:\n",
      "x[0].shape torch.Size([12, 132])\n",
      "x[0] for second sensor in original order tensor([0.3349, 0.6005, 0.5854, 0.5837, 0.4715, 0.6081, 0.4150, 0.2742, 0.4285,\n",
      "        0.5626, 0.3745, 0.5246, 0.5499, 0.5398, 0.6444, 0.5778, 0.5778, 0.6984,\n",
      "        0.2211, 0.7979, 0.4943, 0.6984, 0.5854, 0.7675, 0.6764, 0.5702, 0.6992,\n",
      "        0.6579, 0.6688, 0.6984, 0.6157, 0.6376, 0.7675, 0.5702, 0.7599, 0.5162,\n",
      "        0.4639, 0.4412, 0.5027, 0.4715, 0.5027, 0.0010, 0.5837, 0.5930, 0.6376,\n",
      "        0.3273, 0.7296, 0.6005, 0.4260, 0.5162, 0.4639, 0.4825, 0.4639, 0.6579,\n",
      "        0.5019, 0.1924, 0.6174, 0.5008, 0.4488, 0.6107, 0.5095, 0.3425, 0.5474,\n",
      "        0.6537, 0.5162, 0.6385, 0.5854, 0.1722, 0.5550, 0.6537, 0.6461, 0.5432,\n",
      "        0.5095, 0.4639, 0.5019, 0.3611, 0.5230, 0.4791, 0.5432, 0.5778, 0.2514,\n",
      "        0.7068, 0.6233, 0.5095, 0.5442, 0.6984, 0.6005, 0.6233, 0.6714, 0.5930,\n",
      "        0.5550, 0.6157, 0.5634, 0.5398, 0.5778, 0.5162, 0.5171, 0.4825, 0.5171,\n",
      "        0.4867, 0.4757, 0.6005, 0.5322, 0.5322, 0.5432, 0.5171, 0.6309, 0.5095,\n",
      "        0.6569, 0.5027, 0.4563, 0.2126, 0.6992, 0.6461, 0.5702, 0.5365, 0.6081,\n",
      "        0.6743, 0.7523, 0.5432, 0.6005, 0.6984, 0.6309, 0.6385, 0.7220, 0.6916,\n",
      "        0.6157, 0.5930, 0.6461, 0.6309, 0.5230, 0.5930])\n",
      "\n",
      "the first augmentated input, for fixed temporal shifting tensor([0.3407, 0.6002, 0.5853, 0.5812, 0.4745, 0.6039, 0.4119, 0.2776, 0.4314,\n",
      "        0.5585, 0.3778, 0.5252, 0.5497, 0.5421, 0.6429, 0.5778, 0.5804, 0.6879,\n",
      "        0.2337, 0.7912, 0.4987, 0.6959, 0.5893, 0.7655, 0.6741, 0.5730, 0.6983,\n",
      "        0.6581, 0.6695, 0.6966, 0.6162, 0.6405, 0.7632, 0.5743, 0.7546, 0.5151,\n",
      "        0.4634, 0.4425, 0.5020, 0.4722, 0.4918, 0.0137, 0.5839, 0.5939, 0.6309,\n",
      "        0.3361, 0.7267, 0.5967, 0.4280, 0.5151, 0.4643, 0.4821, 0.4682, 0.6545,\n",
      "        0.4951, 0.2017, 0.6149, 0.4997, 0.4523, 0.6084, 0.5058, 0.3470, 0.5497,\n",
      "        0.6507, 0.5189, 0.6373, 0.5763, 0.1805, 0.5572, 0.6535, 0.6438, 0.5425,\n",
      "        0.5085, 0.4648, 0.4988, 0.3646, 0.5220, 0.4805, 0.5440, 0.5706, 0.2614,\n",
      "        0.7050, 0.6208, 0.5102, 0.5475, 0.6962, 0.6010, 0.6244, 0.6697, 0.5921,\n",
      "        0.5563, 0.6146, 0.5629, 0.5407, 0.5764, 0.5162, 0.5163, 0.4832, 0.5164,\n",
      "        0.4865, 0.4785, 0.5990, 0.5322, 0.5325, 0.5426, 0.5195, 0.6282, 0.5127,\n",
      "        0.6536, 0.5017, 0.4510, 0.2233, 0.6980, 0.6444, 0.5694, 0.5380, 0.6096,\n",
      "        0.6760, 0.7478, 0.5444, 0.6027, 0.6969, 0.6311, 0.6403, 0.7213, 0.6900,\n",
      "        0.6152, 0.5941, 0.6457, 0.6285, 0.5245, 0.5245], device='mps:0')\n",
      "the second augmentated input, for fixed temporal shifting tensor([0.3824, 0.5978, 0.5851, 0.5636, 0.4960, 0.5736, 0.3898, 0.3018, 0.4525,\n",
      "        0.5289, 0.4014, 0.5292, 0.5481, 0.5585, 0.6325, 0.5778, 0.5993, 0.6130,\n",
      "        0.3243, 0.7436, 0.5308, 0.6781, 0.6180, 0.7512, 0.6574, 0.5933, 0.6918,\n",
      "        0.6598, 0.6741, 0.6836, 0.6196, 0.6609, 0.7322, 0.6041, 0.7163, 0.5069,\n",
      "        0.4599, 0.4522, 0.4971, 0.4771, 0.4129, 0.1052, 0.5853, 0.6009, 0.5821,\n",
      "        0.3993, 0.7065, 0.5693, 0.4421, 0.5069, 0.4672, 0.4792, 0.4986, 0.6300,\n",
      "        0.4465, 0.2684, 0.5965, 0.4915, 0.4777, 0.5926, 0.4796, 0.3792, 0.5664,\n",
      "        0.6291, 0.5381, 0.6290, 0.5114, 0.2407, 0.5727, 0.6523, 0.6277, 0.5372,\n",
      "        0.5013, 0.4707, 0.4767, 0.3900, 0.5151, 0.4906, 0.5494, 0.5194, 0.3329,\n",
      "        0.6919, 0.6029, 0.5157, 0.5718, 0.6809, 0.6046, 0.6319, 0.6573, 0.5862,\n",
      "        0.5659, 0.6064, 0.5592, 0.5466, 0.5668, 0.5164, 0.5109, 0.4887, 0.5116,\n",
      "        0.4847, 0.4981, 0.5883, 0.5322, 0.5342, 0.5385, 0.5374, 0.6092, 0.5358,\n",
      "        0.6293, 0.4944, 0.4127, 0.2997, 0.6897, 0.6325, 0.5641, 0.5493, 0.6200,\n",
      "        0.6882, 0.7149, 0.5535, 0.6180, 0.6863, 0.6323, 0.6534, 0.7165, 0.6780,\n",
      "        0.6116, 0.6025, 0.6434, 0.6116, 0.5355, 0.5355], device='mps:0')\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([12, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([12, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "\n",
      "In performing encoder contrast learning, the data shape before loss calculation:\n",
      "x1.shape torch.Size([12, 32])\n",
      "x2.shape torch.Size([12, 32])\n",
      "\n",
      "The validation for encoder starts at index 12\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([16, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([16, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "\n",
      "In performing encoder contrast learning, the data shape before loss calculation:\n",
      "x1.shape torch.Size([4, 32])\n",
      "x2.shape torch.Size([4, 32])\n",
      "epoch 0 time used: 0  seconds  train loss: tensor(2.3844, device='mps:0', grad_fn=<NegBackward0>) validation loss: tensor(1.9278, device='mps:0')\n",
      "PRETIME DURATION: 0:00:00.529364\n",
      "pretrainModel Ended ...\n",
      "\n",
      "\n",
      "trainModel Started ...\n",
      "TIMESTEP_IN, TIMESTEP_OUT 12 12\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of adj_train torch.Size([12, 12])\n",
      "The shape of adj_val_u torch.Size([4, 4])\n",
      "The shape of adj_val_a torch.Size([16, 16])\n",
      "\n",
      "The shape of train_encoder_input torch.Size([12, 132])\n",
      "The shape of val_u_encoder_input torch.Size([4, 132])\n",
      "The shape of val_a_encoder_input torch.Size([16, 132])\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([12, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([4, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([16, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "\n",
      "ENCODER INFER DURATION IN MODEL TRAINING: 0:00:00.060784\n",
      "train_embed torch.Size([32, 12]) tensor(0.0073, device='mps:0') tensor(0.0760, device='mps:0')\n",
      "val_u_embed torch.Size([32, 4]) tensor(0.0026, device='mps:0') tensor(0.0699, device='mps:0')\n",
      "val_a_embed torch.Size([32, 16]) tensor(0.0063, device='mps:0') tensor(0.0814, device='mps:0')\n",
      "\n",
      "For verification purposes\n",
      "The shape of model_input torch.Size([132, 1, 12, 12])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 32])\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "The corresponding second instance of y_pred tensor([ 0.0558,  0.0293, -0.0234,  0.0403, -0.0353, -0.0839, -0.0170, -0.0159,\n",
      "         0.0205,  0.0784,  0.0639,  0.0441], device='mps:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "The corresponding second instance of y tensor([0.5499, 0.5398, 0.6444, 0.5778, 0.5778, 0.6984, 0.2211, 0.7979, 0.4943,\n",
      "        0.6984, 0.5854, 0.7675])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 32])\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "The corresponding second instance of y_pred tensor([ 0.0989,  0.0500, -0.0110,  0.0785, -0.0211, -0.0188,  0.0342,  0.0598,\n",
      "         0.0755,  0.1033,  0.1176,  0.0899], device='mps:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "The corresponding second instance of y tensor([0.5230, 0.4791, 0.5432, 0.5778, 0.2514, 0.7068, 0.6233, 0.5095, 0.5442,\n",
      "        0.6984, 0.6005, 0.6233])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([4, 12, 12, 32])\n",
      "\n",
      "For veryfication purposes\n",
      "The shape of y_pred torch.Size([4, 12, 12, 1])\n",
      "The shape of y torch.Size([4, 12, 12, 1])\n",
      "The corresponding second instance of y_pred tensor([ 0.1368,  0.0536,  0.0144,  0.1024, -0.0134,  0.0422,  0.0829,  0.1381,\n",
      "         0.1272,  0.1265,  0.1598,  0.1185], device='mps:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "The corresponding second instance of y tensor([0.5246, 0.4260, 0.0769, 0.4218, 0.0372, 0.2818, 0.4639, 0.5702, 0.4015,\n",
      "        0.4488, 0.3197, 0.3121])\n",
      "\n",
      "The validation for model training starts at index 12\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([17, 4, 12, 32])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([17, 12, 4, 1])\n",
      "The shape of y torch.Size([17, 12, 4, 1])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([17, 16, 12, 32])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([17, 12, 4, 1])\n",
      "The shape of y torch.Size([17, 12, 4, 1])\n",
      "epoch 0 time used: 0  seconds  train loss: 0.680383071754918 validation unseen nodes loss: 0.6889294385910034 validation all nodes loss: 0.68896484375\n",
      "MODEL TRAINING DURATION: 0:00:00.606570\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 32])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([64, 12, 12, 32])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([64, 12, 12, 1])\n",
      "The shape of y torch.Size([64, 12, 12, 1])\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([4, 12, 12, 32])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([4, 12, 12, 1])\n",
      "The shape of y torch.Size([4, 12, 12, 1])\n",
      "trainModel Ended ...\n",
      "\n",
      "Model Testing test_a Started ...\n",
      "Model Infer Start ...\n",
      "\n",
      "The shape of tst_encoder_input torch.Size([20, 132])\n",
      "\n",
      "Encoder started\n",
      "\n",
      "the data shape after convolutional layers and potential sampling\n",
      "x_.shape torch.Size([20, 32, 10])\n",
      "GCN is enabled\n",
      "\n",
      "Encoder finished\n",
      "ENCODER INFER DURATION: 0:00:00.044568\n",
      "\n",
      "The inference for model starts at index 16\n",
      "\n",
      "MODEL INFER START ...\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([9, 20, 12, 32])\n",
      "\n",
      "In model evaluation process:\n",
      "The shape of y_pred torch.Size([9, 12, 4, 1])\n",
      "The shape of y torch.Size([9, 12, 4, 1])\n",
      "Model Infer End ... 2024-05-05 16:20:55.011762\n",
      "MODEL INFER DURATION: 0:00:00.033159\n",
      "\n",
      "After adding the embeddings, the shape of x is: torch.Size([9, 20, 12, 32])\n",
      "YS.shape, YS_pred.shape, (9, 12, 4, 1) (9, 12, 4, 1)\n",
      "****************************************\n",
      "LSTM, test_a, Torch MSE, 6.2620759010e-01, 0.6262075901\n",
      "all pred steps, LSTM, test_a, MSE, RMSE, MAE, MAPE, 122.1492996216, 11.0521173477, 10.3137769699, 15.7473176718\n",
      "1 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 112.7721252441, 10.6194219589, 10.0129776001, 15.2566686273\n",
      "2 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 126.9129638672, 11.2655658722, 10.6452493668, 16.2168666720\n",
      "3 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 145.0069427490, 12.0418825150, 11.2833948135, 17.1928346157\n",
      "4 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 107.3021316528, 10.3586740494, 9.7064151764, 14.8313924670\n",
      "5 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 154.2594451904, 12.4201221466, 11.6617670059, 17.8713709116\n",
      "6 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 141.8893585205, 11.9117317200, 11.1032247543, 16.9537290931\n",
      "7 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 136.0371551514, 11.6634969711, 10.8691596985, 16.5981024504\n",
      "8 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 109.7369079590, 10.4755382538, 9.7009515762, 14.8514926434\n",
      "9 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 107.3086547852, 10.3589887619, 9.6121721268, 14.6825730801\n",
      "10 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 105.2118377686, 10.2572822571, 9.5608024597, 14.5785927773\n",
      "11 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 109.9865188599, 10.4874458313, 9.7889680862, 14.9192631245\n",
      "12 step, LSTM, test_a, MSE, RMSE, MAE, MAPE, 109.3674621582, 10.4578895569, 9.8202505112, 15.0149270892\n",
      "Model Testing Ended ... Sun May  5 16:20:55 2024\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for i in range(1):\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "    P = type('Parameters', (object,), {})()\n",
    "    P.dataname = 'EXAMPLE'\n",
    "    P.model = 'LSTM'\n",
    "    P.seed = 10\n",
    "\n",
    "    P.t_train = 0.8\n",
    "    P.t_val = 0.1\n",
    "    P.s_train = 0.6\n",
    "    P.s_val = 0.2\n",
    "\n",
    "    P.timestep_in = 12\n",
    "    P.timestep_out = 12\n",
    "    P.n_channel = 1\n",
    "    P.batch_size = 64\n",
    "\n",
    "    P.lstm_hidden_dim = 128\n",
    "    P.lstm_layers = 2\n",
    "    P.lstm_dropout = 0.2\n",
    "    P.gwnet_is_adp_adj = True\n",
    "    P.gwnet_is_SGA = False\n",
    "\n",
    "    P.adj_type = 'doubletransition'\n",
    "    P.adj_method = 1\n",
    "    P.adj_diag = 0\n",
    "    P.is_cost = False\n",
    "    P.cost_kernals = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    P.cost_alpha = 0.5\n",
    "    P.cl_temperature = 1\n",
    "    P.is_pretrain = True\n",
    "    P.is_GCN_encoder = True\n",
    "    P.is_GCN_after_CL = False\n",
    "    P.gcn_order = 1\n",
    "    P.gcn_dropout = 0\n",
    "    P.augmentation = 'temporal_shifting_new'\n",
    "    P.temporal_shifting_r = 0.8\n",
    "    P.encoder_to_model_ratio = 1\n",
    "    P.is_concat_encoder_model = True\n",
    "    P.is_layer_after_concat = True\n",
    "\n",
    "    P.learn_rate = 0.001\n",
    "    P.pretrain_epoch = 1\n",
    "    P.train_epoch = 1\n",
    "    P.weight_decay = 0\n",
    "    P.is_testunseen = True\n",
    "    P.train_model_datasplit = 'A'\n",
    "    P.train_encoder_on = 'gpu'\n",
    "\n",
    "    P.example_verbose = True\n",
    "    %run -i 'experiment.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
