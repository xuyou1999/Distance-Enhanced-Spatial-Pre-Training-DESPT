{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'test'\n",
    "save_exe_id = 'HAGUE_gwnet_TCN_240703-2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path and the sheet name\n",
    "file_path = 'result/Result.xlsx'\n",
    "sheet_name = 'Parameters_offline'  # Replace with your specific sheet name\n",
    "\n",
    "# Read the specific sheet\n",
    "parameter_file = pd.read_excel(file_path, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exe_id</th>\n",
       "      <th>adj_diag</th>\n",
       "      <th>adj_method</th>\n",
       "      <th>adj_path</th>\n",
       "      <th>adj_type</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>cl_temperature</th>\n",
       "      <th>cost_alpha</th>\n",
       "      <th>cost_kernals</th>\n",
       "      <th>...</th>\n",
       "      <th>timestep_in</th>\n",
       "      <th>timestep_out</th>\n",
       "      <th>tolerance</th>\n",
       "      <th>track_id</th>\n",
       "      <th>train_encoder_on</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>train_model_datasplit</th>\n",
       "      <th>train_size</th>\n",
       "      <th>trainval_size</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>HAGUE_gwnet_TCN_240703-2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/Hauge/adj_mx_comp1.pkl</td>\n",
       "      <td>doubletransition</td>\n",
       "      <td>input_smoothing</td>\n",
       "      <td>64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[1, 2, 4, 8, 16]</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>9007</td>\n",
       "      <td>gpu</td>\n",
       "      <td>100</td>\n",
       "      <td>B</td>\n",
       "      <td>83597</td>\n",
       "      <td>146295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          exe_id  adj_diag  adj_method  \\\n",
       "483  HAGUE_gwnet_TCN_240703-2016         1           1   \n",
       "\n",
       "                          adj_path          adj_type     augmentation  \\\n",
       "483  ./data/Hauge/adj_mx_comp1.pkl  doubletransition  input_smoothing   \n",
       "\n",
       "     batch_size  cl_temperature  cost_alpha      cost_kernals  ...  \\\n",
       "483          64             2.0         0.5  [1, 2, 4, 8, 16]  ...   \n",
       "\n",
       "     timestep_in  timestep_out tolerance  track_id  train_encoder_on  \\\n",
       "483           12            12        20      9007               gpu   \n",
       "\n",
       "     train_epoch  train_model_datasplit  train_size  trainval_size  \\\n",
       "483          100                      B       83597         146295   \n",
       "\n",
       "     weight_decay  \n",
       "483             0  \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_row = parameter_file.loc[parameter_file['exe_id'] == save_exe_id]\n",
    "selected_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = type('Parameters', (object,), {})()\n",
    "\n",
    "P.dataname = selected_row['dataname'].values[0]\n",
    "P.model = selected_row['model'].values[0]\n",
    "P.pre_model = selected_row['pre_model'].values[0]\n",
    "P.track_id = selected_row['track_id'].values[0]\n",
    "P.replication = selected_row['replication'].values[0]\n",
    "P.seed = selected_row['seed'].values[0]\n",
    "\n",
    "P.t_train = selected_row['t_train'].values[0]\n",
    "P.t_val = selected_row['t_val'].values[0]\n",
    "P.s_train = selected_row['s_train'].values[0]\n",
    "P.s_val = selected_row['s_val'].values[0]\n",
    "P.fold = selected_row['fold'].values[0]\n",
    "\n",
    "P.timestep_in = selected_row['timestep_in'].values[0]\n",
    "P.timestep_out = selected_row['timestep_out'].values[0]\n",
    "P.n_channel = selected_row['n_channel'].values[0]\n",
    "P.batch_size = int(selected_row['batch_size'].values[0])\n",
    "\n",
    "P.lstm_hidden_dim = selected_row['lstm_hidden_dim'].values[0]\n",
    "P.lstm_layers = selected_row['lstm_layers'].values[0]\n",
    "P.lstm_dropout = selected_row['lstm_dropout'].values[0]\n",
    "P.gwnet_is_adp_adj = selected_row['gwnet_is_adp_adj'].values[0]\n",
    "P.gwnet_is_SGA = selected_row['gwnet_is_SGA'].values[0]\n",
    "\n",
    "P.adj_type = selected_row['adj_type'].values[0]\n",
    "P.adj_method = selected_row['adj_method'].values[0]\n",
    "P.adj_diag = selected_row['adj_diag'].values[0]\n",
    "P.cost_kernals = selected_row['cost_kernals'].values[0]\n",
    "P.cost_alpha = selected_row['cost_alpha'].values[0]\n",
    "P.cl_temperature = selected_row['cl_temperature'].values[0]\n",
    "P.is_pretrain = selected_row['is_pretrain'].values[0]\n",
    "P.is_GCN_encoder = selected_row['is_GCN_encoder'].values[0]\n",
    "P.is_GCN_after_CL = selected_row['is_GCN_after_CL'].values[0]\n",
    "P.gcn_order = selected_row['gcn_order'].values[0]\n",
    "P.gcn_dropout = selected_row['gcn_dropout'].values[0]\n",
    "\n",
    "P.augmentation = selected_row['augmentation'].values[0]\n",
    "P.temporal_shifting_r = selected_row['temporal_shifting_r'].values[0]\n",
    "P.input_smoothing_r = selected_row['input_smoothing_r'].values[0]\n",
    "P.input_smoothing_e = selected_row['input_smoothing_e'].values[0]\n",
    "P.encoder_to_model_ratio = selected_row['encoder_to_model_ratio'].values[0]\n",
    "P.is_concat_encoder_model = selected_row['is_concat_encoder_model'].values[0]\n",
    "P.is_layer_after_concat = selected_row['is_layer_after_concat'].values[0]\n",
    "P.is_always_augmentation = selected_row['is_always_augmentation'].values[0]\n",
    "\n",
    "P.tolerance = selected_row['tolerance'].values[0]\n",
    "P.learn_rate = selected_row['learn_rate'].values[0]\n",
    "P.pretrain_epoch = selected_row['pretrain_epoch'].values[0]\n",
    "P.train_epoch = selected_row['train_epoch'].values[0]\n",
    "P.weight_decay = selected_row['weight_decay'].values[0]\n",
    "P.is_testunseen = selected_row['is_testunseen'].values[0]\n",
    "P.train_model_datasplit = selected_row['train_model_datasplit'].values[0]\n",
    "P.train_encoder_on = selected_row['train_encoder_on'].values[0]\n",
    "\n",
    "P.is_mongo = selected_row['is_mongo'].values[0]\n",
    "P.example_verbose = selected_row['example_verbose'].values[0]\n",
    "P.is_tune = selected_row['is_tune'].values[0]\n",
    "\n",
    "P.fold_i = 0\n",
    "P.exe_id = file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(P.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import unseen_nodes\n",
    "from utils import *\n",
    "from encoder import *\n",
    "from augmentation import *\n",
    "from model import *\n",
    "import Metrics\n",
    "import json\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "\n",
    "class StandardScaler:\n",
    "    def __init__(self):\n",
    "        self.u = None\n",
    "        self.z = None\n",
    "    def fit_transform(self, x):\n",
    "        self.u = x.mean()\n",
    "        self.z = x.std()\n",
    "        return (x-self.u)/self.z\n",
    "    def inverse_transform(self, x):\n",
    "        return x * self.z + self.u\n",
    "\n",
    "def connect_mongo():\n",
    "    with open('config.json', 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "    username = config['username']\n",
    "    password = config['password']\n",
    "    cluster_url = config['cluster_url']\n",
    "    db_name = config['db_name']\n",
    "    connection_string = f\"mongodb+srv://{username}:{password}@{cluster_url}/test?retryWrites=true&w=majority\"\n",
    "    client = MongoClient(connection_string)\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def save_parameters(P, param_obj, filename, mongodb):\n",
    "    data = {attr: [getattr(param_obj, attr)] for attr in dir(param_obj) if not attr.startswith(\"__\") and not callable(getattr(param_obj, attr))}\n",
    "    column_order = ['exe_id'] + [col for col in data if col != 'exe_id']\n",
    "    new_row = pd.DataFrame(data, columns=column_order)\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=column_order)\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df = df[column_order]\n",
    "    df.to_csv(filename, index=False)\n",
    "    if P.is_mongo:\n",
    "        data_db = {attr: getattr(param_obj, attr) for attr in dir(param_obj) if not attr.startswith(\"__\") and not callable(getattr(param_obj, attr)) \n",
    "                   and attr != 'exe_id'\n",
    "                   and attr != 'replication'\n",
    "                   and attr != 'track_id'\n",
    "                   and attr != 'fold_i'}\n",
    "        doc = {\n",
    "                \"exe_id\": param_obj.exe_id,  # Ensure that param_obj has an exe_id att{attr: getattr(param_obj, attr) for attr in dir(param_obj) if not attr.startswith(\"__\") and not callable(getattr(param_obj, attr)) and attr != 'exe_id'}ribute\n",
    "                \"track_id\": param_obj.track_id,\n",
    "                \"replication\": param_obj.replication,\n",
    "                \"fold_i\": param_obj.fold_i,\n",
    "                \"P\": data_db\n",
    "            }\n",
    "\n",
    "        mongodb['performance'].insert_one(doc)\n",
    "\n",
    "def getModel(P, name, device, support_len):\n",
    "    if name == 'gwnet':\n",
    "        model = gwnet(device, num_nodes=P.n_sensor, in_dim=P.n_channel, adp_adj=P.gwnet_is_adp_adj, sga=P.gwnet_is_SGA, support_len=support_len, is_concat=P.is_concat_encoder_model, is_layer_after_concat=P.is_layer_after_concat).to(device)\n",
    "        # if P.gwnet_is_adp_adj == False:\n",
    "        #     model = nn.DataParallel(model)\n",
    "    elif name == 'LSTM':\n",
    "        if P.is_pretrain == False:\n",
    "            lstm_input_dim = 32\n",
    "        elif P.is_layer_after_concat:\n",
    "            lstm_input_dim = 32\n",
    "        elif P.is_concat_encoder_model:\n",
    "            lstm_input_dim = 64\n",
    "        else:\n",
    "            lstm_input_dim = 32\n",
    "        model = LSTM_uni(input_dim=P.n_channel, lstm_input_dim=lstm_input_dim, hidden_dim=P.lstm_hidden_dim, output_dim=12, layer_dim = P.lstm_layers, dropout_prob = P.lstm_dropout, device=device, is_GCN_after_CL = P.is_GCN_after_CL, support_len = support_len, gcn_order=P.gcn_order, gcn_dropout=P.gcn_dropout).to(device)\n",
    "        model = nn.DataParallel(model)\n",
    "    return model\n",
    "\n",
    "def getXSYS(P, data, mode):\n",
    "    TRAIN_NUM = int(data.shape[0] * (P.t_train + P.t_val))\n",
    "    XS, YS = [], []\n",
    "    if mode == 'TRAIN':    \n",
    "        for i in range(TRAIN_NUM - P.timestep_out - P.timestep_in + 1):\n",
    "            x = data[i:i+P.timestep_in, :]\n",
    "            y = data[i+P.timestep_in:i+P.timestep_in+P.timestep_out, :]\n",
    "            XS.append(x), YS.append(y)\n",
    "    elif mode == 'TEST':\n",
    "        for i in range(TRAIN_NUM - P.timestep_in,  data.shape[0] - P.timestep_out - P.timestep_in + 1):\n",
    "            x = data[i:i+P.timestep_in, :]\n",
    "            y = data[i+P.timestep_in:i+P.timestep_in+P.timestep_out, :]\n",
    "            XS.append(x), YS.append(y)\n",
    "    XS, YS = np.array(XS), np.array(YS)\n",
    "    XS, YS = XS[:, :, :, np.newaxis], YS[:, :, :, np.newaxis]\n",
    "    XS = XS.transpose(0, 3, 2, 1)\n",
    "    return XS, YS\n",
    "\n",
    "def setups(P, device):\n",
    "    '''\n",
    "    If the save folder does not exist, create it.\n",
    "    '''\n",
    "    torch.manual_seed(P.seed)\n",
    "    torch.cuda.manual_seed(P.seed)\n",
    "    \n",
    "    '''\n",
    "    Split the data in temporal dimension into training and testing. \n",
    "    At this step, training set contains both training and validation data.\n",
    "    So that each each dimension correspond to [instance, input, sensor, output]\n",
    "    '''\n",
    "    trainXS, trainYS = getXSYS(P, data, 'TRAIN')\n",
    "    testXS, testYS = getXSYS(P, data, 'TEST')\n",
    "\n",
    "    print('\\ntrainXS.shape', trainXS.shape)\n",
    "    print('trainYS.shape', trainYS.shape)\n",
    "    print('testXS.shape', testXS.shape)\n",
    "    print('testYS.shape', testYS.shape)\n",
    "\n",
    "    if P.example_verbose:\n",
    "        print('\\nFirst instance trainXS for first sensor:', trainXS[0,0,0,:])\n",
    "        print('\\nFirst instance trainYS for first sensor:', trainYS[0,:,0,0])\n",
    "        print('\\nLast instance trainXS for first sensor:', trainXS[-1,0,0,:])\n",
    "        print('\\nFirst instance testXS for first sensor:', testXS[0,0,0,:])\n",
    "        print('\\nFirst instance trainXS for second sensor:', trainXS[0,0,1,:])\n",
    "        print('\\nFirst instance trainYS for second sensor:', trainYS[0,:,1,0])\n",
    "\n",
    "    '''\n",
    "    Split the training set further into training and validation sets.\n",
    "    '''\n",
    "    P.trainval_size = len(trainXS)\n",
    "    P.train_size = int(P.trainval_size * (P.t_train / (P.t_train + P.t_val)))\n",
    "    XS_torch_trn = trainXS[:P.train_size,:,:,:]\n",
    "    YS_torch_trn = trainYS[:P.train_size,:,:,:]\n",
    "    XS_torch_val = trainXS[P.train_size:P.trainval_size,:,:,:]\n",
    "    YS_torch_val = trainYS[P.train_size:P.trainval_size,:,:,:]\n",
    "\n",
    "    '''\n",
    "    Get the sensor indexes for each spatial splited set.\n",
    "    '''\n",
    "    spatialSplit_unseen = unseen_nodes.SpatialSplit(data.shape[1], P.fold_i, r_trn=P.s_train, r_val=P.s_val, r_tst=(1-P.s_train-P.s_val), seed=P.seed)\n",
    "    spatialSplit_allNod = unseen_nodes.SpatialSplit(data.shape[1], P.fold_i, r_trn=P.s_train, r_val=min(1.0,P.s_val+P.s_train), r_tst=1.0, seed=P.seed)\n",
    "    print('\\nspatialSplit_unseen', spatialSplit_unseen)\n",
    "    print('spatialSplit_allNod', spatialSplit_allNod)\n",
    "    print('spatialSplit_unseen.i_tst', spatialSplit_unseen.i_tst)\n",
    "    # save the spatial split\n",
    "    with open(P.save_path + '/' + 'i_tst.txt', 'w') as f:\n",
    "        np.savetxt(f, spatialSplit_unseen.i_tst, fmt='%d')\n",
    "    with open(P.save_path + '/' + 'i_val.txt', 'w') as f:\n",
    "        np.savetxt(f, spatialSplit_unseen.i_val, fmt='%d')\n",
    "    with open(P.save_path + '/' + 'i_trn.txt', 'w') as f:\n",
    "        np.savetxt(f, spatialSplit_unseen.i_trn, fmt='%d')\n",
    "    if P.example_verbose:\n",
    "        print('\\nspatialSplit_unseen.i_trn', spatialSplit_unseen.i_trn)\n",
    "        print('spatialSplit_unseen.i_val', spatialSplit_unseen.i_val)\n",
    "        print('spatialSplit_unseen.i_tst', spatialSplit_unseen.i_tst)\n",
    "        print('spatialSplit_allNod.i_trn', spatialSplit_allNod.i_trn)\n",
    "        print('spatialSplit_allNod.i_val', spatialSplit_allNod.i_val)\n",
    "        print('spatialSplit_allNod.i_tst', spatialSplit_allNod.i_tst)\n",
    "    XS_torch_train = torch.Tensor(XS_torch_trn[:,:,spatialSplit_allNod.i_trn,:])\n",
    "    YS_torch_train = torch.Tensor(YS_torch_trn[:,:,spatialSplit_allNod.i_trn,:])\n",
    "    XS_torch_train_model = torch.Tensor(XS_torch_val[:,:,spatialSplit_allNod.i_trn,:])\n",
    "    YS_torch_train_model = torch.Tensor(YS_torch_val[:,:,spatialSplit_allNod.i_trn,:])\n",
    "    XS_torch_val_u = torch.Tensor(XS_torch_val[:,:,spatialSplit_unseen.i_val,:])\n",
    "    YS_torch_val_u = torch.Tensor(YS_torch_val[:,:,spatialSplit_unseen.i_val,:])\n",
    "    XS_torch_val_a = torch.Tensor(XS_torch_val[:,:,spatialSplit_allNod.i_val,:])\n",
    "    YS_torch_val_a = torch.Tensor(YS_torch_val[:,:,spatialSplit_allNod.i_val,:])\n",
    "    XS_torch_tst_u = torch.Tensor(testXS[:,:,spatialSplit_unseen.i_tst,:])\n",
    "    YS_torch_tst_u = torch.Tensor(testYS[:,:,spatialSplit_unseen.i_tst,:])\n",
    "    XS_torch_tst_a = torch.Tensor(testXS[:,:,spatialSplit_allNod.i_tst,:])\n",
    "    YS_torch_tst_a = torch.Tensor(testYS[:,:,spatialSplit_allNod.i_tst,:])\n",
    "    print('\\ntrain.shape', XS_torch_train.shape, YS_torch_train.shape)\n",
    "    print('train_model.shape', XS_torch_train_model.shape, YS_torch_train_model.shape)\n",
    "    print('val_u.shape', XS_torch_val_u.shape, YS_torch_val_u.shape)\n",
    "    print('val_a.shape', XS_torch_val_a.shape, YS_torch_val_a.shape)\n",
    "    print('tst_u.shape', XS_torch_tst_u.shape, YS_torch_tst_u.shape)\n",
    "    print('tst_a.shape', XS_torch_tst_a.shape, YS_torch_tst_a.shape)\n",
    "    if P.example_verbose:\n",
    "        print('\\nFor veryfication purposes')\n",
    "        print('Corresponding first sensor in org order in test', XS_torch_tst_u[0,0,1,:])\n",
    "        print('Corresponding second sensor in org order in train', XS_torch_train[0,0,1,:])\n",
    "    # torch dataset\n",
    "    train_data = torch.utils.data.TensorDataset(XS_torch_train, YS_torch_train)\n",
    "    train_model_data = torch.utils.data.TensorDataset(XS_torch_train_model, YS_torch_train_model)\n",
    "    val_u_data = torch.utils.data.TensorDataset(XS_torch_val_u, YS_torch_val_u)\n",
    "    val_a_data = torch.utils.data.TensorDataset(XS_torch_val_a, YS_torch_val_a)\n",
    "    tst_u_data = torch.utils.data.TensorDataset(XS_torch_tst_u, YS_torch_tst_u)\n",
    "    tst_a_data = torch.utils.data.TensorDataset(XS_torch_tst_a, YS_torch_tst_a)\n",
    "    # torch dataloader\n",
    "    train_iter = torch.utils.data.DataLoader(train_data, P.batch_size, shuffle=False)\n",
    "    train_model_iter = torch.utils.data.DataLoader(train_model_data, P.batch_size, shuffle=False)\n",
    "    val_u_iter = torch.utils.data.DataLoader(val_u_data, P.batch_size, shuffle=False)\n",
    "    val_a_iter = torch.utils.data.DataLoader(val_a_data, P.batch_size, shuffle=False)\n",
    "    tst_u_iter = torch.utils.data.DataLoader(tst_u_data, P.batch_size, shuffle=False)\n",
    "    tst_a_iter = torch.utils.data.DataLoader(tst_a_data, P.batch_size, shuffle=False)\n",
    "\n",
    "    # Load the adjacency matrix\n",
    "    adj_mx = load_adj(P.adj_path, P.adj_type, P.dataname, P.adj_diag)\n",
    "    if P.example_verbose:\n",
    "        print('\\nadjacency matrix after (or not) normalization')\n",
    "        print('frist row of the first adjacency matrix', adj_mx[0][0])\n",
    "        print('Entry (18,1):', adj_mx[0][18][1])\n",
    "        print('Entry (7,11):', adj_mx[0][7][11])\n",
    "        print('Entry (19,10):', adj_mx[0][19][10])\n",
    "\n",
    "    # Split the adjacency matrix by spatial and temporal splits\n",
    "    adj_train = [torch.tensor(i[spatialSplit_unseen.i_trn,:][:,spatialSplit_unseen.i_trn]).to(device) for i in adj_mx]\n",
    "    adj_val_u = [torch.tensor(i[spatialSplit_unseen.i_val,:][:,spatialSplit_unseen.i_val]).to(device) for i in adj_mx]\n",
    "    adj_val_a = [torch.tensor(i[spatialSplit_allNod.i_val,:][:,spatialSplit_allNod.i_val]).to(device) for i in adj_mx]\n",
    "    adj_tst_u = [torch.tensor(i[spatialSplit_unseen.i_tst,:][:,spatialSplit_unseen.i_tst]).to(device) for i in adj_mx]\n",
    "    adj_tst_a = [torch.tensor(i[spatialSplit_allNod.i_tst,:][:,spatialSplit_allNod.i_tst]).to(device) for i in adj_mx]\n",
    "    print('\\nadj_train', 'length of', len(adj_train), adj_train[0].shape)\n",
    "    print('adj_val_u', 'length of', len(adj_val_u), adj_val_u[0].shape)\n",
    "    print('adj_val_a', 'length of', len(adj_val_a), adj_val_a[0].shape)\n",
    "    print('adj_tst_u', 'length of', len(adj_tst_u), adj_tst_u[0].shape)\n",
    "    print('adj_tst_a', 'length of', len(adj_tst_a), adj_tst_a[0].shape)\n",
    "    \n",
    "    if P.example_verbose:\n",
    "        print('\\nFor veryfication purposes')\n",
    "        print('Corresponding Entry (18,1)', adj_train[0][0][1])\n",
    "        print('Corresponding Entry (7,11)', adj_val_u[0][1][3])\n",
    "        print('Corresponding Entry (19,10)', adj_train[0][2][4])\n",
    "        print('\\nadjacency matrix after normalization')\n",
    "        print('train adj', adj_train[0])\n",
    "        print('val_u adj', adj_val_u[0])\n",
    "        print('val_a adj', adj_val_a[0])\n",
    "        print('tst_u adj', adj_tst_u[0])\n",
    "        print('tst_a adj', adj_tst_a[0])\n",
    "    \n",
    "    '''\n",
    "    PRETRAIN data loader.\n",
    "    No need to wrap 12 timestamps into a single instance.\n",
    "    Therefore, destruct them to one dimension.\n",
    "    Both of them should have dimension [number_of_sensor, timestamp]\n",
    "    '''\n",
    "    pretrn_iter = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        XS_torch_train[:,-1,:,0].T), batch_size=1, shuffle=True)\n",
    "    preval_iter = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        torch.tensor(XS_torch_trn[:,-1,spatialSplit_allNod.i_val,0]).T.float()),\n",
    "    batch_size=1, shuffle=False)\n",
    "    print('\\npretrn_iter.dataset.tensors[0].shape', pretrn_iter.dataset.tensors[0].shape)\n",
    "    print('preval_iter.dataset.tensors[0].shape', preval_iter.dataset.tensors[0].shape)\n",
    "    if P.example_verbose:\n",
    "        print('\\nFor veryfication purposes')\n",
    "        a = pretrn_iter.dataset.tensors\n",
    "        b = preval_iter.dataset.tensors\n",
    "        print('Corresponding second instance pretrn_iter', a[0][1,:])\n",
    "        print('Corresponding second instance preval_iter', b[0][1,:])\n",
    "    return pretrn_iter, preval_iter, spatialSplit_unseen, spatialSplit_allNod, \\\n",
    "        train_iter, train_model_iter, val_u_iter, val_a_iter, tst_u_iter, tst_a_iter, \\\n",
    "        adj_train, adj_val_u, adj_val_a, adj_tst_u, adj_tst_a\n",
    "\n",
    "def evaluateModel(P, model, criterion, data_iter, adj, embed, device, sensor_idx_start, test = False):\n",
    "    YS_pred = []\n",
    "    Y = []\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    l_sum, n = 0.0, 0\n",
    "    embed_after_index = embed[:,sensor_idx_start:]\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_iter:\n",
    "            if P.model == 'gwnet':\n",
    "                y_pred = model(x.to(device), adj, embed, P.is_concat_encoder_model, P.is_layer_after_concat).to(device)\n",
    "                y_pred = y_pred[:,:,sensor_idx_start:,]\n",
    "            elif P.model == 'LSTM':\n",
    "                x = x[:,:,sensor_idx_start:,].to(device)\n",
    "                y_pred = model(x, embed_after_index, P.encoder_to_model_ratio, P.is_concat_encoder_model, support = adj, is_example = P.example_verbose, is_layer_after_concat = P.is_layer_after_concat).to(device)\n",
    "            y = y[:,:,sensor_idx_start:,].to(device)\n",
    "            if P.example_verbose:\n",
    "                print('\\nIn model evaluation process:')\n",
    "                print('The shape of y_pred', y_pred.shape)\n",
    "                print('The shape of y', y.shape)\n",
    "            y_pred = scaler.inverse_transform(y_pred)\n",
    "            y = scaler.inverse_transform(y.to(device))\n",
    "            if test == False:\n",
    "                l = criterion(y.to(device), y_pred.to(device))\n",
    "                l_sum += l.item() * y.shape[0]\n",
    "                n += y.shape[0]\n",
    "            Y.append(y)\n",
    "            YS_pred.append(y_pred)\n",
    "        YS_pred = torch.vstack(YS_pred)\n",
    "        Y = torch.vstack(Y)\n",
    "    if test == False:\n",
    "        return l_sum / n, YS_pred, Y\n",
    "    else:\n",
    "        return YS_pred, Y\n",
    "\n",
    "def testModel(P, name, mode, test_iter, adj_tst, spatialsplit, device_cpu, device_gpu, mongodb):\n",
    "    criterion = Metrics.MAE\n",
    "    print('Model Testing', mode, 'Started ...')\n",
    "    if P.train_encoder_on == 'cpu':\n",
    "        device_encoder = device_cpu\n",
    "    else:\n",
    "        device_encoder = device_gpu\n",
    "\n",
    "    if P.augmentation == 'sampler':\n",
    "        is_sampler = True\n",
    "    else:\n",
    "        is_sampler = False\n",
    "    \n",
    "    if P.is_pretrain:\n",
    "        if P.pre_model == 'COST':\n",
    "            encoder = CoSTEncoder(1, 32, P.cost_kernals, 201, 64, 10, P.cost_alpha, P.cl_temperature, P.is_GCN_encoder, is_sampler, len(adj_tst), P.gcn_order, P.gcn_dropout).to(device_encoder)\n",
    "            encoder = nn.DataParallel(encoder)\n",
    "        elif P.pre_model == 'TCN':\n",
    "            encoder = Contrastive_FeatureExtractor_conv(P.cl_temperature, P.is_GCN_encoder, is_sampler, len(adj_tst), P.gcn_order, P.gcn_dropout).to(device_encoder)\n",
    "            encoder = nn.DataParallel(encoder)\n",
    "        encoder.load_state_dict(torch.load(P.save_path+ '/' + 'encoder' + '.pt', map_location=device_encoder))\n",
    "        encoder.eval()\n",
    "    model = getModel(P, name, device_gpu, len(adj_tst))\n",
    "    model.load_state_dict(torch.load(P.save_path+ '/' + name +mode[-2:]+ '.pt', map_location=device_gpu))\n",
    "    s_time = datetime.now()\n",
    "    \n",
    "    '''\n",
    "    Encoder inference\n",
    "    '''\n",
    "    print('Model Infer Start ...')\n",
    "    tst_embed = torch.zeros(32, test_iter.dataset.tensors[0].shape[2]).to(device_gpu).detach()\n",
    "    adj_tst = [tensor.to(device_encoder) for tensor in adj_tst]\n",
    "    if P.is_pretrain:\n",
    "        with torch.no_grad():\n",
    "            tst_encoder_input = torch.Tensor(data[:P.train_size,spatialsplit.i_tst]).to(device_encoder).float().T\n",
    "            if P.is_always_augmentation:\n",
    "                if P.augmentation == 'edge_masking':\n",
    "                    adj_tst = edge_masking(adj_tst, 0.02, device_encoder)\n",
    "                elif P.augmentation == 'temporal_shifting':\n",
    "                    tst_encoder_input = temporal_shifting(tst_encoder_input, P.temporal_shifting_r).to(device_encoder)\n",
    "                elif P.augmentation == 'temporal_shifting_new':\n",
    "                    tst_encoder_input = temporal_shifting_new(tst_encoder_input, P.temporal_shifting_r).to(device_encoder) \n",
    "                elif P.augmentation == 'input_smoothing':\n",
    "                    tst_encoder_input = input_smoothing(tst_encoder_input, P.input_smoothing_r, P.input_smoothing_e).to(device_encoder)\n",
    "            if P.example_verbose:\n",
    "                print('\\nThe shape of tst_encoder_input', tst_encoder_input.shape)\n",
    "            tst_embed = encoder(tst_encoder_input, adj_tst, P.example_verbose).T.detach().to(device_gpu)\n",
    "    adj_tst = [tensor.to(device_gpu) for tensor in adj_tst]\n",
    "    m_time = datetime.now()\n",
    "    print('ENCODER INFER DURATION:', m_time-s_time)\n",
    "\n",
    "    if P.is_testunseen:\n",
    "        sensor_idx_start = len(spatialsplit.i_val)\n",
    "    else:\n",
    "        sensor_idx_start = 0\n",
    "    if P.example_verbose:\n",
    "        print('\\nThe inference for model starts at index', sensor_idx_start)\n",
    "\n",
    "    print('\\nMODEL INFER START ...')\n",
    "    '''\n",
    "    Prediction is on all sensors\n",
    "    But the loss is calculated only for the sensors after sensor_idx_start\n",
    "    '''\n",
    "    YS_pred, YS = evaluateModel(P, model, criterion, test_iter, adj_tst, tst_embed, device_gpu, sensor_idx_start, test = True)\n",
    "    e_time = datetime.now()\n",
    "    print('Model Infer End ...', e_time)\n",
    "    \n",
    "    print('MODEL INFER DURATION:', (e_time-m_time).total_seconds())\n",
    "    print('YS.shape, YS_pred.shape,', YS.shape, YS_pred.shape)\n",
    "    #  Save the results\n",
    "    torch.save(YS, P.save_path + '/' + 'YS.pt')\n",
    "    torch.save(YS_pred, P.save_path + '/' + 'YS_pred.pt')\n",
    "\n",
    "\n",
    "'''\n",
    "System parameters\n",
    "P = type('Parameters', (object,), {})()\n",
    "P.dataname = 'METRLA'\n",
    "P.model = 'LSTM'\n",
    "P.pre_model = 'TCN'\n",
    "P.track_id = 0\n",
    "P.replication = 1\n",
    "P.seed = 0\n",
    "\n",
    "P.t_train = 0.7\n",
    "P.t_val = 0.1\n",
    "P.s_train = 0.7\n",
    "P.s_val = 0.1\n",
    "P.fold = 2\n",
    "\n",
    "P.timestep_in = 12\n",
    "P.timestep_out = 12\n",
    "P.n_channel = 1\n",
    "P.batch_size = 64\n",
    "\n",
    "P.lstm_hidden_dim = 128\n",
    "P.lstm_layers = 2\n",
    "P.lstm_dropout = 0.2\n",
    "P.gwnet_is_adp_adj = True\n",
    "P.gwnet_is_SGA = False\n",
    "\n",
    "P.adj_type = 'doubletransition'\n",
    "P.adj_method = 1\n",
    "P.adj_diag = 0\n",
    "P.cost_kernals = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "P.cost_alpha = 0.5\n",
    "P.cl_temperature = 1\n",
    "P.is_pretrain = True\n",
    "P.is_GCN_encoder = True\n",
    "P.is_GCN_after_CL = True\n",
    "P.gcn_order = 1\n",
    "P.gcn_dropout = 0\n",
    "\n",
    "P.augmentation = 'sampler'\n",
    "P.temporal_shifting_r = 0.8\n",
    "P.input_smoothing_r = 0.9\n",
    "P.input_smoothing_e = 20\n",
    "P.encoder_to_model_ratio = 1\n",
    "P.is_concat_encoder_model = True\n",
    "P.is_layer_after_concat = True\n",
    "P.is_always_augmentation = True\n",
    "\n",
    "P.tolerance = 10\n",
    "P.learn_rate = 0.001\n",
    "P.pretrain_epoch = 2\n",
    "P.train_epoch = 1\n",
    "P.weight_decay = 0\n",
    "P.is_testunseen = True\n",
    "P.train_model_datasplit = 'B'\n",
    "P.train_encoder_on = 'cpu'\n",
    "\n",
    "P.is_mongo = True\n",
    "P.example_verbose = True\n",
    "P.is_tune = False\n",
    "\n",
    "P.fold_i = 0\n",
    "P.exe_id = file_name\n",
    "'''\n",
    "\n",
    "def main(P):\n",
    "    global data\n",
    "    global scaler\n",
    "\n",
    "    '''\n",
    "    Check the parameter settings.\n",
    "    '''\n",
    "    if P.is_pretrain == False and P.is_concat_encoder_model == True:\n",
    "        raise ValueError('Pretraining should be enabled for concatenation')\n",
    "    if P.augmentation == 'edge_masking' and P.is_GCN_encoder == False:\n",
    "        raise ValueError('edge_masking augmentation requires GCN encoder')\n",
    "    if P.is_GCN_encoder == True and P.is_GCN_after_CL == True:\n",
    "        raise ValueError('GCN should be used only in one place')\n",
    "    if P.is_layer_after_concat == True and P.is_concat_encoder_model == False:\n",
    "        raise ValueError('Layer after concatenation requires concatenation')\n",
    "    if P.fold * (1 - P.s_train - P.s_val) > 1:\n",
    "        raise ValueError('The number of sensors cannot meet this fold requirement')\n",
    "    if P.is_layer_after_concat and P.gwnet_is_SGA:\n",
    "        raise ValueError('Layer after concatenation requires no SGA')\n",
    "\n",
    "    '''\n",
    "    Set backend devices. \n",
    "    Check the type of GPU, either mps or cuda, is available.\n",
    "    Also, another options is to use the CPU.\n",
    "    '''\n",
    "    if torch.backends.mps.is_available():\n",
    "        device_gpu = torch.device('mps') \n",
    "    if torch.cuda.is_available():\n",
    "        device_gpu = torch.device('cuda')\n",
    "    device_cpu = torch.device('cpu')\n",
    "\n",
    "    # load data from file\n",
    "    # P.exe_id = P.dataname + '_' + P.model + '_' + P.pre_model + '_' + datetime.now().strftime(\"%y%m%d-%H%M\")\n",
    "    # P.save_path = 'save/' + P.exe_id\n",
    "    if P.dataname == 'METRLA':\n",
    "        print('P.dataname == METRLA')\n",
    "        data_path = './data/METRLA/metr-la.h5'\n",
    "        if P.adj_method == 0:\n",
    "            P.adj_path = './data/METRLA/adj_mx.pkl'\n",
    "        elif P.adj_method == 1:\n",
    "            P.adj_path = './data/METRLA/adj_mx_new1.pkl'\n",
    "        P.n_sensor = 207\n",
    "        data = pd.read_hdf(data_path).values\n",
    "    elif P.dataname == 'PEMSBAY':\n",
    "        print('P.dataname == PEMSBAY')\n",
    "        data_path = './data/PEMSBAY/pems-bay.h5'\n",
    "        if P.adj_method == 0:\n",
    "            P.adj_path = './data/PEMSBAY/adj_mx_bay.pkl'\n",
    "        elif P.adj_method == 1:\n",
    "            P.adj_path = './data/PEMSBAY/adj_mx_new1.pkl'\n",
    "        P.n_sensor = 325\n",
    "        data = pd.read_hdf(data_path).values\n",
    "    elif P.dataname == 'HAGUE_FULL':\n",
    "        print('P.dataname == HAGUE_FULL')\n",
    "        data_path = './data/Hauge/hague_filled.h5'\n",
    "        if P.adj_method == 1:\n",
    "            P.adj_path = './data/Hauge/adj_mx1.pkl'\n",
    "        P.n_sensor = 144\n",
    "        data = pd.read_hdf(data_path).values\n",
    "    elif P.dataname == 'HAGUE':\n",
    "        print('P.dataname == HAGUE')\n",
    "        data_path = './data/Hauge/hague_comp_filled.h5'\n",
    "        if P.adj_method == 1:\n",
    "            P.adj_path = './data/Hauge/adj_mx_comp1.pkl'\n",
    "        if P.adj_method == 2:\n",
    "            P.adj_path = './data/Hauge/adj_mx_comp2.pkl'\n",
    "        P.n_sensor = 89\n",
    "        data = pd.read_hdf(data_path).values\n",
    "    elif P.dataname == 'HAGUE_25':\n",
    "        print('P.dataname == HAGUE_25')\n",
    "        data_path = './data/Hauge/hague_comp_filled_25.h5'\n",
    "        if P.adj_method == 1:\n",
    "            P.adj_path = './data/Hauge/adj_mx_comp1.pkl'\n",
    "        if P.adj_method == 2:\n",
    "            P.adj_path = './data/Hauge/adj_mx_comp2.pkl'\n",
    "        P.n_sensor = 89\n",
    "        data = pd.read_hdf(data_path).values\n",
    "    elif P.dataname == 'HAGUE_20_2':\n",
    "        print('P.dataname == HAGUE_20_2')\n",
    "        data_path = './data/Hauge/hague_comp_filled_20_2.h5'\n",
    "        if P.adj_method == 1:\n",
    "            P.adj_path = './data/Hauge/adj_mx_comp1.pkl'\n",
    "        if P.adj_method == 2:\n",
    "            P.adj_path = './data/Hauge/adj_mx_comp2.pkl'\n",
    "        P.n_sensor = 89\n",
    "        data = pd.read_hdf(data_path).values\n",
    "    elif P.dataname == 'HAGUE_FULL_75':\n",
    "        print('P.dataname == HAGUE_FULL_75')\n",
    "        data_path = './data/Hauge/hague_filled_75.h5'\n",
    "        if P.adj_method == 1:\n",
    "            P.adj_path = './data/Hauge/adj_mx1.pkl'\n",
    "        P.n_sensor = 144\n",
    "        data = pd.read_hdf(data_path).values\n",
    "    elif P.dataname == 'EXAMPLE':\n",
    "        print('P.dataname == EXAMPLE')\n",
    "        data_path = './data/example.h5'\n",
    "        if P.adj_method == 1:\n",
    "            P.adj_path = './data/adj_mx_ex1.pkl'\n",
    "        P.n_sensor = 20\n",
    "        data = pd.read_hdf(data_path).values\n",
    "        if P.example_verbose:\n",
    "            print('\\nFirst row at 10 am:', data[0])\n",
    "            print('\\nSecond row at 10:05:', data[1])\n",
    "    \n",
    "    '''\n",
    "    Apply the scaler to the sensor readings. \n",
    "    The data is scaled based on the mean and standard deviation of the data.\n",
    "    '''\n",
    "    if P.is_mongo:\n",
    "        mongodb = connect_mongo()\n",
    "    else:\n",
    "        mongodb = None\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    P.data_mean = scaler.u\n",
    "    P.data_std = scaler.z\n",
    "    if P.example_verbose:\n",
    "        print('data.shape:', data.shape)\n",
    "        print('data mean:', P.data_mean)\n",
    "        print('data stadard deviation:', P.data_std)\n",
    "        if P.dataname == 'EXAMPLE':\n",
    "            print('\\nFirst row at 10 am after scaling:', data[0])\n",
    "            print('\\nSecond row at 10:05 after scaling:', data[1])\n",
    "            print('\\nFirst sensor data:', data[:,0])\n",
    "            print('\\nSecond sensor data:', data[:,1])\n",
    "\n",
    "    P.save_path = 'result/' + P.exe_id\n",
    "    # setup\n",
    "    pretrn_iter, preval_iter, spatialSplit_unseen, spatialSplit_allNod, \\\n",
    "        train_iter, train_model_iter, val_u_iter, val_a_iter, tst_u_iter, tst_a_iter, \\\n",
    "        adj_train, adj_val_u, adj_val_a, adj_tst_u, adj_tst_a = setups(P, device_gpu)\n",
    "    testModel(P, P.model, 'test_a', tst_a_iter, adj_tst_a, spatialSplit_allNod, device_cpu, device_gpu, mongodb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.dataname == HAGUE\n",
      "\n",
      "trainXS.shape (146295, 1, 89, 12)\n",
      "trainYS.shape (146295, 12, 89, 1)\n",
      "testXS.shape (62698, 1, 89, 12)\n",
      "testYS.shape (62698, 12, 89, 1)\n",
      "\n",
      "spatialSplit_unseen all: trn/val/tst : 89 : 62 / 9 / 18\n",
      "spatialSplit_allNod all: trn/val/tst : 89 : 62 / 71 / 89\n",
      "spatialSplit_unseen.i_tst [51 49 72 33 62 54 11 16 36 40  0 73  8 29 28 64 15  9]\n",
      "\n",
      "train.shape torch.Size([83597, 1, 62, 12]) torch.Size([83597, 12, 62, 1])\n",
      "train_model.shape torch.Size([62698, 1, 62, 12]) torch.Size([62698, 12, 62, 1])\n",
      "val_u.shape torch.Size([62698, 1, 9, 12]) torch.Size([62698, 12, 9, 1])\n",
      "val_a.shape torch.Size([62698, 1, 71, 12]) torch.Size([62698, 12, 71, 1])\n",
      "tst_u.shape torch.Size([62698, 1, 18, 12]) torch.Size([62698, 12, 18, 1])\n",
      "tst_a.shape torch.Size([62698, 1, 89, 12]) torch.Size([62698, 12, 89, 1])\n",
      "\n",
      "adj_train length of 2 torch.Size([62, 62])\n",
      "adj_val_u length of 2 torch.Size([9, 9])\n",
      "adj_val_a length of 2 torch.Size([71, 71])\n",
      "adj_tst_u length of 2 torch.Size([18, 18])\n",
      "adj_tst_a length of 2 torch.Size([89, 89])\n",
      "\n",
      "pretrn_iter.dataset.tensors[0].shape torch.Size([62, 83597])\n",
      "preval_iter.dataset.tensors[0].shape torch.Size([71, 83597])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuyou/Desktop/master_graduation_project/utils.py:50: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing test_a Started ...\n",
      "Model Infer Start ...\n",
      "ENCODER INFER DURATION: 0:00:00.836152\n",
      "\n",
      "MODEL INFER START ...\n",
      "Model Infer End ... 2024-07-30 17:49:52.860458\n",
      "MODEL INFER DURATION: 95.054604\n",
      "YS.shape, YS_pred.shape, torch.Size([62698, 12, 18, 1]) torch.Size([62698, 12, 18, 1])\n"
     ]
    }
   ],
   "source": [
    "main(P)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
